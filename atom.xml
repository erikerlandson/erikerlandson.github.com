<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[tool monkey]]></title>
  <link href="http://erikerlandson.github.com/atom.xml" rel="self"/>
  <link href="http://erikerlandson.github.com/"/>
  <updated>2015-05-07T13:17:22-07:00</updated>
  <id>http://erikerlandson.github.com/</id>
  <author>
    <name><![CDATA[Erik Erlandson]]></name>
    <email><![CDATA[erikerlandson@yahoo.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Parallel K-Medoids Using Scala ParSeq]]></title>
    <link href="http://erikerlandson.github.com/blog/2015/05/06/parallel-k-medoids-using-scala-parseq/"/>
    <updated>2015-05-06T16:33:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2015/05/06/parallel-k-medoids-using-scala-parseq</id>
    <content type="html"><![CDATA[<p>Scala supplies a <a href="http://docs.scala-lang.org/overviews/parallel-collections/overview.html">parallel collections library</a> that was designed to make it easy for a programmer to add parallel computing over the elements in a collection.  In this post, I will describe a case study of applying Scala&#8217;s parallel collections to cleanly implement multithreading support for training a K-Medoids clustering model.</p>

<h3>Motivation</h3>

<p><a href="http://en.wikipedia.org/wiki/K-medoids">K-Medoids clustering</a> is a relative of K-Means clustering that does not require an algebra over input data elements.  That is, K-Medoids requires only a distance metric defined on elements in the data space, and can cluster objects which do not have a well-defined concept of addition or division that is necessary for computing the <a href="http://en.wikipedia.org/wiki/Centroid">centroids</a> required by K-Means.  For example, K-Medoids can cluster character strings, which have a notion of <a href="http://en.wikipedia.org/wiki/Edit_distance">distance</a>, but no notion of summation that could be used to compute a geometric centroid.</p>

<p>This additional generality comes at a cost.  The medoid of a collection of elements is the member of the collection that minimizes some function F of the distances from that element to all the other elements in the collection.  For example, F might be the sum of distances from one element to all the elements, or perhaps the maximum distance, etc.  <strong>It is not hard to see that the cost of computing a medoid of (n) elements is quadratic in (n)</strong>: Evaluating F is linear in (n) and F in turn must be evaluated with respect to each element.  Furthermore, unlike centroid-based computations used in K-Means, computing a medoid does not naturally lend itself to common scale-out computing formalisms such as Spark RDDs, due to the full-cross-product nature of the computation.</p>

<p>With this in mind, a more traditional multithreading approach is a good candidate to achieve some practical parallelism on modern multi-core hardware.  I&#8217;ll demonstrate that this is easy to implement in Scala with parallel sequences.</p>

<h3>Non-Parallel Code</h3>

<p>Consider a baseline non-parallel implementation of K-Medoids, as in the following example skeleton code.  (A working version of this code, under review at the time of this post, can be <a href="https://github.com/erikerlandson/silex/blob/parseq_blog/src/main/scala/com/redhat/et/silex/cluster/KMedoids.scala">viewed here</a>)</p>

<figure class='code'><figcaption><span>A skeleton K-Medoids implementation </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">class</span> <span class="nc">KMedoids</span><span class="o">[</span><span class="kt">T</span><span class="o">](</span><span class="n">k</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="n">metric</span><span class="k">:</span> <span class="o">(</span><span class="kt">T</span><span class="o">,</span> <span class="kt">T</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="nc">Double</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">// Train a K-Medoids cluster on some input data</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">train</span><span class="o">[</span><span class="kt">T</span><span class="o">](</span><span class="n">data</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">T</span><span class="o">])</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">var</span> <span class="n">current</span> <span class="k">=</span> <span class="c1">// randomly select k data elements as initial cluster</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">var</span> <span class="n">model_converged</span> <span class="k">=</span> <span class="kc">false</span>
</span><span class='line'>    <span class="k">while</span> <span class="o">(!</span><span class="n">model_converged</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>      <span class="c1">// assign each element to its closest medoid</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">clusters</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">medoidIdx</span><span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">current</span><span class="o">)).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>      <span class="c1">// recompute the medoid from the latest cluster elements</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">next</span> <span class="k">=</span> <span class="n">benchmark</span><span class="o">(</span><span class="s">&quot;medoids&quot;</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">clusters</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">medoid</span><span class="o">)</span>
</span><span class='line'>      <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>      <span class="n">model_converged</span> <span class="k">=</span> <span class="c1">// test for model convergence</span>
</span><span class='line'>
</span><span class='line'>      <span class="n">current</span> <span class="k">=</span> <span class="n">next</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">// Return the medoid of some collection of elements</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">medoid</span><span class="o">(</span><span class="n">data</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">T</span><span class="o">])</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">benchmark</span><span class="o">(</span><span class="n">s</span><span class="s">&quot;medoid: n= ${data.length}&quot;</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>      <span class="n">data</span><span class="o">.</span><span class="n">minBy</span><span class="o">(</span><span class="n">medoidCost</span><span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">data</span><span class="o">)</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">// The sum of an element&#39;s distance to all the elements in its cluster</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">medoidCost</span><span class="o">(</span><span class="n">e</span><span class="k">:</span> <span class="kt">T</span><span class="o">,</span> <span class="n">data</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">T</span><span class="o">])</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">iterator</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">metric</span><span class="o">(</span><span class="n">e</span><span class="o">,</span> <span class="k">_</span><span class="o">)).</span><span class="n">sum</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">// Index of the closest medoid to an element</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">medoidIdx</span><span class="o">(</span><span class="n">e</span><span class="k">:</span> <span class="kt">T</span><span class="o">,</span> <span class="n">mv</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">T</span><span class="o">])</span> <span class="k">=</span> <span class="n">mv</span><span class="o">.</span><span class="n">iterator</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">metric</span><span class="o">(</span><span class="n">e</span><span class="o">,</span> <span class="k">_</span><span class="o">)).</span><span class="n">zipWithIndex</span><span class="o">.</span><span class="n">min</span><span class="o">.</span><span class="n">_2</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">// Output a benchmark timing of some expression</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">benchmark</span><span class="o">[</span><span class="kt">T</span><span class="o">](</span><span class="n">label</span><span class="k">:</span> <span class="kt">String</span><span class="o">)(</span><span class="n">blk</span><span class="k">:</span> <span class="o">=&gt;</span> <span class="n">T</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">t0</span> <span class="k">=</span> <span class="nc">System</span><span class="o">.</span><span class="n">nanoTime</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">t</span> <span class="k">=</span> <span class="n">blk</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">sec</span> <span class="k">=</span> <span class="o">(</span><span class="nc">System</span><span class="o">.</span><span class="n">nanoTime</span> <span class="o">-</span> <span class="n">t0</span><span class="o">)</span> <span class="o">/</span> <span class="mi">1</span><span class="n">e9</span>
</span><span class='line'>    <span class="n">println</span><span class="o">(</span><span class="n">f</span><span class="s">&quot;Run time for $label = $sec%.1f&quot;</span><span class="o">);</span> <span class="nc">System</span><span class="o">.</span><span class="n">out</span><span class="o">.</span><span class="n">flush</span>
</span><span class='line'>    <span class="n">t</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>If we run the code above (de-skeletonized), then we might see something like this output from our benchmarking, where I clustered a dataset of 40,000 randomly-generated (x,y,z) points by Gaussian sampling around 5 chosen centers.  (This data is numeric, but I provide only a distance metric on the points.  K-Medoids has no knowledge of the data except that it can run the given metric function on it):</p>

<figure class='code'><figcaption><span>One iteration of a clustering run (k = 5) </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Run time for medoid: n= 8299 = 7.7
</span><span class='line'>Run time for medoid: n= 3428 = 1.2
</span><span class='line'>Run time for medoid: n= 12581 = 17.0
</span><span class='line'>Run time for medoid: n= 5731 = 3.3
</span><span class='line'>Run time for medoid: n= 9961 = 10.2
</span><span class='line'>Run time for medoids = 39.8</span></code></pre></td></tr></table></div></figure>


<p>Observe that cluster sizes are generally not the same, and we can see the time per cluster varying quadratically with respect to cluster size.</p>

<h3>A First Take On Parallel K-Medoids</h3>

<p>Studying our non-parallel code above, we can see that the computation of each new medoid is independent, which makes it a likely place to inject some parallelism. A Scala sequence can be transformed into a corresponding parallel sequence using the <code>par</code> method, and so parallelizing our code is literally this simple:</p>

<figure class='code'><figcaption><span>Parallelizing a collection with .par </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'>      <span class="c1">// recompute the medoid from the latest cluster elements</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">next</span> <span class="k">=</span> <span class="n">benchmark</span><span class="o">(</span><span class="s">&quot;medoids&quot;</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">clusters</span><span class="o">.</span><span class="n">par</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">medoid</span><span class="o">).</span><span class="n">seq</span>
</span><span class='line'>      <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>In this block, I also apply <code>.seq</code> at the end, which is not always necessary but can avoid type mismatches between <code>Seq[T]</code> and <code>ParSeq[T]</code> under some circumstances.</p>

<p>In my case I also wish to exercise some control over the threading used by the parallelism, and so I explicitly assign a <code>ForkJoinPool</code> thread pool to the sequence:</p>

<figure class='code'><figcaption><span>Set the threading used by a Scala ParSeq </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'>      <span class="c1">// establish a thread pool for use by K-Medoids</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">threadPool</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ForkJoinPool</span><span class="o">(</span><span class="n">numThreads</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>      <span class="c1">// ...</span>
</span><span class='line'>
</span><span class='line'>      <span class="c1">// recompute the medoid from the latest cluster elements</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">next</span> <span class="k">=</span> <span class="n">benchmark</span><span class="o">(</span><span class="s">&quot;medoids&quot;</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="k">val</span> <span class="n">pseq</span> <span class="k">=</span> <span class="n">clusters</span><span class="o">.</span><span class="n">par</span>
</span><span class='line'>        <span class="n">pseq</span><span class="o">.</span><span class="n">tasksupport</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ForkJoinTaskSupport</span><span class="o">(</span><span class="n">threadPool</span><span class="o">)</span>
</span><span class='line'>        <span class="n">pseq</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">medoid</span><span class="o">).</span><span class="n">seq</span>
</span><span class='line'>      <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Minor grievance: it would be nice if Scala supported some &#8216;in-line&#8217; methods, like <code>seq.par(n)...</code> and <code>seq.par(threadPool)...</code>, instead of requiring the programmer to break the flow of the code to invoke <code>tasksupport =</code>, which returns <code>Unit</code>.</p>

<p>Now that we&#8217;ve parallelized our K-Medoids training, we should see how well it responds to additional threads.  I ran the above parallelized version using <code>{1, 2, 4, 8, 16, 32}</code> threads, on a machine with 40 cores, so that my benchmarking would not be impacted by attempting to run more threads than there are cores to support them.  I also ran two version of test data.  The first I generated with clusters of equal size (5 clusters of ~8000 elements), and the second with one cluster being twice as large (1 cluster of ~13300 and 4 clusters of ~6700).  Following is a plot of throughput (iterations / second) versus threads:</p>

<p><img class="left" src="http://erikerlandson.github.com/assets/images/parseq/by_cluster_1.png" title="Throughput As A Function Of Threads" ></p>

<p>In the best of all possible worlds, our throughput would increase linearly with the number of threads; double the threads, double our iterations per second.  Instead, our throughput starts to increase nicely as we add threads, but hits a hard ceiling at 8 threads.  It is not hard to see why: our parallelism is limited by the number of elements in our collection of clusters.  In our case that is k = 5, and so we reach our ceiling at 8 threads, the first thread number >= 5.  Furthermore, we see that when the size of clusters is unequal, the throughput suffers even more.  The time required to complete the clustering is dominated by the most expensive element.  In our case, the cluster that is twice the size of other clusters:</p>

<figure class='code'><figcaption><span>Run time is dominated by largest cluster </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Run time for medoid: n= 6695 = 5.1
</span><span class='line'>Run time for medoid: n= 6686 = 5.2
</span><span class='line'>Run time for medoid: n= 6776 = 5.3
</span><span class='line'>Run time for medoid: n= 6682 = 5.4
</span><span class='line'>Run time for medoid: n= 13161 = 19.9
</span><span class='line'>Run time for medoids = 19.9</span></code></pre></td></tr></table></div></figure>


<h3>Take 2: Improving The Use Of Threads</h3>

<p>Fortunately it is not hard to improve on this situation.  If parallelizing by cluster is too coarse, we can try pushing our parallelism down one level of granularity.  In our case, that means parallelizing the outer loop of our medoid function, and it is just as easy as before:</p>

<figure class='code'><figcaption><span>Parallelize the outer loop of medoid computation </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'>  <span class="c1">// Return the medoid of some collection of elements</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">medoid</span><span class="o">(</span><span class="n">data</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">T</span><span class="o">])</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">benchmark</span><span class="o">(</span><span class="n">s</span><span class="s">&quot;medoid: n= ${data.length}&quot;</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">pseq</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">par</span>
</span><span class='line'>      <span class="n">pseq</span><span class="o">.</span><span class="n">tasksupport</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ForkJoinTaskSupport</span><span class="o">(</span><span class="n">threadPool</span><span class="o">)</span>
</span><span class='line'>      <span class="n">pseq</span><span class="o">.</span><span class="n">minBy</span><span class="o">(</span><span class="n">medoidCost</span><span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">data</span><span class="o">)</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>  <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Observe that we are applying the same thread pool we supplied to the ParSeq at the cluster level.  Scala&#8217;s parallel logic can utilize the same thread pool at multiple granularities without blocking.  This makes it very clean to control the total number of threads used by some computation, by simply re-using the same threadpool across all points of parallelism.</p>

<p>Now, when we re-run our experiment, we see that our throughput continues to increase as we add threads.  The following plot illustrates the throughput increasing in comparison to the previous ceiling, and also that throughput is less sensitive to the cluster size, as threads can be allocated flexibly across clusters as they are available:</p>

<p><img class="left" src="http://erikerlandson.github.com/assets/images/parseq/all_1.png" title="Thread utilization improves at finer granularity" ></p>

<p>I hope this short case study has demonstrated how easy it is to add multithreading to computations with Scala parallel sequences, and some considerations for making the best use of available threads.  Happy Parallel Programming!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hygienic Closures for Scala Function Serialization]]></title>
    <link href="http://erikerlandson.github.com/blog/2015/03/31/hygienic-closures-for-scala-function-serialization/"/>
    <updated>2015-03-31T06:06:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2015/03/31/hygienic-closures-for-scala-function-serialization</id>
    <content type="html"><![CDATA[<p>In most use cases of Scala closures, what you see is what you get, but there are exceptions where looks can be deceiving and this can have a big impact on closure serialization.  Closure serialization is of more than academic interest.  Tools like Apache Spark cannot operate without serializing functions over the network.  In this post I&#8217;ll describe some scenarios where closures include more than what is evident in the code, and then a technique for preventing unwanted inclusions.</p>

<p>To establish a bit of context, consider this simple example that obtains a function and serializes it to disk, and which <em>does</em> behave as expected:</p>

<pre><code>object Demo extends App {
  def write[A](obj: A, fname: String) {
    import java.io._
    new ObjectOutputStream(new FileOutputStream(fname)).writeObject(obj)
  }

  object foo {
    val v = 42
    // The returned function includes 'v' in its closure
    def f() = (x: Int) =&gt; v * x
  }

  // The function 'f' will serialize as expected
  val f = foo.f
  write(f, "/tmp/demo.f")
}
</code></pre>

<p>When this app is compiled and run, it will serialize <code>f</code> to &#8220;/tmp/demo.f1&#8221;, which of course includes the value of <code>v</code> as part of the closure for <code>f</code>.</p>

<pre><code>$ scalac -d /tmp closures.scala
$ scala -cp /tmp Demo
$ ls /tmp/demo*
/tmp/demo.f
</code></pre>

<p>Now, imagine you wanted to make a straightforward change, where <code>object foo</code> becomes <code>class foo</code>:</p>

<pre><code>object Demo extends App {
  def write[A](obj: A, fname: String) {
    import java.io._
    new ObjectOutputStream(new FileOutputStream(fname)).writeObject(obj)
  }

  // foo is a class instead of an object
  class foo() {
    val v = 42
    // The returned function includes 'v' in its closure, but also a secret surprise
    def f() = (x: Int) =&gt; v * x
  }

  // This will throw an exception!
  val f = new foo().f
  write(f, "/tmp/demo.f")
}
</code></pre>

<p>It would be reasonable to expect that this minor variation behaves exactly as the previous one, but instead it throws an exception!</p>

<pre><code>$ scalac -d /tmp closures.scala
$ scala -cp /tmp Demo
java.io.NotSerializableException: Demo$foo
</code></pre>

<p>If we look at the exception message, we see that it&#8217;s complaining about not knowing how to serialize objects of class <code>foo</code>.  But we weren&#8217;t including any values of <code>foo</code> in the closure for <code>f</code>, only a particular member &#8216;v&#8217;!  What gives?  Scala is not very helpful with diagnosing this problem, but when a class member value shows up in a closure that is defined <em>inside</em> the class body, the <em>entire instance</em>, including any and all other member values, is included in the closure.  Presumably this is because a class may have any number of instances, and the compiler is including the entire instance in the closure to properly resolve the correct member value.</p>

<p>One straightforward way to fix this is to simply make class <code>foo</code> serializable:</p>

<pre><code>class foo() extends Serializable {
  // ...
}
</code></pre>

<p>If you make this change to the above code, the example with <code>class foo</code> now works correctly, but it is working by serializing the entire <code>foo</code> instance, not just the value of <code>v</code>.</p>

<p>In many cases, this is not a problem and will work fine.  Serializing a few additional members may be inexpensive.  In other cases, however, it can be an impractical or impossible option.  For example, <code>foo</code> might include other very large members, which will be expensive or outright impossible to serialize:</p>

<pre><code>class foo() extends Serializable {
  val v = 42    // easy to serialize
  val w = 4.5   // easy to serialize
  val data = (1 to 1000000000).toList  // serialization landmine hiding in your closure

  // The returned function includes all of 'foo' instance in its closure
  def f() = (x: Int) =&gt; v * x
}
</code></pre>

<p>A variation on the above problem is class members that are small or moderate in size, but serialized many times.  In this case, the serialization cost can become intractable via repetition of unwanted inclusions.</p>

<p>Another potential problem is class members that are not serializable, and perhaps not under your control:</p>

<pre><code>class foo() extends Serializable {
  import some.class.NotSerializable

  val v = 42                      // easy to serialize
  val x = new NotSerializable     // I'll hide in your closure and fail to serialize

  // The returned function includes all of 'foo' instance in its closure
  def f() = (x: Int) =&gt; v * x
}
</code></pre>

<p>There is a relatively painless way to decouple values from their parent instance, so that only desired values are included in a closure.  Passing desired values as parameters to a shim function whose job is to assemble the closure will prevent the parent instance from being pulled into the closure.  In the following example, a shim function named <code>closureFunction</code> is defined for this purpose:</p>

<pre><code>object Demo extends App {
  def write[A](obj: A, fname: String) {
    import java.io._
    new ObjectOutputStream(new FileOutputStream(fname)).writeObject(obj)
  }

  // apply a generator to create a function with safe decoupled closures
  def closureFunction[E,D,R](enclosed: E)(gen: E =&gt; (D =&gt; R)) = gen(enclosed)

  class NotSerializable {}

  class foo() {
    val v1 = 42
    val v2 = 73
    val n = new NotSerializable

    // use shim function to enclose *only* the values of 'v1' and 'v2'
    def f() = closureFunction((v1, v2)) { enclosed =&gt;
      val (v1, v2) = enclosed
      (x: Int) =&gt; (v1 + v2) * x   // Desired function, with 'v1' and 'v2' enclosed
    }
  }

  // This will work!
  val f = new foo().f
  write(f, "/tmp/demo.f")
}
</code></pre>

<p>Being aware of the scenarios where parent instances are pulled into closures, and how to keep your closures clean, can save some frustration and wasted time.  Happy programming!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Monadic 'break' and 'continue' for Scala Sequence Comprehensions]]></title>
    <link href="http://erikerlandson.github.com/blog/2015/01/24/monadic-break-and-continue-for-scala-sequence-comprehensions/"/>
    <updated>2015-01-24T11:54:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2015/01/24/monadic-break-and-continue-for-scala-sequence-comprehensions</id>
    <content type="html"><![CDATA[<p>Author&#8217;s note: I&#8217;ve since received some excellent feedback from the Scala community, which I included in some <a href="#notes">end notes</a>.</p>

<p>Author&#8217;s note the 2nd: I later realized I could apply an implicit conversion and mediator class to preserve the traditional ordering: the code has been updated with that approach.</p>

<p>Author&#8217;s note the 3rd: This concept has been submitted to the Scala project as JIRA <a href="https://issues.scala-lang.org/browse/SI-9120">SI-9120</a> (PR <a href="https://github.com/scala/scala/pull/4275">#4275</a>)</p>

<p>Scala <a href="http://docs.scala-lang.org/tutorials/tour/sequence-comprehensions.html">sequence comprehensions</a> are an excellent functional programming idiom for looping in Scala.  However, sequence comprehensions encompass much more than just looping &#8211; they represent a powerful syntax for manipulating <em>all</em> monadic structures<a href="#ref1">[1]</a>.</p>

<p>The <code>break</code> and <code>continue</code> looping constructs are a popular framework for cleanly representing multiple loop halting and continuation conditions at differing stages in the execution flow.  Although there is no native support for <code>break</code> or <code>continue</code> in Scala control constructs, it is possible to implement them in a clean and idiomatic way for sequence comprehensions.</p>

<p>In this post I will describe a lightweight and easy-to-use implementation of <code>break</code> and <code>continue</code> for use in Scala sequence comprehensions (aka <code>for</code> statements).  The entire implementation is as follows:</p>

<pre><code>object BreakableGenerators {
  import scala.language.implicitConversions

  type Generator[+A] = Iterator[A]
  type BreakableGenerator[+A] = BreakableIterator[A]

  // Generates a new breakable generator from any traversable object.
  def breakable[A](t1: TraversableOnce[A]): Generator[BreakableGenerator[A]] =
    List(new BreakableIterator(t1.toIterator)).iterator

  // Mediates boolean expression with 'break' and 'continue' invocations
  case class BreakableGuardCondition(cond: Boolean) {
    // Break the looping over one or more breakable generators, if 'cond' 
    // evaluates to true.
    def break(b: BreakableGenerator[_], bRest: BreakableGenerator[_]*): Boolean = {
      if (cond) {
        b.break
        for (x &lt;- bRest) { x.break }
      }
      !cond
    }

    // Continue to next iteration of enclosing generator if 'cond' 
    // evaluates to true.
    def continue: Boolean = !cond
  }

  // implicit conversion of boolean values to breakable guard condition mediary
  implicit def toBreakableGuardCondition(cond: Boolean) =
    BreakableGuardCondition(cond)

  // An iterator that can be halted via its 'break' method.  Not invoked directly
  class BreakableIterator[+A](itr: Iterator[A]) extends Iterator[A] {
    private var broken = false
    private[BreakableGenerators] def break { broken = true }

    def hasNext = !broken &amp;&amp; itr.hasNext
    def next = itr.next
  }
}
</code></pre>

<p>The approach is based on a simple subclass of <code>Iterator</code> &#8211; <code>BreakableIterator</code> &#8211; that can be halted by &#8216;breaking&#8217; it.  The function <code>breakable(&lt;traversable-object&gt;)</code> returns an Iterator over a single <code>BreakableIterator</code> object.  Iterators are monad-like structures in that they implement <code>map</code> and <code>flatMap</code>, and so its output can be used with <code>&lt;-</code> at the start of a <code>for</code> construct in the usual way.  Note that this means the result of the <code>for</code> statement will also be an Iterator.</p>

<p>Whenever the boolean expression for an <code>if</code> guard is followed by either <code>break</code> or <code>continue</code>, it is implicitly converted to a &#8220;breakable guard condition&#8221; that supports those methods.  The function <code>break</code> accepts one or more instances of <code>BreakableIterator</code>.  If it evaluates to <code>true</code>, the loops embodied by the given iterators are immediately halted via the associated <code>if</code> guard, and the iterators are halted via their <code>break</code> method.  The <code>continue</code> function is mostly syntactic sugar for a standard <code>if</code> guard, simply with the condition inverted.</p>

<p>Here is a simple example of <code>break</code> and <code>continue</code> in use:</p>

<pre><code>object Main {
  import BreakableGenerators._

  def main(args: Array[String]) {

    val r = for (
      // generate a breakable sequence from some sequential input
      loop &lt;- breakable(1 to 1000);
      // iterate over the breakable sequence
      j &lt;- loop;
      // print out at each iteration
      _ = { println(s"iteration j= $j") };
      // continue to next iteration when 'j' is even
      if { j % 2 == 0 } continue;
      // break out of the loop when 'j' exceeds 5
      if { j &gt; 5 } break(loop)
    ) yield {
      j
    }
    println(s"result= ${r.toList}")
  }
}
</code></pre>

<p>We can see from the resulting output that <code>break</code> and <code>continue</code> function in the usual way.  The <code>continue</code> clause ignores all subsequent code when <code>j</code> is even.  The <code>break</code> clause halts the loop when it sees its first value > 5, which is 7.  Only odd values &lt;= 5 are output from the <code>yield</code> statement:</p>

<pre><code>$ scalac -d /home/eje/class monadic_break.scala
$ scala -classpath /home/eje/class Main
iteration j= 1
iteration j= 2
iteration j= 3
iteration j= 4
iteration j= 5
iteration j= 6
iteration j= 7
result= List(1, 3, 5)
</code></pre>

<p>Breakable iterators can be nested in the way one would expect.  The following example shows an inner breakable loop nested inside an outer one:</p>

<pre><code>object Main {
  import BreakableGenerators._

  def main(args: Array[String]) {
    val r = for (
      outer &lt;- breakable(1 to 7);
      j &lt;- outer;
      _ = { println(s"outer  j= $j") };
      if { j % 2 == 0 } continue;
      inner &lt;- breakable(List("a", "b", "c", "d", "e"));
      k &lt;- inner;
      _ = { println(s"    inner  j= $j  k= $k") };
      if { k == "d" } break(inner);
      if { j == 5  &amp;&amp;  k == "c" } break(inner, outer)
    ) yield {
      (j, k)
    }
    println(s"result= ${r.toList}")
  }
}
</code></pre>

<p>The output demonstrates that the inner loop breaks whenever <code>k=="d"</code>, and so <code>"e"</code> is never present in the <code>yield</code> result.  When <code>j==5</code> and <code>k=="c"</code>, both the inner and outer loops are broken, and so we see that there is no <code>(5,"c")</code> pair in the result, nor does the outer loop ever iterate over 6 or 7:</p>

<pre><code>$ scalac -d /home/eje/class monadic_break.scala
$ scala -classpath /home/eje/class Main
outer  j= 1
    inner  j= 1  k= a
    inner  j= 1  k= b
    inner  j= 1  k= c
    inner  j= 1  k= d
outer  j= 2
outer  j= 3
    inner  j= 3  k= a
    inner  j= 3  k= b
    inner  j= 3  k= c
    inner  j= 3  k= d
outer  j= 4
outer  j= 5
    inner  j= 5  k= a
    inner  j= 5  k= b
    inner  j= 5  k= c
result= List((1,a), (1,b), (1,c), (3,a), (3,b), (3,c), (5,a), (5,b))
</code></pre>

<p>Using <code>break</code> and <code>continue</code> with <code>BreakableIterator</code> for sequence comprehensions is that easy.  Enjoy!</p>

<p><a name="notesname" id="notes"></a></p>

<h5>Notes</h5>

<p>The helpful community on freenode #scala made some excellent observations:</p>

<p>1: Iterators in Scala are not strictly monadic &#8211; it would be more accurate to say they&#8217;re &#8220;things with a flatMap and map method, also they can use filter or withFilter sometimes.&#8221;  However, I personally still prefer to think of them as &#8220;monadic in spirit if not law.&#8221;</p>

<p>2: The <code>break</code> function, as described in this post, is not truly functional in the sense of referential transparency, as the invocation <code>if break(loop) { condition }</code> involves a side-effect on the variable <code>loop</code>.  I would say that it does maintain &#8220;scoped functionality.&#8221;  That is, the break in non-referential transparency is scoped by the variables in question.  The <code>for</code> statement containing them is referentially transparent with respect to its inputs (provided no other code is breaking referential transparency, of course).</p>

<h5>References</h5>

<p><a name="ref1name" id="ref1">[1] </a><em><a href="http://www.manning.com/bjarnason/">Functional Programming in Scala</a></em>, Paul Chiusano and Runar Bjarnason, (section 6.6)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Faster Random Samples With Gap Sampling]]></title>
    <link href="http://erikerlandson.github.com/blog/2014/09/11/faster-random-samples-with-gap-sampling/"/>
    <updated>2014-09-11T07:57:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2014/09/11/faster-random-samples-with-gap-sampling</id>
    <content type="html"><![CDATA[<p>Generating a random sample of a collection is, logically, a O(np) operation, where (n) is the sample size and (p) is the sampling probability.  For example, extracting a random sample, without replacement, from an array might look like this in pseudocode:</p>

<pre><code>sample(data: array, p: real) {
    n = length(data)
    m = floor(p * n)
    for j = 0 to m-1 {
        k = random(j, n-1)
        swap(data[j], data[k])
    }
    emit the first m elements of 'data' to output
}
</code></pre>

<p>We can see that this sampling algorithm is indeed O(np).  However, it makes some nontrivial assumptions about its input data:</p>

<ul>
<li>It is random access</li>
<li>It is writable</li>
<li>Its size is known</li>
<li>It can be destructively modified</li>
</ul>


<p>These assumptions can be violated in several ways.  The input data might not support random access, for example it might be a list, or stream, or an iterator over the same.  We might not know its size a priori.  It might be read-only.  It might be up-cast to some superclass where knowledge about these assumed properties is no longer available.</p>

<p>In cases such as this, there is another common sampling algorithm:</p>

<pre><code>sample(data: sequence, p: real) {
    while not end(data) {
        v = next(data)
        if random(0.0, 1.0) &lt; p then emit v to output
    }
}
</code></pre>

<p>The above algorithm enjoys all the advantage in flexibility.  It requires only linear access, does not require writable input, and makes no assumptions about input size.  However it comes at a price: this algorithm is no longer O(np), it is O(n).  Each element must be traversed directly, and worse yet the random number generagor (RNG) must be invoked on each element.  O(n) invocation of the RNG is a substantial cost &#8211; random number generation is typically very expensive compared to the cost of iterating to the next element in a sequence.</p>

<p>But&#8230; does linear sampling truly require us to invoke our RNG on every element?   Consider the pattern of data access, divorced from code.   It looks like a sequence of choices: for each element we either (skip) or (sample):</p>

<pre><code>(skip) (skip) (sample) (skip) (sample) (skip) (sample) (sample) (skip) (skip) (sample) ...
</code></pre>

<p>The number of consecutive (skip) events between each (sample) &#8211; the <em>sampling gap</em> &#8211; can itself be modeled as a random variable.  Each (skip)/(sample) choice is an independent Bernoulli trial, where the probability of (skip) is (1-p).   The PMF of the sampling gap for gap of {0, 1, 2, &#8230;} is therefore a geometric distribution: P(k) = p(1-p)<sup>k</sup></p>

<p>This suggests an alternative algorithm for sampling, where we only need to randomly choose sample gaps instead of randomly choosing whether we sample each individual element:</p>

<pre><code>// choose a random sampling gap 'k' from P(k) = p(1-p)^k
// caution: this explodes for p = 0 or p = 1
random_gap(p: real) {
    u = max(random(0.0, 1.0), epsilon)
    return floor(log(u) / log(1-p))
}

sample(data: sequence, p: real) {
    advance(data, random_gap(p))
    while not end(data) {
        emit next(data) to output
        advance(data, random_gap(p))
    }
}
</code></pre>

<p>The above algorithm calls the RNG only once per actual collected sample, and so the cost of RNG calls is O(np).  Note that the algorithm is still O(n), but the cost of the RNG tends to dominate the cost of sequence traversal, and so the resulting efficiency improvement is substantial.  I measured the following performance improvements with gap sampling, compared to traditional linear sequence sampling, on a <a href="https://gist.github.com/erikerlandson/05db1f15c8d623448ff6">Scala prototype testing rig</a>:</p>

<p><head><style>
table, th, td {
border: 1px solid black;
border-collapse: collapse;
}
th, td {
padding: 10px;
}
th {
text-align: center;
}
</style></head></p>

<table>
<tr> <th>Type</th> <th>p</th> <th>linear</th> <th>gap</th> </tr>
<tr> <td>Array</td> <td>0.001</td> <td>2833</td> <td>29</td> </tr>
<tr> <td>Array</td> <td>0.01</td> <td>2825</td> <td>76</td> </tr>
<tr> <td>Array</td> <td>0.1</td> <td>2985</td> <td>787</td> </tr>
<tr> <td>Array</td> <td>0.5</td> <td>3526</td> <td>3478</td> </tr>
<tr> <td>Array</td> <td>0.9</td> <td>3023</td> <td>6081</td> </tr>
<tr> <td>List</td> <td>0.001</td> <td>2213</td> <td>230</td> </tr>
<tr> <td>List</td> <td>0.01</td> <td>2220</td> <td>265</td> </tr>
<tr> <td>List</td> <td>0.1</td> <td>2337</td> <td>796</td> </tr>
<tr> <td>List</td> <td>0.5</td> <td>2794</td> <td>3151</td> </tr>
<tr> <td>List</td> <td>0.9</td> <td>2513</td> <td>4849</td> </tr>
</table>




<br>


<p>In the results above, we see that the gap sampling times are essentially linear in (p), as expected.  In the case of the linear-access List type, there is a higher baseline time (230 vs 29) due to the constant cost of actual data traversal.  Efficiency improvements are substantial at small sampling probabilities.</p>

<p>We can also see that the cost of gap sampling begins to meet and then exceed the cost of traditinal linear sampling, in the vicinnity (p) = 0.5.  This is due to the fact that the gap sampling logic is about twice the cost (in my test environment) of simply calling the RNG once.  For example, the gap sampling invokes a call to the numeric logarithm code that isn&#8217;t required in traditional sampling.  And so at (p) = 0.5 the time spent doing the gap sampling approximates the time spent invoking the RNG once per sample, and at higher values of (p) the cost is greater.</p>

<p>This suggests that one should in fact fall back to traditional linear sampling when the sampling probability (p) >= some threshold.  That threshold appears to be about 0.5 or 0.6 in my testing rig, but is likely to depend on underlying numeric libraries, the particular RNG being used, etc, and so I would expect it to benefit from customized tuning on a per-environment basis.  With this in mind, a sample algorithm as deployed would look like this:</p>

<pre><code>// threshold is a tuning parameter
threshold = 0.5

sample(data: sequence, p: real) {
    if (p &lt; threshold) {
        gap_sample(data, p)
    } else {
        traditional_linear_sample(data, p)
    }
}
</code></pre>

<p>The gap-sampling algorithm described above is for sampling <em>without</em> replacement.   However, the same approach can be modified to generate sampling <em>with</em> replacement.</p>

<p>When sampling with replacement, it is useful to consider the <em>replication factor</em> of each element (where a replication factor of zero means the element wasn&#8217;t sampled).  Pretend for the moment that the actual data size (n) is known.  The sample size (m) = (n)(p).  The probability that each element gets sampled, per trial, is 1/n, with (m) independent trials, and so the replication factor (r) for each element obeys a binomial distribution: Binomial(m, 1/n).  If we substitute (n)(p) for (m), we have Binomial(np, 1/n).  As the (n) grows, the Binomial is <a href="http://en.wikipedia.org/wiki/Binomial_distribution#Poisson_approximation">well approximated by a Poisson distribution</a> Poisson(L), where (L) = (np)(1/n) = (p).  And so for our purposes we may sample from Poisson(p), where P(r) = (p<sup>r</sup> / r!)e<sup>(-p),</sup> for our sampling replication factors.  Note that we have now discarded any dependence on sample size (n), as we desire.</p>

<p>In our gap-sampling context, the sampling gaps are now elements whose replication factor is zero, which occurs with probability P(0) = e<sup>(-p).</sup>  And so our sampling gaps are now drawn from geometric distribution P(k) = (1-q)(q)<sup>k,</sup> where q = e<sup>(-p).</sup>   When we <em>do</em> sample an element, its replication factor is drawn from Poisson(p), however <em>conditioned such that the value is >= 1.</em>  It is straightforward to adapt a <a href="http://en.wikipedia.org/wiki/Poisson_distribution#Generating_Poisson-distributed_random_variables">standard Poisson generator</a>, as shown below.</p>

<p>Given the above, gap sampling with replacement in pseudocode looks like:</p>

<pre><code>// sample 'k' from Poisson(p), conditioned to k &gt;= 1
poisson_ge1(p: real) {
    q = e^(-p)
    // simulate a poisson trial such that k &gt;= 1
    t = q + (1-q)*random(0.0, 1.0)
    k = 1

    // continue standard poisson generation trials
    t = t * random(0.0, 1.0)
    while (t &gt; q) {
        k = k + 1
        t = t * random(0.0, 1.0)
    }
    return k
}

// choose a random sampling gap 'k' from P(k) = p(1-p)^k
// caution: this explodes for p = 0 or p = 1
random_gap(p: real) {
    u = max(random(0.0, 1.0), epsilon)
    return floor(log(u) / -p)
}

sample(data: sequence, p: real) {
    advance(data, random_gap(p))
    while not end(data) {
        rf = poisson_ge1(p)
        v = next(data)
        emit (rf) copies of (v) to output
        advance(data, random_gap(p))
    }
}
</code></pre>

<p>The efficiency improvements I have measured for gap sampling with replacement are shown here:</p>

<table>
<tr> <th>Type</th> <th>p</th> <th>linear</th> <th>gap</th> </tr>
<tr> <td>Array</td> <td>0.001</td> <td>2604</td> <td>45</td> </tr>
<tr> <td>Array</td> <td>0.01</td> <td>3442</td> <td>117</td> </tr>
<tr> <td>Array</td> <td>0.1</td> <td>3653</td> <td>1044</td> </tr>
<tr> <td>Array</td> <td>0.5</td> <td>5643</td> <td>5073</td> </tr>
<tr> <td>Array</td> <td>0.9</td> <td>7668</td> <td>8388</td> </tr>
<tr> <td>List</td> <td>0.001</td> <td>2431</td> <td>233</td> </tr>
<tr> <td>List</td> <td>0.01</td> <td>2450</td> <td>299</td> </tr>
<tr> <td>List</td> <td>0.1</td> <td>2984</td> <td>1330</td> </tr>
<tr> <td>List</td> <td>0.5</td> <td>5331</td> <td>4752</td> </tr>
<tr> <td>List</td> <td>0.9</td> <td>6744</td> <td>7811</td> </tr>
</table>




<br>


<p>As with the results for sampling without replacement, we see that gap sampling cost is linear with (p), which yields large cost savings at small sampling, but begins to exceed traditional linear sampling at higher sampling probabilities.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Scala Iterator 'drop' Method Generates a Matryoshka Class Nesting]]></title>
    <link href="http://erikerlandson.github.com/blog/2014/09/03/matryoshka-class-construction-from-the-scala-iterator-drop-method/"/>
    <updated>2014-09-03T17:23:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2014/09/03/matryoshka-class-construction-from-the-scala-iterator-drop-method</id>
    <content type="html"><![CDATA[<p>The Scala Iterator <code>drop</code> method has a complexity bug that shows up when one calls <code>drop</code> repeatedly, for example when traversing over an iterator in a loop.</p>

<p>The nature of the problem is that <code>drop</code>, under the hood, invokes <code>slice</code>, which returns a new anonymous subclass of <code>AbstractIterator</code> containing an instance of the input class, which can be seen in this <a href="https://github.com/erikerlandson/scala/blob/scala_drop_blog/src/library/scala/collection/Iterator.scala#L323">code excerpt from Iterator.scala</a>:</p>

<pre><code>def drop(n: Int): Iterator[A] = slice(n, Int.MaxValue)

// ... comments excised ...

def slice(from: Int, until: Int): Iterator[A] = {
  val lo = from max 0
  var toDrop = lo
  while (toDrop &gt; 0 &amp;&amp; self.hasNext) {
    self.next()
    toDrop -= 1
  }

  // I am a ticking quadratic time bomb:
  new AbstractIterator[A] {
    private var remaining = until - lo
    def hasNext = remaining &gt; 0 &amp;&amp; self.hasNext
    def next(): A =
      if (remaining &gt; 0) {
        remaining -= 1
        self.next()
      }
      else empty.next()
  }
}
</code></pre>

<p>In the case where one is only calling <code>drop</code> once, this is not very consequential, but when the same method is used in a loop, the nesting is repeated, generating a nesting of anonymous classes that is ever-deeper &#8211; rather like Matryoshka dolls:</p>

<p><img src="http://erikerlandson.github.com/assets/images/matryoshka.jpg" width="400"></p>

<p>This can be a substantial problem, as it generates quadratic complexity in what is logically a linear operation.  A simple example of looping code that can cause this nesting:</p>

<pre><code>def process_nth_elements[T](itr: Iterator[T], n: Int = 1) {
  var iter = itr
  while (iter.hasNext) {
    val nxt = iter.next
    // ... process next element ...

    // skip to next element
    iter = iter.drop(n-1)
    // this becomes more and more expensive as iterator classes
    // become nested deeper
  }
}
</code></pre>

<p>A simple example program, which can be <a href="https://gist.github.com/erikerlandson/a310ccd3c58a85f031dc">found here</a>, demonstrates this nesting directly:</p>

<pre><code>import java.io.{StringWriter, PrintWriter}
import scala.reflect.ClassTag

def tracehead(e: Exception, substr: String = "slice"): String = {
  val sw = new StringWriter()
  e.printStackTrace(new PrintWriter(sw))
  sw.toString.split('\n').takeWhile((s:String)=&gt; !s.contains(substr)).drop(1).mkString("\n")  
}

class TestIterator[T: ClassTag](val iter: Iterator[T]) extends Iterator[T] {
  override def hasNext = iter.hasNext
  override def next = {
    println(tracehead(new Exception))
    iter.next
  }
}

def drop_test[T](itr: Iterator[T]) {
  var n = 0
  var iter = itr
  while (iter.hasNext) {
    n += 1
    println(s"\ndrop # $n")
    iter = iter.drop(1)
  }
}
</code></pre>

<p>When the <code>drop_test</code> function is run on an instance of <code>TestIterator</code>, the stack trace output shows the Matryoshka nesting directly:</p>

<pre><code>scala&gt; drop_test(new TestIterator(List(1,2,3,4,5).iterator))

drop # 1
    at $line18.$read$$iw$$iw$$iw$$iw$TestIterator.next(&lt;console&gt;:19)

drop # 2
    at $line18.$read$$iw$$iw$$iw$$iw$TestIterator.next(&lt;console&gt;:19)
    at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)

drop # 3
    at $line18.$read$$iw$$iw$$iw$$iw$TestIterator.next(&lt;console&gt;:19)
    at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)
    at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)

drop # 4
    at $line18.$read$$iw$$iw$$iw$$iw$TestIterator.next(&lt;console&gt;:19)
    at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)
    at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)
    at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)

drop # 5
    at $line18.$read$$iw$$iw$$iw$$iw$TestIterator.next(&lt;console&gt;:19)
    at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)
    at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)
    at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)
    at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)
</code></pre>

<p>One would expect this quadratic behavior to show up in benchmarking, and it does.  Consider this simple timing test:</p>

<pre><code>def drop_time[T](itr: Iterator[T]) {
  val t0 = System.currentTimeMillis()
  var iter = itr
  while (iter.hasNext) {
    iter = iter.drop(1)
  }
  println(s"Time: ${System.currentTimeMillis() - t0}")
}
</code></pre>

<p>One would expect this function to be linear in the length of the iterator, but we see the following behavior:</p>

<pre><code>scala&gt; drop_time((1 to 5000 * 1).toList.iterator)
Time: 106

scala&gt; drop_time((1 to 5000 * 2).toList.iterator)
Time: 475

scala&gt; drop_time((1 to 5000 * 3).toList.iterator)
Time: 1108

scala&gt; drop_time((1 to 5000 * 4).toList.iterator)
Time: 2037

scala&gt; drop_time((1 to 5000 * 5).toList.iterator)
Time: 3234

scala&gt; drop_time((1 to 5000 * 6).toList.iterator)
Time: 4717

scala&gt; drop_time((1 to 5000 * 7).toList.iterator)
Time: 6447

scala&gt; drop_time((1 to 5000 * 8).toList.iterator)
java.lang.StackOverflowError
    at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)
</code></pre>

<p>The corresponding plot shows the quadratic cost:</p>

<p><img src="http://erikerlandson.github.com/assets/images/matryoshka_quadratic_plot.png" alt="&quot;image&quot;" /></p>

<p>Given the official semantics of <code>drop</code>, which state that the method invalidates the iterator it was called on, this nesting problem should be avoidable by implementing the method more like this:</p>

<pre><code>def drop(n: Int): Iterator[A] = {
  var j = 0
  while (j &lt; n) {
    this.next
    j += 1
  }
  this
}
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Implementing Parallel Prefix Scan as a Spark RDD Transform]]></title>
    <link href="http://erikerlandson.github.com/blog/2014/08/12/implementing-parallel-prefix-scan-as-a-spark-rdd-transform/"/>
    <updated>2014-08-12T11:37:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2014/08/12/implementing-parallel-prefix-scan-as-a-spark-rdd-transform</id>
    <content type="html"><![CDATA[<p>In my <a href="http://erikerlandson.github.com/blog/2014/08/09/implementing-an-rdd-scanleft-transform-with-cascade-rdds/">previous post</a>, I described how to implement the Scala <code>scanLeft</code> function as an RDD transform.  By definition <code>scanLeft</code> invokes a sequential-only prefix scan algorithm; it does not assume that either its input function <code>f</code> or its initial-value <code>z</code> can be applied in a parallel fashion.   Its companion function <code>scan</code>, however, computes a <em>parallel</em> prefix scan.  In this post I will describe an implementation of parallel prefix <code>scan</code> as an RDD transform.</p>

<p>As was the case with <code>scanLeft</code>, a basic strategy is to begin by applying <code>scan</code> to each RDD partition.  Provided that appropriate &#8220;offsets&#8221; <code>{z1, z2, ...}</code> can be computed for each partition, these can be applied to the partial, per-partition results to yield the output.   In fact, the desired <code>{z1, z2, ...}</code> are the parallel prefix scan of the last element in each per-partition scan.  The following diagram illustrates:</p>

<p><img src="http://erikerlandson.github.com/assets/images/rdd_scan/rdd_scan_4.png" alt="image" /></p>

<p>The diagram above glosses over the details of computing <code>scan</code> to obtain <code>{z1, z2, ...}</code>.   I will first describe the implementation I currently use, and then also discuss a possible alternative.  The current implementation takes the approach of encoding the <a href="http://en.wikipedia.org/wiki/Prefix_sum#Parallel_algorithm">logic of a parallel prefix scan</a> directly into an RDD computation DAG.   Each iteration, or &#8220;ply,&#8221; of the parallel algorithm is represented by an RDD.  Each element resides in its own partition, and so the computation dependency for each element is directly representable in the RDD dependency substructure.  This construction is illustrated in the following schematic (for a vector of 8 z-values):</p>

<p><img src="http://erikerlandson.github.com/assets/images/rdd_scan/rdd_scan_5.png" alt="image" /></p>

<p>The parallel prefix scan algorithm executes O(log(n)) plies, which materializes as O(log(n)) RDDs shown in the diagram above.  In this context, (n) is the number of input RDD <em>partitions</em>, not to be confused with the number of data rows in the RDD.   There are O((n)log(n)) partitions, each having a single row containing the z-value for a corresponding output partition.   Some z-values are determined earlier than others.  For example z1 is immediately available in ply(0), and ply(3) can refer directly back to that ply(0) partition in the interest of efficiency, as called out by the red DAG arcs.</p>

<p>This scheme allows each final output partition to obtain its z-value directly from a single dedicated partition, which ensures that minimal data needs to be transferred across worker processes.  Final output partitions can be computed local to their corresponding input partitions.  Data transfer may be limited to the intermediate z-values, which are small single-row affairs by construction.</p>

<p>The code implementing the logic above can be <a href="https://github.com/erikerlandson/spark/blob/rdd_scan_blog/core/src/main/scala/org/apache/spark/rdd/ScanRDDFunctions.scala#L161">viewed here.</a></p>

<p>I will conclude by noting that there is an alternative to this highly distributed computation of <code>{z1, z2, ...}</code>, which is to collect the last-values in the per-partition intermediate scan ouputs into a single array, and run <code>scan</code> directly on that array.   This has the advantage of avoiding the construction of log(n) intermediate RDDs.   It does, however, require a monolithic &#8216;fan-in&#8217; of data into a single RDD to receive the collection of values.  That is followed by a fan-out of the array, where each output partition picks its single z-value from the array.  It is for this reason I suspect this alternative incurs substantially more transfer overhead across worker processes.  However, one might also partition the resulting z-values in some optimal way, so that each final output partition needs to request only the partition that contains its z-value.  Future experimentation might show that this can out-perform the current fully-distributed implementation.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Implementing an RDD scanLeft Transform With Cascade RDDs]]></title>
    <link href="http://erikerlandson.github.com/blog/2014/08/09/implementing-an-rdd-scanleft-transform-with-cascade-rdds/"/>
    <updated>2014-08-09T09:10:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2014/08/09/implementing-an-rdd-scanleft-transform-with-cascade-rdds</id>
    <content type="html"><![CDATA[<p>In Scala, sequence (and iterator) data types support the <code>scanLeft</code> method for computing a sequential prefix scan on sequence elements:</p>

<pre><code>// Use scanLeft to compute the cumulative sum of some integers
scala&gt; List(1, 2, 3).scanLeft(0)(_ + _)
res0: List[Int] = List(0, 1, 3, 6)
</code></pre>

<p>Spark RDDs are logically a sequence of row objects, and so <code>scanLeft</code> is in principle well defined on RDDs.  In this post I will describe how to cleanly implement a <code>scanLeft</code> RDD transform by applying an RDD variation called Cascade RDDs.</p>

<p>A Cascade RDD is an RDD having one partition which is a function of an input RDD partition and an optional predecessor Cascade RDD partition.  You can see that this definition is somewhat recursive, where the basis case is a Cascade RDD having no precedessor.  The following diagram illustrates both cases of Cascade RDD:</p>

<p><img src="http://erikerlandson.github.com/assets/images/rdd_scanleft/rdd_scan_1.png" alt="image" /></p>

<p>As implied by the above diagram, a series of Cascade RDDs falling out of an input RDD will have as many Cascade RDDs as there are input partitions.  This situation begs for an abstraction to re-assemble the cascade back into a single output RDD, and so the method <code>cascadePartitions</code> is defined, as illustrated:</p>

<p><img src="http://erikerlandson.github.com/assets/images/rdd_scanleft/rdd_scan_3.png" alt="image" /></p>

<p>The <code>cascadePartitions</code> method takes a function argument <code>f</code>, with the signature:</p>

<pre><code>f(input: Iterator[T], cascade: Option[Iterator[U]]): Iterator[U]
</code></pre>

<p>in a manner somewhat analogous to <code>mapPartitions</code>.  The function <code>f</code> must address the fact that <code>cascade</code> is optional and will be <code>None</code> in case where there is no predecessor Cascade RDD.  The interested reader can examine the details of how the <code>CascadeRDD</code> class and its companion method <code>cascadePartitions</code> are <a href="https://github.com/erikerlandson/spark/blob/rdd_scan_blog/core/src/main/scala/org/apache/spark/rdd/CascadeRDDFunctions.scala">implemented here.</a></p>

<p>With Cascade RDDs it is now straightforward to define a <code>scanLeft</code> transform for RDDs.  We wish to run <code>scanLeft</code> on each input partition, with the condition that we want to start where the previous input partition left off.  The Scala <code>scanLeft</code> function makes this easy, as the starting point is its first parameter (z): <code>scanLeft(z)(f)</code>.  The following figure illustrates what this looks like:</p>

<p><img src="http://erikerlandson.github.com/assets/images/rdd_scanleft/rdd_scan_2.png" alt="image" /></p>

<p>As the above schematic demonstrates, almost all the work is accomplished with a single call to <code>cascadePartitions</code>, using a thin wrapper around <code>f</code> which determines where to start the next invocation of Scala <code>scanLeft</code> &#8211; either the input parameter <code>z</code>, or the last output element of the previous cascade.   One final transform must be applied to remove the initial element that Scala <code>scanLeft</code> inserts into its output, excepting the first output partition, where it is kept to be consistent with the <code>scanLeft</code> definition.</p>

<p>All computation is accomplished in the standard RDD formalism, and so <code>scanLeft</code> is a proper lazy RDD transform.</p>

<p>The actual implementation is as compact as the above description implies, and you can see the <a href="https://github.com/erikerlandson/spark/blob/rdd_scan_blog/core/src/main/scala/org/apache/spark/rdd/ScanRDDFunctions.scala#L144">code here.</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Deferring Spark Actions to Lazy Transforms With the Promise RDD]]></title>
    <link href="http://erikerlandson.github.com/blog/2014/07/29/deferring-spark-actions-to-lazy-transforms-with-the-promise-rdd/"/>
    <updated>2014-07-29T13:53:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2014/07/29/deferring-spark-actions-to-lazy-transforms-with-the-promise-rdd</id>
    <content type="html"><![CDATA[<p>In a <a href="http://erikerlandson.github.io/blog/2014/07/27/some-implications-of-supporting-the-scala-drop-method-for-spark-rdds/">previous post</a> I described a method for implementing the Scala <code>drop</code> transform for Spark RDDs.  That implementation came at a cost of subverting the RDD lazy transform model; it forced the computation of one or more input RDD partitions at call time instead of deferring partition computation, and so behaved more like a Spark action than a transform.</p>

<p>In this followup post I will describe how to implement <code>drop</code> as a true lazy RDD transform, using a new RDD subclass: the Promise RDD.  A Promise RDD can be used to embed computations in the lazy transform formalism that otherwise would require non-lazy actions.</p>

<p>The Promise RDD (aka <code>PromiseRDD</code> subclass) is designed to encapsulate a single expression value in an RDD having exactly one row, to be evaluated <em>only</em> if and when its single partition is computed. It behaves somewhat analogously to a Scala <code>promise</code> structure, as it abstracts the expression such that any requests for its value (and hence its actual computation) may be deferred.</p>

<p>The definition of PromiseRDD is compact:</p>

<pre><code>class PromisePartition extends Partition {
  // A PromiseRDD has exactly one partition, by construction:
  override def index = 0
}

/**
 * A way to represent the concept of a promised expression as an RDD, so that it
 * can operate naturally inside the lazy-transform formalism
 */
class PromiseRDD[V: ClassTag](expr: =&gt; (TaskContext =&gt; V),
                              context: SparkContext, deps: Seq[Dependency[_]])
  extends RDD[V](context, deps) {

  // This RDD has exactly one partition by definition, since it will contain
  // a single row holding the 'promised' result of evaluating 'expr' 
  override def getPartitions = Array(new PromisePartition)

  // compute evaluates 'expr', yielding an iterator over a sequence of length 1:
  override def compute(p: Partition, ctx: TaskContext) = List(expr(ctx)).iterator
}
</code></pre>

<p>A PromiseRDD is constructed with the expression of choice, embodied as a function from a <code>TaskContext</code> to the implied expression type.   Note that <em>only</em> the task context is a parameter;  Any other inputs needed to evaluate the expression must be present in the closure of <code>expr</code>.  This allows the expression to be of very general form: its value may depend on a single input RDD, or multiple RDDs, or no RDDs at all.  It receives an arbitrary sequence of partition dependencies which is the responsibility of the calling code to assemble.  Again, this allows substantial generality in the form of the expression: the PromiseRDD dependencies can correspond to any arbitrary input dependencies assumed by the expression.  The dependencies can be tuned to exactly what input partitions are required.</p>

<p>As a motivating example, consider how a PromiseRDD can be used to promote <code>drop</code> to a true lazy transform.  The aspect of computing <code>drop</code> that threatens laziness is the necessity of determining the location of the boundary partition (<a href="http://erikerlandson.github.io/blog/2014/07/27/some-implications-of-supporting-the-scala-drop-method-for-spark-rdds/">see previous discussion</a>).  However, this portion of the computation can in fact be encapsulated in a PromiseRDD.  The details of constructing such a PromiseRDD can be <a href="https://github.com/erikerlandson/spark/blob/promise_rdd_blog/core/src/main/scala/org/apache/spark/rdd/DropRDDFunctions.scala#L46">viewed here</a>.  The following illustration summarizes the topology of the dependency DAG that is constructed:</p>

<p><img src="http://erikerlandson.github.com/assets/images/rdd_drop/rdd_drop_promise.png" alt="image" /></p>

<p>As the dependency diagram shows, the PromiseRDD responsible for locating the boundary partition depends on each partition of the original input RDD.  The actual computation is likely to only request the first input partition, but all partitions might be required to handle all possible arguments to <code>drop</code>.   In turn, the location information given by the PromiseRDD is depended upon by each output partition.  Input partitions are either passed to the output, or used to compute the boundary, and so none of the partition computation is wasted.</p>

<p>Observe that the scheduler remains in charge of when partitions are computed.  An advantage to using a PromiseRDD is that it works within Spark&#8217;s computational model, instead of forcing it.</p>

<p>The following brief example demonstrates that <code>drop</code> implemented using a PromiseRDD satisfies the lazy transform model:</p>

<pre><code>// create data rdd with values 0 thru 9
scala&gt; val data = sc.parallelize(0 until 10)
data: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at &lt;console&gt;:12

// drop the first 3 rows
// note that no action is performed -- this transform is lazy
scala&gt; val rdd = data.drop(3)
rdd: org.apache.spark.rdd.RDD[Int] = $anon$1[2] at drop at &lt;console&gt;:14

// collect the values.  This action kicks off job scheduling and execution
scala&gt; rdd.collect
14/07/28 12:16:13 INFO SparkContext: Starting job: collect at &lt;console&gt;:17
... job scheduling and execution output ...

res0: Array[Int] = Array(3, 4, 5, 6, 7, 8, 9)

scala&gt;
</code></pre>

<p>In this post, I have described the Promise RDD, an RDD subclass that can be used to encapsulate computations in the lazy transform formalism that would otherwise require non-lazy actions.  As an example, I have outlined a lazy transform implementation of <code>drop</code> that uses PromiseRDD.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Some Implications of Supporting the Scala drop Method for Spark RDDs]]></title>
    <link href="http://erikerlandson.github.com/blog/2014/07/27/some-implications-of-supporting-the-scala-drop-method-for-spark-rdds/"/>
    <updated>2014-07-27T17:08:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2014/07/27/some-implications-of-supporting-the-scala-drop-method-for-spark-rdds</id>
    <content type="html"><![CDATA[<p>In Scala, sequence data types support the <code>drop</code> method for skipping (aka &#8220;dropping&#8221;) the first elements of the sequence:</p>

<pre><code>// drop the first element of a list
scala&gt; List(1, 2, 3).drop(1)
res1: List[Int] = List(2, 3)
</code></pre>

<p>Spark RDDs also support various standard sequence methods, for example <code>filter</code>, as they are logically a sequence of row objects.  One might suppose that <code>drop</code> could be a useful sequence method for RDDs, as it would support useful idioms like:</p>

<pre><code>// Use drop (hypothetically) to skip the header of a text file:
val data = sparkContext.textFile("data.txt").drop(1)
</code></pre>

<p>Implementing <code>drop</code> for RDDs is possible, and in fact can be done with a <a href="https://github.com/erikerlandson/spark/compare/erikerlandson:rdd_drop_blogpost_base...rdd_drop_blogpost">small amount of code</a>, however it comes at the price of an impact to the RDD lazy computing model.</p>

<p>To see why, recall that RDDs are composed of partitions, and so in order to drop the first (n) rows of an RDD, one must first identify the partition that contains the (n-1),(n) row boundary.  In the resulting RDD, this partition will be the first one to contain any data.  Identifying this &#8220;boundary&#8221; partition cannot have a closed-form solution, because partition sizes are not in general equal;  the partition interface does not even support the concept of a <code>count</code> method.  In order to obtain the size of a partition, one is forced to actually compute its contents.  The diagram below illustrates one example of why this is so &#8211; the contents of the partitions in the filtered RDD on the right cannot be known without actually running the filter on the parent RDD:</p>

<p><img src="http://erikerlandson.github.com/assets/images/rdd_drop/rdd-drop-1.png" alt="image" /></p>

<p>Given all this, the structure of a <code>drop</code> implementation is to compute the first partition, find its length, and see if it contains the requested (n-1),(n) boundary.  If not, compute the next partition, and so on, until the boundary partition is identified.  All prior partitions are ignored in the result.  All subsequent partitions are passed on with no change.  The boundary partition is passed through its own <code>drop</code> to eliminate rows up to (n).</p>

<p>The code implementing the concept described above can be viewed here:
<a href="https://github.com/erikerlandson/spark/compare/erikerlandson:rdd_drop_blogpost_base...rdd_drop_blogpost">https://github.com/erikerlandson/spark/compare/erikerlandson:rdd_drop_blogpost_base&#8230;rdd_drop_blogpost</a></p>

<p>The following diagram illustrates the relation between input and output partitions in a call to <code>drop</code>:</p>

<p><img src="http://erikerlandson.github.com/assets/images/rdd_drop/rdd-drop-2.png" alt="image" /></p>

<p>Arguably, this represents a potential subversion of the RDD lazy compute model, as it forces the computation of at least one (and possibly more) partitions.  It behaves like a &#8220;partial action&#8221;, instead of a transform, but an action that returns another RDD.</p>

<p>In many cases, the impact of this might be relatively small.  For example, dropping the first few rows in a text file is likely to only force computation of a single partition, and it is a partition that will eventually be computed anyway.  Furthermore, such a use case is generally not inside a tight loop.</p>

<p>However, it is not hard to construct cases where computing even the first partition of one RDD recursively forces the computation of <em>all</em> the partitions in its parents, as in this example:</p>

<p><img src="http://erikerlandson.github.com/assets/images/rdd_drop/rdd-drop-3.png" alt="image" /></p>

<p>Whether the benefits of supporting <code>drop</code> for RDDs outweigh the costs is an open question.  It is likely to depend on whether or not the Spark community yields any compelling use cases for <code>drop</code>, and whether a transform that behaves like a &#8220;partial action&#8221; is considered an acceptable addition to the RDD formalism.</p>

<p>RDD support for <code>drop</code> has been proposed as issue <a href="https://issues.apache.org/jira/browse/SPARK-2315">SPARK-2315</a>, with corresponding pull request <a href="https://github.com/apache/spark/pull/1254/">1254</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Bi-directional Variation of the O(NP) Edit Distance Algorithm]]></title>
    <link href="http://erikerlandson.github.com/blog/2014/02/20/a-bi-directional-variation-of-the-o-np-edit-distance-algorithm/"/>
    <updated>2014-02-20T19:51:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2014/02/20/a-bi-directional-variation-of-the-o-np-edit-distance-algorithm</id>
    <content type="html"><![CDATA[<p>The O(ND) edit distance algorithm <a href="#ref1">[1]</a> is a standard for efficient computation of the edit distance between two sequences, appearing in applications such as the GNU diff tool.  There is also a variation <a href="#ref2">[2]</a> that operates in O(NP) time, where P is the number of deletions in the shortest edit path, and which has lower computational complexity, since P &lt;= D (and may be &lt;&lt; D in some circumstances).  In order to apply these algorithms to obtain an <em>edit script</em> in linear space, they must be adapted into a bidirectional form that enables recursive divide-and-conquer.   The basic principles of a bidirectional adaptation of the O(ND) algorithm are described in <a href="#ref1">[1]</a>.   However, no such discussion of a bidirectional O(NP) algorithm is provided in <a href="#ref2">[2]</a>.  Understanding this adaptation involves some observations that aren&#8217;t immediately obvious.  In this post, I will describe these key observations.</p>

<h3>Notation</h3>

<p>My code segments are written as C/C++, however written in a simplified style I hope will be clear regardless of what languages the reader is familiar with.  If you wish to port this (pseudo-ish)code, it may be worth keeping in mind that indexing is zero-based in C/C++.</p>

<h3>Sequence Lengths</h3>

<p>A brief note on the O(NP) algorithm and sequence lengths: the algorithm assumes that the length of its second sequence argument is >= its first (that is, N >= M).   In the following discussions, I will be making the same assumption, however the modification to address N &lt; M is relatively easy, and can be seen in the references to actual source code below.</p>

<h3>Indexing</h3>

<p>A note on naming:  In <a href="#ref2">[2]</a>, the authors use &#8216;fp&#8217; for the name of the array holding path endpoints.  I will use &#8216;Vf&#8217; for the array holding forward endpoints, and &#8216;Vr&#8217; for the corresponding array holding reverse endpoints.</p>

<p>The O(ND) and O(NP) algorithms operate by iteratively extending the frontier of edit paths through the implicit graph of possible paths, where each iteration is computed as a function of the previous.  In the O(NP) algorithm, this computation has to proceed from the outside in, as described in the paper:</p>

<pre><code>for (k = -P;  k &lt; delta;  k += 1) {
    y = max(Vf[k-1] + 1, Vf[k+1]);
    Vf[k] = snake(y-k, y);
}
for (k = P + delta;  k &gt;= delta;  k -= 1) {
    y = max(Vf[k-1] + 1, Vf[k+1]);
    Vf[k] = snake(y-k, y);
}
</code></pre>

<p>In order to implement a bi-directional algorithm, we must also run the algorithm in reverse, beginning at the &#8220;lower right corner&#8221; of the graph (M,N) and working backward to the origin (0,0).  The indexing is the mirror image of the above:</p>

<pre><code>for (k = P+delta;  k &gt; 0;  k -= 1) {
    y = min(Vr[k-1], Vr[k+1] - 1);
    Vr[k] = rsnake(y-k, y);
}
for (k = -P;  k &lt;= 0;  k += 1) {
    y = min(Vr[k-1], Vr[k+1] - 1);
    Vr[k] = rsnake(y-k, y);
}
</code></pre>

<p>In the above, &#8216;rsnake&#8217; is the reverse-direction snake function.  A note on initialization:  whereas the forward algorithm initializes its Vf array to (-1), the symmetric initial value for the reverse algorithm Vr array is (N+1) (In the general case, 1 plus the length of the longest sequence).</p>

<h3>Detecting Path Overlap</h3>

<p>The uni-directional O(NP) algorithm halts when Vf[delta] == N.  However, the bi-directional algorithms halt when shortest opposing paths meet &#8211; or overlap &#8211; each other, as described in the O(ND) paper <a href="#ref1">[1]</a>.  The semantics of storing paths in working arrays is the same in both algorithms, with the exception that in the O(NP) algorithm it is the (y) values that are stored.  Myers describes the predicate for detecting meeting paths in O(ND) as: (x >= u)  &amp;&amp;  (x-y == u-v), where (x,y) are forward endpoints and (u,v) are reverse endpoints.  Observe that since y = x-k, then (x-y == u-v) is equivalent to &#8220;forward-k == reverse-k&#8221;.  However, in operation one always checks the opposing path with the <em>same</em> k index, and so this clause is redundant.  It is sufficient to check that (x >= u), or in the case of O(NP), that (y >= v).  In the code, this looks something like:</p>

<pre><code>y = max(Vf[k-1] + 1, Vf[k+1]);
if (y &gt;= Vr[k]) {
    // overlapping paths detected 
}
</code></pre>

<p>The other checks for forward and reverse are similar.  Note that these checks happen at the <em>beginning</em> of each &#8216;snake&#8217;, that is prior to invoking the snake extension logic.  The semantic is that the opposing path overlaps the run (snake) one is about to start.</p>

<h3>Computing Distance</h3>

<p>When two overlapping paths are detected, we must compute the path distance associated with their union.  In the O(ND) algorithm, we know that distance implicitly, as the paths are extended over successive iterations of D.  In the O(NP) algorithm, however, the current path endpoints are associated with a particular value of P, and so we must consider how to obtain the actual distance.</p>

<p>A little algebra comes to the rescue.  At iteration P, consider the number of deletions along the forward-path at the kth endpoint, which I will denote as &#8216;vf&#8217; (the authors refer to it as V(x,y)).  In <a href="#ref2">[2]</a>, the authors show that P == vf when k &lt; delta, and P == vf+k-delta, when k > delta (note that either formula applies for k == delta).  Solving for vf, we have:   vf == P for k &lt; delta and vf == P+delta-k for k > delta.  The authors also show that: vf = (df-k)/2, where df is the total edit distance along the path up to the current endpoint (the authors refer to df as D(x,y)).   Therefore, we have: df = 2(vf)+k, where we can obtain vf from the expression we just derived.</p>

<p>It remains to derive the expressions for the reverse direction, where we want &#8216;vr&#8217; and &#8216;dr&#8217;.  Here, I note that the mirror-image indexing of the reverse algorithm implies that the expressions above work if we transform k &#8211;> delta-k.  Making that transform gives us:   vr == P for k > 0 and vr == P+k for k &lt; 0 (again, either applies for k == 0).  And dr = 2(vr)+delta-k.</p>

<p>And so the actual edit distance covered by our overlapping paths is:  d == (df+dr) == 2(vf+vr)+delta.  Note now pleasing this is, as vf+vr is the number of deletions of the combined paths, and so this corresponds to the original formula D == 2P+delta, where P is the number of deletions over the entire pathway.  We also see from the above that at a given Pth iteration, P does <em>not</em> equal the number of deletions in all paths with endpoints at the current iteration.  The true number of deletions for a given endpoint is a function of P, k and delta.</p>

<p>A note on implementation: when one is advancing forward paths, an overlapping reverse-path will be from previous iteration (P-1), as the reverse paths for (P) have not happened yet.  That will show up in the distance formula for (vr) by using (P-1) in place of P, as in this example code:</p>

<pre><code>y = max(Vf[k-1] + 1, Vf[k+1]);
if (y &gt;= Vr[k]) {
    // we found overlapping path, so compute corresponding edit distance
    vf = (k&gt;delta) ? (P + delta - k) : P;
    // use (P-1) for reverse paths:
    vr = (k&lt;0) ? (P-1 + k) : P-1;
    d = 2*(vf+vr)+delta;
}

// ....

y = min(Vr[k-1], Vr[k+1] - 1);
if (y &lt;= Vf[k]) {
    // we can use P for both since forward-paths have been advanced:
    vf = (k&gt;delta) ? (P + delta - k) : P;
    vr = (k&lt;0) ? (P + k) : P;
    d = 2*(vf+vr)+delta;
}
</code></pre>

<h3>Shortest Path</h3>

<p>With respect to halting conditions, the O(NP) algorithm differs in one imporant way from the O(ND) algorithm: The O(ND) algorithm maintains path endpoints corresponding to increasing <em>distance</em> (D) values.  Therefore, when two paths meet, they form a shortest-distance path by definition, and the algorithm can halt on the first such overlap it detects.</p>

<p>The same is <em>not true</em> for the O(NP) algorithm.  It stores endpoints at a particular P value.  However, at a given value of P, actual <em>distances</em> may vary considerably.  On a given iteration over P, actual path distances may vary from 2(P-1)+delta up to 4P+delta.</p>

<p>This problem is dealt with by maintaining a best-known distance, &#8216;Dbest&#8217;, which is initialized to its maximum possible value of N+M, the sum of both sequence lengths.  Whenever two overlapping paths are detected, their corresponding distance &#8216;d&#8217; is computed as described earlier, and the running minimum is maintainted:  Dbest = min(Dbest,d).  As mentioned above, we know that the mimimum possible distance at a given iteration is Dmin = 2(P-1)+delta, and so when Dmin >= Dbest, we halt and return Dbest as our result.</p>

<h3>Loop Bounding</h3>

<p>Some important computational efficiency can be obtained by reorganizing the looping over the endpoints.   As mentioned above, conceptually the looping proceeds from the outside, inward.  Suppose we organize the looping over k values such that we explore k = {-P, P+delta, -P+1, P+delta-1, -P+2, P+delta-2 &#8230; }  Note that the symmetry breaks a bit when we get to k==delta, as here we stop iterating backward, but continue iterating forward until we hit delta from below.  In the code, this looping pattern looks something like:</p>

<pre><code>// advance forward paths: reverse path looping is similar
for (ku = -P, kd = P+delta;  ku &lt;= delta;  ku += 1) {
    // advance diagonals from -P, upwards:
    y = max(1+Vf[ku-1], Vf[ku+1]);

    // check for overlapping path

    Vf[ku] = snake(y-ku, y);

    // stop searching backward past here:
    if (kd &lt;= delta) continue;

    // advance diagonals from P+delta, downwards:
    y = max(1+Vf[kd-1], Vf[kd+1]);

    // check for overlapping path

    Vf[kd] = snake(y-kd, y);
    kd -= 1;
}
</code></pre>

<p>There is method to this madness.  Observe that for any particular P value, the smallest edit distances are at the outside, and get larger as one moves inward.  The minimum distance 2P+delta is always when k == -P, and k == P+delta.  As we proceed inward, the corresponding edit distance increases towards its maximum of 4P+delta.   This allows <em>two</em> optimizations.  The first is that if we hit an overlapping path, we can now exit the loop immediately, as we know that any other such overlapping paths to our inside will have a larger edit distance, and so do not need to be considered.</p>

<p>The second optimization is to recall that path distances are a function of P, k and delta.  We can use this information to solve for k and obtain a useful adaptive bound on how far we loop.  From previous sections, also recall we are keeping a best-known distance Dbest.  We know that we do not have to explore any paths whose distance is >= Dbest.  So, we can set up the following inequality: 2(vf+vr)+delta &lt; Dbest, where vf = P, and vr = (P-1)+k, where k &lt; 0, which is the region where distance is growing.  Therefore, we have 2(P+(P-1)+k)+delta &lt; Dbest.  Solving for k, we have:  k &lt; ((Dbest-delta)/2)-2P+1.  The looping wants to use &#8216;&lt;=&#8217;, so we can rewrite as: k &lt;= ((Dbest-delta-1)/2)-2P+1.  For the reverse-path looping, we can set up a similar inequality:  2(P+P+delta-k)+delta &lt; Dbest, which yields:  k >= ((1+delta-Dbest)/2)+delta+2P.</p>

<p>Note that if these bound expressions evaluate to a value past the nominal bound, then the nominal bound remains in effect: e.g. the operative forward looping bound = min(delta, ((Dbest-delta)/2)-2P).   Also note that these constraints do not break the computation of the endpoints, because when the bounds move, they always retreat toward the outside by 2 on each iteration of P.  Since computation proceeds outside in, that means the necessary values are always correctly populated from the previous iteration.</p>

<p>In the code, the forward path looping looks like this:</p>

<pre><code>// compute our adaptive loop bound (using P-1 for reverse)
bound = min(delta, ((Dbest-delta-1)/2)-(2*P)+1);

// constrain our search by bound:
for (ku = -P, kd = P+delta;  ku &lt;= bound;  ku += 1) {
    y = max(1+Vf[ku-1], Vf[ku+1]);
    if (y &gt;= Vr[k]) {
        vf = (k&gt;delta) ? (P + delta - k) : P;
        vr = (k&lt;0) ? (P-1 + k) : P-1;

        // maintain minimum distance:
        Dbest = min(Dbest, 2*(vf+vr)+delta);

        // we can now halt this loop immediately:
        break;
    }

    Vf[ku] = snake(y-ku, y);

    if (kd &lt;= delta) continue;

    y = max(1+Vf[kd-1], Vf[kd+1]);
    if (y &gt;= Vr[k]) {
        vf = (k&gt;delta) ? (P + delta - k) : P;
        vr = (k&lt;0) ? (P-1 + k) : P-1;

        // maintain minimum distance:
        Dbest = min(Dbest, 2*(vf+vr)+delta);

        // we can now halt this loop immediately:
        break;
    }

    Vf[kd] = snake(y-kd, y);
    kd -= 1;
}
</code></pre>

<h3>Implementation</h3>

<p>In conclusion, I will display a code segment with all of the ideas presented above, coming together.  This segment was taken from my <a href="https://github.com/erikerlandson/algorithm/blob/order_np_alg/include/boost/algorithm/sequence/detail/edit_distance.hpp#L342">working prototype code</a>, with some syntactic clutter removed and variable names changed to conform a bit more closely to <a href="#ref2">[2]</a>.  The implementation of O(NP) below is performing about 25% faster than the corresponding O(ND) algorithm in my benchmarking tests, and also uses substantially less memory.</p>

<pre><code>// initialize this with the maximum possible distance:
Dbest = M+N;

P = 0;
while (true) {
    // the minimum possible distance for the current P value
    Dmin = 2*(P-1) + delta;

    // if the minimum possible distance is &gt;= our best-known distance, we can halt
    if (Dmin &gt;= Dbest) return Dbest;

    // adaptive bound for the forward looping
    bound = min(delta, ((Dbest-delta-1)/2)-(2*P)+1);

    // advance forward diagonals
    for (ku = -P, kd = P+delta;  ku &lt;= bound;  ku += 1) {
        y = max(1+Vf[ku-1], Vf[ku+1]);
        x = y-ku;

        // path overlap detected
        if (y &gt;= Vr[ku]) {
            vf = (ku&gt;delta) ? (P + delta - ku) : P;
            vr = (ku&lt;0) ? (P-1 + ku) : P-1;
            Dbest = min(Dbest, 2*(vf+vr)+delta);
            break;
        }

        // extend forward snake
        if (N &gt;= M) {
            while (x &lt; M  &amp;&amp;  y &lt; N  &amp;&amp;  equal(S1[x], S2[y])) { x += 1;  y += 1; }
        } else {
            while (x &lt; N  &amp;&amp;  y &lt; M  &amp;&amp;  equal(S1[y], S2[x])) { x += 1;  y += 1; }
        }

        Vf[ku] = y;

        if (kd &lt;= delta) continue;

        y = max(1+Vf[kd-1], Vf[kd+1]);
        x = y-kd;

        // path overlap detected
        if (y &gt;= Vr[kd]) {
            vf = (kd&gt;delta) ? (P + delta - kd) : P;
            vr = (kd&lt;0) ? (P-1 + kd) : P-1;
            Dbest = min(Dbest, 2*(vf+vr)+delta);
            break;
        }

        // extend forward snake
        if (N &gt;= M) {
            while (x &lt; M  &amp;&amp;  y &lt; N  &amp;&amp;  equal(S1[x], S2[y])) { x += 1;  y += 1; }
        } else {
            while (x &lt; N  &amp;&amp;  y &lt; M  &amp;&amp;  equal(S1[y], S2[x])) { x += 1;  y += 1; }
        }

        Vf[kd] = y;
        kd -= 1;
    }

    // adaptive bound for the reverse looping
    bound = max(0, ((1+delta-Dbest)/2)+delta+(2*P));

    // advance reverse-path diagonals:
    for (kd=P+delta, ku=-P;  kd &gt;= bound;  kd -= 1) {
        y = min(Vr[kd-1], Vr[kd+1]-1);
        x = y-kd;

        // path overlap detected
        if (y &lt;= Vf[kd]) {
            vf = (kd&gt;delta) ? (P + delta - kd) : P;
            vr = (kd&lt;0) ? (P + kd) : P;
            Dbest = min(Dbest, 2*(vf+vr)+delta);
            break;
        }

        // extend reverse snake
        if (N &gt;= M) {
            while (x &gt; 0  &amp;&amp;  y &gt; 0  &amp;&amp;  equal(S1[x-1], S2[y-1])) { x -= 1;  y -= 1; }
        } else {
            while (x &gt; 0  &amp;&amp;  y &gt; 0  &amp;&amp;  equal(S1[y-1], S2[x-1])) { x -= 1;  y -= 1; }
        }

        Vr[kd] = y;

        if (ku &gt;= 0) continue;

        y = min(Vr[ku-1], Vr[ku+1]-1);
        x = y-ku;

        // path overlap detected
        if (y &lt;= Vf[ku]) {
            vf = (ku&gt;delta) ? (P + delta - ku) : P;
            vr = (ku&lt;0) ? (P + ku) : P;
            Dbest = min(Dbest, 2*(vf+vr)+delta);
            break;
        }

        // extend reverse snake
        if (N &gt;= M) {
            while (x &gt; 0  &amp;&amp;  y &gt; 0  &amp;&amp;  equal(S1[x-1], S2[y-1])) { x -= 1;  y -= 1; }
        } else {
            while (x &gt; 0  &amp;&amp;  y &gt; 0  &amp;&amp;  equal(S1[y-1], S2[x-1])) { x -= 1;  y -= 1; }
        }

        Vr[ku] = y;
        ku += 1;
    }
}
</code></pre>

<h3>References</h3>

<p><a name="anchor1" id="ref1">[1] </a><a href="http://www.xmailserver.org/diff2.pdf">An O(ND) Difference Algorithm and its Variations</a>, Eugene W. Myers<br>
<a name="anchor2" id="ref2">[2] </a><a href="http://www.itu.dk/stud/speciale/bepjea/xwebtex/litt/an-onp-sequence-comparison-algorithm.pdf">An O(NP) Sequence Comparison Algorithm</a>, Sun Wu, Udi Manber, Gene Myers</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Impact of Negotiator Cycle Cadence on Slot Loading]]></title>
    <link href="http://erikerlandson.github.com/blog/2013/03/21/the-impact-of-negotiator-cycle-cadence-on-slot-loading/"/>
    <updated>2013-03-21T15:10:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2013/03/21/the-impact-of-negotiator-cycle-cadence-on-slot-loading</id>
    <content type="html"><![CDATA[<p>The <a href="http://research.cs.wisc.edu/htcondor/manual/v7.8/3_1Introduction.html#8555">HTCondor negotiator</a> assigns jobs (resource requests) to slots (compute resources) at regular intervals, configured by the <a href="http://research.cs.wisc.edu/htcondor/manual/v7.8/3_3Configuration.html#20544">NEGOTIATOR_INTERVAL</a> parameter.  This interval (the cycle <em>cadence</em>) has a fundamental impact on a pool <em>loading factor</em> &#8211; the fraction of time that slots are being productively utilized.</p>

<p>Consider the following diagram, which illustrates the utilization of a slot over the lifetime of a job.  When a job completes, its slot will remain empty until it can be assigned a new job on the next negotiation cycle.</p>

<p><img src="http://erikerlandson.github.com/assets/images/slot_load_study/loading_factor_diagram.png" width="750"></p>

<p>As the diagram above shows, the loading factor for a slot can be expressed as D/Z, where D is the duration of the job, and Z is the total time until the next cycle occurring after the job completes.  We can also write Z = D+I, where I is the &#8220;idle time&#8221; from job completion to the start of the next negotiation cycle.   Loading factor is always &lt;= 1, where a value of 1 corresponds to ideal loading &#8211; every slot is utilized 100% of the time.  In general, loading will be &lt; 1, as jobs rarely complete exactly on a cycle boundary.</p>

<p>It is worth briefly noting that the <a href="http://research.cs.wisc.edu/htcondor/manual/v7.8/3_3Configuration.html#18202">claim reuse</a> feature was developed to help address this problem.  However, claim re-use is not compatible with all other features &#8211; for example enabling claim re-use can cause accounting group starvation &#8211; and so what follows remains relevant to many HTCondor configurations.</p>

<p>Given a particular negotiation cycle cadence, how does a slot&#8217;s loading factor behave, as a function of job duration?  The loading factor can be expressed as:</p>

<div markdown="0">
&#92;[
&#92;text{Loading Factor} = &#92;frac{D}{C &#92;left( q + &#92;lceil r &#92;rceil &#92;right)} &#92;&#92;
 &#92;&#92;
&#92;text{where:} &#92;&#92;
D = &#92;text{job duration} &#92;&#92;
C = &#92;text{cycle cadence} &#92;&#92;
q = &#92;lfloor D / C &#92;rfloor &#92;&#92;
r = &#92;left( D / C &#92;right) - q &#92;&#92;
&#92;]
</div>


<p>The following plot illustrates how the loading factor changes with job duration, assuming a cadence of 300 seconds (5 minutes):</p>

<p><img src="http://erikerlandson.github.com/assets/images/slot_load_study/load_factor_300s.png" width="750"></p>

<p>We immediately see that there is a saw-tooth pattern to the plot.  As the job duration increases towards the boundary of a cycle, there is less and less idle time until the next cycle, and so the loading approaches 1.0.  However, once the job&#8217;s end crosses the thresold to <em>just past</em> the start of the cycle, it immediately drops to the worse possible case: the slot will be idle for nearly an entire cycle.</p>

<p>The other important pattern is that the bottom of the saw-tooth gradually increases.  As a job&#8217;s duration occupies more whole negotiation cycles, the idle time at the end of the last cycle represents a decreasing fraction of the total time.</p>

<p>Observe that the most important &#8216;unit&#8217; in this plot is the number of negotiation cycles.  Since the saw-toothing scales with the cycle interval, we can express the same plot in units of cycles instead of seconds:</p>

<p><img src="http://erikerlandson.github.com/assets/images/slot_load_study/load_factor_cu.png" width="750"></p>

<p>The results above suggest a couple possible approaches for tuning negotiator cycle cadence to optimize slot loading in an HTCondor pool.  The first is to configure the negotiator interval to be small relative to a typical job duration, as the lower-bound on loading factor increases with the number of cycles a job&#8217;s duration occupies.  For example, if a typical job duration is 10 minutes, then a cycle cadence of 60 seconds ensures that in general 9 out of 10 cycles will be fully utilized, and so loading will be around 90%.  However, if one has mostly very short jobs, this can be difficult, as negotiation cycle cadences much less than 60 seconds may risk causing performance problems even on a moderately loaded pool.</p>

<p>A second approach is to try and tune the cadence so that as many jobs as possible complete <em>near the end</em> of a cycle, thus minimizing delay until the next cycle.  For example, if job durations are relatively consistent, say close to 90 seconds, then setting the negotiator interval to something like 50 seconds will induce those jobs to finish near the end of the 2nd negotiation cycle (at t+100 seconds), for a loading factor around 90%.  The caveat here is that job durations are frequently <em>not</em> that consistent, and as job duration spread increases, one&#8217;s ability to play this game <a href="http://erikerlandson.github.com/blog/2013/03/15/examining-the-modulus-of-random-variables/">rapidly evaporates</a>.</p>

<p>In this post, I have focused on the behavior of individual jobs and individual slots.  An obvious next question is what happens to aggregate pool loading when job durations are treated as population sampling from random variables, which I plan to explore in future posts.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Smooth Gradients for Cubic Hermite Splines]]></title>
    <link href="http://erikerlandson.github.com/blog/2013/03/16/smooth-gradients-for-cubic-hermite-splines/"/>
    <updated>2013-03-16T07:39:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2013/03/16/smooth-gradients-for-cubic-hermite-splines</id>
    <content type="html"><![CDATA[<p>One of the advantages of cubic Hermite splines is that their interval interpolation formula is an explicit function of gradients \( m_0, m_1, &#8230; m_{n-1} \) at knot-points:</p>

<div markdown="0">
&#92;[
y(t) = h_{00}(t) y_j + h_{10}(t) m_j + h_{01}(t) y_{j+1} + h_{11}(t) m_{j+1} &#92;&#92;
&#92;]
</div>


<p>where the Hermite bases are:</p>

<div markdown="0">
&#92;[
h_{00} = 2t^3 - 3t^2 + 1 &#92;&#92;
h_{10} = t^3 - 2t^2 + t &#92;&#92;
h_{01} = -2t^3 + 3t^2 &#92;&#92;
h_{11} = t^3 - t^2 &#92;&#92;
&#92;]
</div>


<p>(For now, I will be using the unit-interval form of the interpolation, where t runs from 0 to 1 on each interval.  I will also discuss the non-uniform interval equations below)</p>

<p>This formulation allows one to explicitly specify the interpolation gradient at each knot point, and to choose from various gradient assignment policies, for example <a href="http://en.wikipedia.org/wiki/Cubic_Hermite_spline#Interpolating_a_data_set">those listed here</a>, even supporting policies for <a href="http://en.wikipedia.org/wiki/Monotone_cubic_interpolation">enforcing monotonic interpolations</a>.</p>

<p>One important caveat with cubic Hermite splines is that although the gradient \( y&#8217;(t) \) is guaranteed to be continuous, it is <em>not</em> guaranteed to be smooth (that is, differentiable) <em>across</em> the knots (it is of course smooth <em>inside</em> each interval). Therefore, another useful category of gradient policy is to obtain gradients \( m_0, m_1, &#8230; m_{n-1} \) such that \( y&#8217;(t) \) is also smooth across knots.</p>

<p>(I feel sure that what follows was long since derived elsewhere, but my attempts to dig the formulation up on the internet failed, and so I decided the derivation might make a useful blog post)</p>

<p>To ensure smooth gradient across knot points, we want the 2nd derivative \( y&#8221;(t) \) to be equal at the boundaries of adjacent intervals:</p>

<div markdown="0">
&#92;[
h_{00}^&#8221;(t) y_{j-1} + h_{10}^&#8221;(t) m_{j-1} + h_{01}^&#8221;(t) y_j + h_{11}^&#8221;(t) m_j &#92;&#92;
= &#92;&#92;
h_{00}^&#8221;(t) y_j + h_{10}^&#8221;(t) m_j + h_{01}^&#8221;(t) y_{j+1} + h_{11}^&#8221;(t) m_{j+1}
&#92;]
</div>


<p>or substituting the 2nd derivative of the basis definitions above:</p>

<div markdown="0">
&#92;[
&#92;left( 12 t - 6 &#92;right) y_{j-1} + &#92;left( 6 t - 4 &#92;right) m_{j-1}  + &#92;left( 6 - 12 t &#92;right) y_j + &#92;left( 6 t - 2 &#92;right) m_j &#92;&#92;
= &#92;&#92;
&#92;left( 12 t - 6 &#92;right) y_{j} + &#92;left( 6 t - 4 &#92;right) m_{j}  + &#92;left( 6 - 12 t &#92;right) y_{j+1} + &#92;left( 6 t - 2 &#92;right) m_{j+1}
&#92;]
</div>


<p>Observe that t = 1 on the left hand side of this equation, and t = 0 on the right side, and so we have:</p>

<div markdown="0">
&#92;[
6 y_{j-1} + 2 m_{j-1} - 6 y_j + 4 m_j
=
-6 y_j - 4 m_j + 6 y_{j+1} - 2 m_{j+1}
&#92;]
</div>


<p>which we can rearrange as:</p>

<div markdown="0">
&#92;[
2 m_{j-1} + 8 m_j + 2 m_{j+1}
=
6 &#92;left( y_{j+1} - y_{j-1} &#92;right)
&#92;]
</div>


<p>Given n knot points, the above equation holds for j = 1 to n-2 (using zero-based indexing, as nature intended).  Once we define equations for j = 0 and j = n-1, we will have a system of equations to solve.  There are two likely choices.  The first is to simply specify the endpoint gradients \( m_0 = G \) and \( m_{n-1} = H \) directly, which yields the following <a href="http://en.wikipedia.org/wiki/Tridiagonal_matrix_algorithm">tri-diagonal matrix equation:</a></p>

<div markdown="0">
&#92;[
&#92;left( &#92;begin{array} {ccccc}
1 &   &   &   &   &#92;&#92;
2 & 8 & 2 &   &   &#92;&#92;
  & 2 & 8 & 2 &   &#92;&#92;
  &   & &#92;vdots &   &   &#92;&#92;
  &   & 2 & 8 & 2 &#92;&#92; 
  &   &   &   & 1 &#92;&#92;
&#92;end{array} &#92;right)

&#92;left( &#92;begin{array} {c}
m_0 &#92;&#92;
m_1 &#92;&#92;
 &#92;&#92;
&#92;vdots &#92;&#92;
 &#92;&#92;
m_{n-1}
&#92;end{array} &#92;right)
=
&#92;left( &#92;begin{array} {c}
G &#92;&#92;
6 &#92;left( y_2 - y_0 &#92;right) &#92;&#92;
6 &#92;left( y_3 - y_1 &#92;right) &#92;&#92;
&#92;vdots &#92;&#92;
6 &#92;left( y_{n-1} - y_{n-3} &#92;right) &#92;&#92;
H &#92;&#92;
&#92;end{array} &#92;right)
&#92;]
</div>


<p>The second common endpoint policy is to set the 2nd derivative equal to zero &#8211; the &#8220;natural spline.&#8221;   Setting the 2nd derivative to zero at the left-end knot (and t = 0) gives us:</p>

<div markdown="0">
&#92;[
4 m_0 + 2 m_1   =   6 &#92;left( y_1 - y_0 &#92;right)
&#92;]
</div>


<p>Similarly, at the right-end knot (t = 1), we have:</p>

<div markdown="0">
&#92;[
2 m_0 + 4 m_1   =   6 &#92;left( y_{n-1} - y_{n-2} &#92;right)
&#92;]
</div>


<p>And so for a natural spline endpoint policy the matrix equation looks like this:</p>

<div markdown="0">
&#92;[
&#92;left( &#92;begin{array} {ccccc}
4 & 2 &   &   &   &#92;&#92;
2 & 8 & 2 &   &   &#92;&#92;
  & 2 & 8 & 2 &   &#92;&#92;
  &   & &#92;vdots &   &   &#92;&#92;
  &   & 2 & 8 & 2 &#92;&#92; 
  &   &   & 2 & 4 &#92;&#92;
&#92;end{array} &#92;right)

&#92;left( &#92;begin{array} {c}
m_0 &#92;&#92;
m_1 &#92;&#92;
 &#92;&#92;
&#92;vdots &#92;&#92;
 &#92;&#92;
m_{n-1}
&#92;end{array} &#92;right)
=
&#92;left( &#92;begin{array} {c}
6 &#92;left( y_1 - y_0 &#92;right) &#92;&#92;
6 &#92;left( y_2 - y_0 &#92;right) &#92;&#92;
6 &#92;left( y_3 - y_1 &#92;right) &#92;&#92;
&#92;vdots &#92;&#92;
6 &#92;left( y_{n-1} - y_{n-3} &#92;right) &#92;&#92;
6 &#92;left( y_{n-1} - y_{n-2} &#92;right) &#92;&#92;
&#92;end{array} &#92;right)
&#92;]
</div>


<p>The derivation above is for uniform (and unit) intervals, where t runs from 0 to 1 on each knot interval.  I&#8217;ll now discuss the variation where knot intervals are non-uniform.   The non-uniform form of the interpolation equation is:</p>

<div markdown="0">
&#92;[
y(x) = h_{00}(t) y_j + h_{10}(t) d_j m_j + h_{01}(t) y_{j+1} + h_{11}(t) d_j m_{j+1} &#92;&#92;
&#92;text{ } &#92;&#92;
&#92;text{where:} &#92;&#92;
&#92;text{ }  &#92;&#92;
d_j = x_{j+1} - x_j &#92;text{  for  } j = 0, 1, &#8230; n-2 &#92;&#92;
t = (x - x_j) / d_j
&#92;]
</div>


<p>Taking \( t = t(x) \) and applying the chain rule, we see that 2nd derivative equation now looks like:</p>

<div markdown="0">
&#92;[
y&#8221;(x) = &#92;frac { &#92;left( 12 t - 6 &#92;right) y_{j} + &#92;left( 6 t - 4 &#92;right) d_j m_{j}  + &#92;left( 6 - 12 t &#92;right) y_{j+1} + &#92;left( 6 t - 2 &#92;right) d_j m_{j+1} } { d_j^2 }
&#92;]
</div>


<p>Applying a derivation similar to the above, we find that our (interior) equations look like this:</p>

<div markdown="0">
&#92;[
&#92;frac {2} { d_{j-1} }  m_{j-1} + &#92;left( &#92;frac {4} { d_{j-1} } + &#92;frac {4} { d_j } &#92;right) m_j + &#92;frac {2} {d_j} m_{j+1}
=
&#92;frac { 6 &#92;left( y_{j+1} - y_{j} &#92;right) } { d_j^2 } + &#92;frac { 6 &#92;left( y_{j} - y_{j-1} &#92;right) } { d_{j-1}^2 }
&#92;]
</div>


<p>and natural spline endpoint equations are:</p>

<div markdown="0">
&#92;[
&#92;text{left:  } &#92;frac {4} {d_0} m_0 + &#92;frac {2} {d_0} m_1   =   &#92;frac {6 &#92;left( y_1 - y_0 &#92;right)} {d_0^2} &#92;&#92;
&#92;text{right: } &#92;frac {2} {d_{n-2}} m_0 + &#92;frac {4} {d_{n-2}} m_1   =   &#92;frac {6 &#92;left( y_{n-1} - y_{n-2} &#92;right)} {d_{n-2}^2}
&#92;]
</div>


<p>And so the matrix equation for specified endpoint gradients is:</p>

<div markdown="0">
&#92;[
&#92;scriptsize
&#92;left( &#92;begin{array} {ccccc}
&#92;normalsize 1 &#92;scriptsize &   &   &   &   &#92;&#92;
&#92;frac{2}{d_0} & &#92;frac{4}{d_0} {+} &#92;frac{4}{d_1} & &#92;frac{2}{d_1} &   &   &#92;&#92;
  & &#92;frac{2}{d_1} & &#92;frac{4}{d_1} {+} &#92;frac{4}{d_2} & &#92;frac{2}{d_2} &   &#92;&#92;
  &   & &#92;vdots &   &   &#92;&#92;
  &   & &#92;frac{2}{d_{n-3}} & &#92;frac{4}{d_{n-3}} {+} &#92;frac{4}{d_{n-2}} & &#92;frac{2}{d_{n-2}} &#92;&#92; 
  &   &   &   & &#92;normalsize 1 &#92;scriptsize &#92;&#92;
&#92;end{array} &#92;right)

&#92;left( &#92;begin{array} {c}
m_0 &#92;&#92;
m_1 &#92;&#92;
 &#92;&#92;
&#92;vdots &#92;&#92;
 &#92;&#92;
m_{n-1}
&#92;end{array} &#92;right)
=
&#92;left( &#92;begin{array} {c}
G &#92;&#92;
6 &#92;left( &#92;frac{y_2 {-} y_1}{d_1^2} {+} &#92;frac{y_1 {-} y_0}{d_0^2} &#92;right) &#92;&#92;
6 &#92;left( &#92;frac{y_3 {-} y_2}{d_2^2} {+} &#92;frac{y_2 {-} y_1}{d_1^2} &#92;right)  &#92;&#92;
&#92;vdots &#92;&#92;
6 &#92;left( &#92;frac{y_{n-1} {-} y_{n-2}}{d_{n-2}^2} {+} &#92;frac{y_{n-2} {-} y_{n-3}}{d_{n-3}^2} &#92;right) &#92;&#92;
H &#92;&#92;
&#92;end{array} &#92;right)
&#92;normalsize
&#92;]
</div>


<p>And the equation for natural spline endpoints is:</p>

<div markdown="0">
&#92;[
&#92;scriptsize
&#92;left( &#92;begin{array} {ccccc}
&#92;frac{4}{d_0} & &#92;frac{2}{d_0}  &   &   &   &#92;&#92;
&#92;frac {2} {d_0} & &#92;frac {4} {d_0} {+} &#92;frac {4} {d_1} & &#92;frac{2}{d_1} &   &   &#92;&#92;
  & &#92;frac{2}{d_1} & &#92;frac{4}{d_1} {+} &#92;frac{4}{d_2} & &#92;frac{2}{d_2} &   &#92;&#92;
  &   & &#92;vdots &   &   &#92;&#92;
  &   & &#92;frac{2}{d_{n-3}} & &#92;frac{4}{d_{n-3}} {+} &#92;frac{4}{d_{n-2}} & &#92;frac{2}{d_{n-2}} &#92;&#92; 
  &   &   & &#92;frac{2}{d_{n-2}} & &#92;frac{4}{d_{n-2}} &#92;&#92;
&#92;end{array} &#92;right)

&#92;left( &#92;begin{array} {c}
m_0 &#92;&#92;
m_1 &#92;&#92;
 &#92;&#92;
&#92;vdots &#92;&#92;
 &#92;&#92;
m_{n-1}
&#92;end{array} &#92;right)
=
&#92;left( &#92;begin{array} {c}
&#92;frac{6 &#92;left( y_1 {-} y_0 &#92;right)}{d_0^2} &#92;&#92;
6 &#92;left( &#92;frac{y_2 {-} y_1}{d_1^2}  {+}  &#92;frac{y_1 {-} y_0}{d_0^2} &#92;right) &#92;&#92;
6 &#92;left( &#92;frac{y_3 {-} y_2}{d_2^2}  {+}  &#92;frac{y_2 {-} y_1}{d_1^2} &#92;right)  &#92;&#92;
&#92;vdots &#92;&#92;
6 &#92;left( &#92;frac{y_{n-1} {-} y_{n-2}}{d_{n-2}^2}  {+}  &#92;frac{y_{n-2} {-} y_{n-3}}{d_{n-3}^2} &#92;right) &#92;&#92;
&#92;frac{6 &#92;left( y_{n-1} {-} y_{n-2} &#92;right)}{d_{n-2}^2} &#92;&#92;
&#92;end{array} &#92;right)
&#92;normalsize
&#92;]
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Examining the Modulus of Random Variables]]></title>
    <link href="http://erikerlandson.github.com/blog/2013/03/15/examining-the-modulus-of-random-variables/"/>
    <updated>2013-03-15T12:03:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2013/03/15/examining-the-modulus-of-random-variables</id>
    <content type="html"><![CDATA[<h3>Motivation</h3>

<p>The original motivation for these experiments was consideration of the impact of negotiator cycle cadence (i.e. the time between the start of one cycle and the start of the next) on HTCondor pool loading.  Specifically, any HTCondor job that completes and vacates its resource may leave that resource unloaded until it can be re-matched on the next cycle.  Therefore, the duration of resource vacancies (and hence, pool loading) can be thought of as a function of job durations <em>modulo</em> the cadence of the negotiator cycle.  In general, the aggregate behavior of job durations on a pool is useful to model as a random variable.  And so, it seemed worthwhile to build up a little intuition about the behavior of a random variable when you take its modulus.</p>

<h3>Methodology</h3>

<p>I took a Monte Carlo approach to this study because a tractable theoretical framework eluded me, and you do not have to dive very deep to show that <a href="http://erikerlandson.github.com/blog/2013/01/02/the-mean-of-the-modulus-does-not-equal-the-modulus-of-the-mean/">even trivial random variable behavior under a modulus is dependent on the distribution</a>.   A Monte Carlo framework for the study also allows for other underlying distributions to be easily studied, by altering the random variable being sampled.   In the interest of getting right into results, I&#8217;ll briefly discuss the tools I used at the end of this post.</p>

<h3>Modulus and Variance</h3>

<p>Consider what happens to a random variable&#8217;s modulus as its variance increases.  This sequence of plots shows that the modulus of a normal distribution tends toward a uniform distribution over the modulus interval, as the underlying variance increases:</p>

<table>
<thead>
<tr>
<th></th>
<th align="center">  </th>
<th align="center">  </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/normal_0.20.png" width="375" height="375">  </td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/normal_0.30.png" width="375" height="375">  |</td>
</tr>
<tr>
<td></td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/normal_0.40.png" width="375" height="375">  </td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/normal_0.50.png" width="375" height="375">  |</td>
</tr>
</tbody>
</table>


<br>


<p>From the above plots, we can see that in the case of a normal distribution, its modulus tends toward uniform rather quickly - by the time the underlying variance is half of the modulus interval.</p>

<p>The following plots demonstrate the same effect with a one-tailed distribution (the exponential) &#8211; it requires a larger variance for the effect to manifest.</p>

<table>
<thead>
<tr>
<th></th>
<th align="center">  </th>
<th align="center">  </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/exponential_01.png" width="375" height="375">  </td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/exponential_04.png" width="375" height="375">  |</td>
</tr>
<tr>
<td></td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/exponential_10.png" width="375" height="375">  </td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/exponential_20.png" width="375" height="375">  |</td>
</tr>
</tbody>
</table>


<br>


<p>A third example, using a log-normal distribution.   The variance of the log-normal increases as a function of both \( \mu \) and \( \sigma \).  In this example \( \mu \) is increased systematically, holding \( \sigma \) constant at 1:</p>

<table>
<thead>
<tr>
<th></th>
<th align="center">  </th>
<th align="center">  </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/lognormal_0.0_1.0.png" width="375" height="375">  </td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/lognormal_0.5_1.0.png" width="375" height="375">  |</td>
</tr>
<tr>
<td></td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/lognormal_1.0_1.0.png" width="375" height="375">  </td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/lognormal_2.0_1.0.png" width="375" height="375">  |</td>
</tr>
</tbody>
</table>


<br>


<p>For a final examination of variance, I will again use log-normals and this time vary \( \sigma \), while holding \( \mu \) constant at 0.  Here we see that the effect of increasing the log-normal variance via \( \sigma \) does <em>not</em> follow the pattern in previous examples &#8211; the distribution does not &#8216;spread&#8217; and its modulus does not evolve toward a uniform distribution!</p>

<table>
<thead>
<tr>
<th></th>
<th align="center">  </th>
<th align="center">  </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/lognormal_0.0_0.5.png" width="375" height="375">  </td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/lognormal_0.0_1.0.png" width="375" height="375">  |</td>
</tr>
<tr>
<td></td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/lognormal_0.0_1.5.png" width="375" height="375">  </td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/lognormal_0.0_2.0.png" width="375" height="375">  |</td>
</tr>
</tbody>
</table>


<br>


<h3>Modulus and Mean</h3>

<p>The following table of plots demonstrates the decreasing effect that a distribution&#8217;s location (mean) has, as its spread increases and its modulus approaches uniformity.   In fact, we see that <em>any</em> distribution in the &#8216;uniform modulus&#8217; parameter region is indistinguishable from any other, with respect to its modulus &#8211; all changes to mean or variance <em>within</em> this region have no affect on the distribution&#8217;s modulus!</p>

<table>
<thead>
<tr>
<th></th>
<th align="center">  </th>
<th align="center">  </th>
<th align="center">  </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/normal_0.0_0.3.png" width="260" height="260">  </td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/normal_0.5_0.3.png" width="260" height="260">  </td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/normal_1.0_0.3.png" width="260" height="260">  |</td>
</tr>
<tr>
<td></td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/normal_0.0_0.4.png" width="260" height="260">  </td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/normal_0.5_0.4.png" width="260" height="260">  </td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/normal_1.0_0.4.png" width="260" height="260">  |</td>
</tr>
<tr>
<td></td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/normal_0.0_0.5.png" width="260" height="260">  </td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/normal_0.5_0.5.png" width="260" height="260">  </td>
<td align="center">  <img src="http://erikerlandson.github.com/assets/images/rv_mod_study/normal_1.0_0.5.png" width="260" height="260">  |</td>
</tr>
</tbody>
</table>


<br>


<h3>Conclusions</h3>

<p>Generally, as the spread of a distribution increases, its modulus tends toward a uniform distribution on the modulus interval.   Although it was tempting to state this in terms of increasing variance, we see from the 2nd log-normal experiment that variance can increase without increasing &#8216;spread&#8217; in a way that causes the trend toward uniform modulus.   Currently, I&#8217;m not sure what the true invariant is, that properly distinguishes the 2nd log-normal scenario from the others.</p>

<p>For any distribution that <em>does</em> reside in the &#8216;uniform-modulus&#8217; parameter space, we see that neither changes to location nor spread (nor even category of distribution) can be distinguished by the distribution modulus.</p>

<h3>Tools</h3>

<p>I used the following software widgets:</p>

<ul>
<li><a href="https://github.com/erikerlandson/condor_tools/blob/cad8773da36fa7f3c60c93895a428d6f1fae6752/bin/rv_modulus_study">rv_modulus_study</a> &#8211; the jig for Monte Carlo sampling of underlying distributions and their corresponding modulus</li>
<li><a href="https://github.com/erikerlandson/dtools/wiki/dplot">dplot</a> &#8211; a simple cli wrapper around <code>matplotlib.pyplot</code> functionality</li>
<li><a href="https://github.com/willb/capricious/">Capricious</a> &#8211; a library for random sampling of various distribution types</li>
<li><a href="https://github.com/erikerlandson/capricious/blob/c8ec13f1f49880bb3573034de59971f84d15f7c1/lib/capricious/spline_distribution.rb">Capricious::SplineDistribution</a> &#8211; a ruby class for estimating PDF and CDF of a distribution from sampled data, using cubic Hermite splines (note, at the time of this writing, I&#8217;m using an experimental variation on my personal repo fork, at the link)</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Mean of the Modulus Does Not Equal the Modulus of the Mean]]></title>
    <link href="http://erikerlandson.github.com/blog/2013/01/02/the-mean-of-the-modulus-does-not-equal-the-modulus-of-the-mean/"/>
    <updated>2013-01-02T08:55:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2013/01/02/the-mean-of-the-modulus-does-not-equal-the-modulus-of-the-mean</id>
    <content type="html"><![CDATA[<p>I&#8217;ve been considering models for the effects of HTCondor negotiation cycle cadence on pool loading and accounting group starvation, which led me to thinking about the effects of taking the modulus of a random variable, for reasons I plan to discuss in future posts.</p>

<p>When you take the modulus of a random variable, X, the corresponding expected value E[X mod m] is not equal to E[X] mod m.  Consider the following example:</p>

<p><img src="http://erikerlandson.github.com/assets/images/rv_modulus_mean.png" title="An example demonstrating that E[X mod m] != E[X] mod m" alt="Random Variable Images" /></p>

<p>As we see from the example above, the random variables X and Y have the same mean:  E[X] = E[Y] = 0.75, however E[X mod 1] = 0.75 while E[Y mod 1] = 0.5.  One implication is that computing the moments of the modulus of random variables must be on a per-distribution basis, perhaps via monte carlo methods.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Demonstration of Negotiator-Side Resource Consumption]]></title>
    <link href="http://erikerlandson.github.com/blog/2012/12/03/a-demonstration-of-negotiator-side-resource-consumption/"/>
    <updated>2012-12-03T08:25:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2012/12/03/a-demonstration-of-negotiator-side-resource-consumption</id>
    <content type="html"><![CDATA[<p>HTCondor supports a notion of aggregate compute resources known as partitionable slots (p-slots), which may be consumed by multiple jobs.   Historically, at most one job could be matched against such a slot in a single negotiation cycle, which limited the rate at which partitionable slot resources could be utilized.  More recently, the scheduler has been enhanced with logic to allow it to acquire multiple claims against a partitionable slot, which increases the p-slot utilization rate. However, as this potentially bypasses the negotiator&#8217;s accounting of global pool resources such as accounting group quotas and concurrency limits, it places some contraints on what jobs can can safely acquire multiple claims against any particular p-slot: for example, only other jobs on the same scheduler can be considered.  Additionally, candidate job requirements must match the requirements of the job that originally matched in the negotiator.  Another significant impact is that the negotiator is still forced to match an entire p-slot, which may have a large match cost (weight): these large match costs cause <a href="https://htcondor-wiki.cs.wisc.edu/index.cgi/tktview?tn=3013">accounting difficulties</a> when submitter shares and/or group quotas drop below the cost of a slot.  This particular problem is growing steadily larger, as machines with ever-larger numbers of cores and other resources appear in HTCondor pools.</p>

<p>An alternative approach to scheduler-side resource consumption is to enhance the negotiator with the ability to match multiple jobs against a resource (p-slot) &#8211; negotiator-side resource consumption.   The advantages of negotiator-side consumption are that it places fewer limitations on what jobs can consume a given resource.  The negotiator already handles global resource accounting, and so jobs are not required to adhere to the same requirements expression to safely consume assets from the same resource.  Furthermore, jobs from any scheduler may be considered.  Each match is only charged the cost of resources consumed, and so p-slots with large amounts of resources do not cause difficulties with large match costs.   Another considerable benefit of this approach is that it facilitates the support of <a href="http://spinningmatt.wordpress.com/2012/11/13/no-longer-thinking-in-slots-thinking-in-aggregate-resources-and-consumption-policies/">configurable resource consumption policies</a></p>

<p>I have developed a working draft of negotiator-side resource consumption on my HTCondor github fork, topic branch <a href="https://github.com/erikerlandson/htcondor/tree/V7_9-prototype-negside-pslot-splits">V7_9-prototype-negside-pslot-splits</a> which also implements support for configurable resource consumption policies.   I will briefly demonstrate this implementation and some of its advantages below.</p>

<p>First I will demonstrate an example with a consumption policy that is essentially equivalent to HTCondor&#8217;s current default policies.  Consider this configuration:</p>

<pre><code># spoof some cores
NUM_CPUS = 10

# configure an aggregate resource (p-slot) to consume
SLOT_TYPE_1 = 100%
SLOT_TYPE_1_PARTITIONABLE = True
# declare multiple claims for negotiator to use
# may also use global: NUM_CLAIMS
SLOT_TYPE_1_NUM_CLAIMS = 20
NUM_SLOTS_TYPE_1 = 1

# turn off schedd-side resource splitting since we're demonstrating neg-side alternative
CLAIM_PARTITIONABLE_LEFTOVERS = False

# turn this off to demonstrate that consumption policy will handle this kind of logic
MUST_MODIFY_REQUEST_EXPRS = False

# configure a consumption policy.   This policy is modeled on
# current 'modify-request-exprs' defaults:
# "my" is resource ad, "target" is job ad
STARTD_EXPRS = ConsumptionCpus, ConsumptionMemory, ConsumptionDisk
ConsumptionCpus = quantize(target.RequestCpus, {1})
ConsumptionMemory = quantize(target.RequestMemory, {128})
ConsumptionDisk = quantize(target.RequestDisk, {1024})
# swap doesn't seem to be actually supported in resource accounting

# keep slot weights enabled for match costing
NEGOTIATOR_USE_SLOT_WEIGHTS = True

# weight used to derive match cost: W(before-consumption) - W(after-consumption)
SlotWeight = Cpus

# for simplicity, turn off preemption, caching, worklife
CLAIM_WORKLIFE=0
MAXJOBRETIREMENTTIME = 3600
PREEMPT = False
RANK = 0
PREEMPTION_REQUIREMENTS = False
NEGOTIATOR_CONSIDER_PREEMPTION = False
NEGOTIATOR_MATCHLIST_CACHING = False

# verbose logging
ALL_DEBUG = D_FULLDEBUG

# reduce daemon update latencies
NEGOTIATOR_INTERVAL = 30
SCHEDD_INTERVAL = 15
</code></pre>

<p>In the above configuration, we declare a typical aggregate (that is, partitionable) resource <code>SLOT_TYPE_1</code>, but then we also configure a <em>consumption policy</em>, by advertising <code>ConsumptionCpus</code>, <code>ConsumptionMemory</code> and <code>ConsumptionDisk</code>.  Note that these are defined with quantizing expressions currently used as default values for the <code>MODIFY_REQUEST_EXPRS</code> behavior.  The startd and the negotiatior will <em>both</em> use these expressions by examining the slot ads.</p>

<p>Next, we submit 15 jobs.  Note that this more than the 10 cores advertised by the p-slot:</p>

<pre><code>universe = vanilla
cmd = /bin/sleep
args = 60
should_transfer_files = if_needed
when_to_transfer_output = on_exit
queue 15
</code></pre>

<p>If we watch the negotiator log, we will see that negotiator matches the 10 jobs supported by the p-slot on the next cycle (note that it uses slot1 each time):</p>

<pre><code>$ tail -f NegotiatorLog | grep -e '\-\-\-\-\-'  -e 'matched
12/03/12 11:53:10 ---------- Finished Negotiation Cycle ----------
12/03/12 11:53:25 ---------- Started Negotiation Cycle ----------
12/03/12 11:53:25       Successfully matched with slot1@rorschach
12/03/12 11:53:25       Successfully matched with slot1@rorschach
12/03/12 11:53:25       Successfully matched with slot1@rorschach
12/03/12 11:53:25       Successfully matched with slot1@rorschach
12/03/12 11:53:25       Successfully matched with slot1@rorschach
12/03/12 11:53:25       Successfully matched with slot1@rorschach
12/03/12 11:53:25       Successfully matched with slot1@rorschach
12/03/12 11:53:25       Successfully matched with slot1@rorschach
12/03/12 11:53:25       Successfully matched with slot1@rorschach
12/03/12 11:53:25       Successfully matched with slot1@rorschach
12/03/12 11:53:25 ---------- Finished Negotiation Cycle ----------
</code></pre>

<p>You can use <code>condor_q</code> to verify that the 10 jobs subsequently run.   The jobs run against 10 dynamic slots (d-slots) in the standard way:</p>

<pre><code>$ ccdump condor_status Name TotalSlotCpus
slot1@rorschach | 10
slot1_10@rorschach | 1
slot1_1@rorschach | 1
slot1_2@rorschach | 1
slot1_3@rorschach | 1
slot1_4@rorschach | 1
slot1_5@rorschach | 1
slot1_6@rorschach | 1
slot1_7@rorschach | 1
slot1_8@rorschach | 1
slot1_9@rorschach | 1
</code></pre>

<p>Next we consider altering the resource consumption policy.  As a simple example, suppose we wish to allocate memory more coarsely.  We could alter the configuration above by changing <code>ConsumptionMemory</code> to:</p>

<pre><code>ConsumptionMemory = quantize(target.RequestMemory, {512})
</code></pre>

<p>Perhaps we then also want to express match cost in a memory-centric way, instead of the usual cpu-centric way:</p>

<pre><code>SlotWeight = floor(Memory / 512)
</code></pre>

<p>Here it is worth noting that in this implementation of negotiator-side consumption, the cost of a match is defined as W(S) - W(S&#8217;), where W(S) is the weight of the slot <em>prior</em> to consuming resources from the match and consumption policy, and W(S`) is the weight evaluated for the slot <em>after</em> those resources are subtracted.  This modification enables multiple matches to be made against a single p-slot, and furthermore it paves the way to possible avenues for a <a href="http://erikerlandson.github.com/blog/2012/11/26/rethinking-the-semantics-of-group-quotas-and-slot-weights-computing-claim-capacity-from-consumption-policy/">better unit analysis of slot weights and accounting groups</a>.</p>

<p>Continuing the example, if we re-run the example with this new consumption policy, we should see that memory limits reduce the number of jobs matched against <code>slot1</code> to 3:</p>

<pre><code>$ tail -f NegotiatorLog | grep -e '\-\-\-\-\-'  -e 'matched'
12/03/12 12:58:22 ---------- Finished Negotiation Cycle ----------
12/03/12 12:58:37 ---------- Started Negotiation Cycle ----------
12/03/12 12:58:37       Successfully matched with slot1@rorschach
12/03/12 12:58:37       Successfully matched with slot1@rorschach
12/03/12 12:58:37       Successfully matched with slot1@rorschach
12/03/12 12:58:37 ---------- Finished Negotiation Cycle ----------
</code></pre>

<p>Examining the slot memory assets, we see that there is insufficient memory for a fourth match when our consumption policy sets the minimum at 512:</p>

<pre><code>$ ccdump condor_status Name TotalSlotMemory
slot1@rorschach | 1903
slot1_1@rorschach | 512
slot1_2@rorschach | 512
slot1_3@rorschach | 512
</code></pre>

<p>As a final example, I&#8217;ll demonstrate the positive impact of negotiator side matching on interactions with accounting groups (or submitter shares).  Again returning to my original example, modify the configuration with a simple accounting group policy:</p>

<pre><code>GROUP_NAMES = a
GROUP_QUOTA_a = 1
GROUP_ACCEPT_SURPLUS = False
GROUP_AUTOREGROUP = False
</code></pre>

<p>Now submit 2 jobs against accounting group <code>a</code>:</p>

<pre><code>universe = vanilla
cmd = /bin/sleep
args = 60
should_transfer_files = if_needed
when_to_transfer_output = on_exit
+AccountingGroup="a.u"
queue 2
</code></pre>

<p>We see that accounting groups are respected: one job runs, and it does not suffer from insufficient share to acquire resources from <code>slot1</code> <a href="https://htcondor-wiki.cs.wisc.edu/index.cgi/tktview?tn=3013">(GT3013)</a>, because match cost is computed using only the individual job&#8217;s impact on slot weight, instead of being required to match the entire p-slot:</p>

<pre><code>$ tail -f ~/condor/local/log/NegotiatorLog | grep -e '\-\-\-\-\-' -e matched
12/03/12 14:57:50 ---------- Finished Negotiation Cycle ----------
12/03/12 14:58:08 ---------- Started Negotiation Cycle ----------
12/03/12 14:58:08       Successfully matched with slot1@rorschach
12/03/12 14:58:09 ---------- Finished Negotiation Cycle ----------

$ ccdump condor_status Name TotalSlotCpus
slot1@rorschach | 10
slot1_1@rorschach | 1
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rethinking the Semantics of Group Quotas and Slot Weights: Computing Claim Capacity from Consumption Policy]]></title>
    <link href="http://erikerlandson.github.com/blog/2012/11/26/rethinking-the-semantics-of-group-quotas-and-slot-weights-computing-claim-capacity-from-consumption-policy/"/>
    <updated>2012-11-26T13:52:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2012/11/26/rethinking-the-semantics-of-group-quotas-and-slot-weights-computing-claim-capacity-from-consumption-policy</id>
    <content type="html"><![CDATA[<p>In two previous posts, I made a case to motivate the need for a better definition of slot weights and group quotas that could accommodate use cases involving aggregate resources (partitionable slots) with heterogeneous consumption policies and also provide a principled unit analysis for weights and quotas.  These previous posts can be viewed here:</p>

<ul>
<li><a href="http://erikerlandson.github.com/blog/2012/11/13/rethinking-the-semantics-of-group-quotas-and-slot-weights-for-heterogeneous-and-multidimensional-compute-resources/">Rethinking the Semantics of Group Quotas and Slot Weights for Heterogeneous and Multidimensional Compute Resources</a></li>
<li><a href="http://erikerlandson.github.com/blog/2012/11/15/rethinking-the-semantics-of-group-quotas-and-slot-weights-claim-capacity-model/">Rethinking the Semantics of Group Quotas and Slot Weights: Claim Capacity Model</a></li>
</ul>


<p>As previously mentioned, a Claim Capacity Model of accounting group quotas and slot weights (or &#8220;resource consumption costs&#8221;) requires a resource claiming model that assigns a well defined finite value for the maximum number of claims that each resource and its consumption policy can support.  It must also be re-evaluatable on a resource as its assets are consumed, so that the cost of a proposed claim (or match, in negotiation-speak) can be defined as W(R) - W(R&#8217;), were R&#8217; embodies the amounts of all assets remaining after the claim has taken its share.  (Here, I will be using the term &#8216;assets&#8217; to refer to quantities such as cpus, memory, disk, swap or any <a href="http://spinningmatt.wordpress.com/2012/11/19/extensible-machine-resources/">extensible resources</a> defined, to clarify the difference between an aggregate resource (i.e. a partitionable slot) versus a single resource dimension such as cpus, memory, etc).</p>

<p>This almost immediately raises the question of how best to define such a resource claiming model.  In this post I will briefly describe a few possible approaches, focusing on models which are easy reason about, easy to configure and additionally allow claim capacity for a resource - W(R) - to be computed automatically for the user, thus making a sane relationship between consumption policies and consumption costs possible to enforce.</p>

<h3>Approach 1: fixed claim consumption model</h3>

<p>The simplest-possible approach is arguably to just directly configure a fixed number, M, of claims attached to a resource.  In this model, each match of a job against a resource consumes one of the M claims.   Here, match cost W(R) - W(R&#8217;) = 1 in all cases, and is independent of the &#8216;size&#8217; of assets consumed from a resource.</p>

<p>A possible use case for such a model is that one might wish to declare that a resource can run up to a certain number of jobs, without assigning any particular cost to consuming individual assets.  If the pool users&#8217; workload consists of large numbers of resource-cheap jobs that can effectively share cpu, memory, etc, then such a model might be a good fit.</p>

<h3>Approach 2: configure asset quantization levels</h3>

<p>Another approach that makes the relation between consumption policy and claim capacity easy to think about is to configure a quantization level for each resource asset.  For example, here we might quantize memory into 20 levels, i.e. Q(memory) = 20.  Similarly we might define Q(cpus) = 10 (note that HTCondor does not currently handle fractional cpus on resources, but this kind of model would benefit if floating point asset fractions were supported).  At any time, a resource R has some number q(a) left of the original Q(a).  A job requests an amount r(a) for asset (a).   Here, a claim gets a quantized approximation of any requested asset = V(a)(n(a)/Q(a)), where V(a) is the total original value available for asset (a), and n(a) = ceiling(r(a)Q(a)/V(a)).   Here there are two possible sub-policies.  If we demand that each claim consume >= 1 quantum of every asset (i.e. n(a) >= 1), then the claim capacity W(R) is the minimum of q(a), for (a) over all assets.  However, if a claim is allowed to consume a zero quantity of some individual assets (n(a)=0), then the claim capacity is the <em>maximum</em> of the q(a).   In this case, one must address the corner case of a claim attempting to consume (n(a)=0) over all assets.  The resulting resource R&#8217; has q&#8217;(a) = q(a)-n(a), and W(R&#8217;) is the minium (or maximum) over the new q&#8217;(a).</p>

<h3>Approach 3: configure minimum asset charges</h3>

<p>A third approach is to configure a <em>minimum</em> amount of each asset that any claim must be charged.   For example, we might define a minimum amount of memory C(memory) to charge any claim.   If a job requests an amount r(a), it will always receive max(r(a), C(a)).  As above, q(a) is the number of quanta currently available for asset (a).  Let v(a) be the amount of (a) currently available.  Here we define q(a) for an asset (a) to be floor(v(a)/C(a)).   If we adhere to a reasonable restriction that C(a) must be strictly > 0 for all (a), we are guaranteed a well defined W(R) = min over the q(a).</p>

<p>It is an open question which of these models (or some other completely different options) should be supported.  Conceivably all of them could be provided as options.</p>

<p>Currently my personal preference leans toward Approach 3.  It is easy to reason about and configure.  It yields a well defined W(R) in all circumstances, with no corner cases, that is straightforward to compute and enforce automatically.  It is easy to configure heterogeneous consumption policies that cost different resource assets in different ways, simply by tuning minimum charge C(a) appropriately for each asset.  This includes claim capacity models where jobs are assumed to use very small amounts of any resource, including fractional shares of cpu assets.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rethinking the Semantics of Group Quotas and Slot Weights: Claim Capacity Model]]></title>
    <link href="http://erikerlandson.github.com/blog/2012/11/15/rethinking-the-semantics-of-group-quotas-and-slot-weights-claim-capacity-model/"/>
    <updated>2012-11-15T17:22:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2012/11/15/rethinking-the-semantics-of-group-quotas-and-slot-weights-claim-capacity-model</id>
    <content type="html"><![CDATA[<p>In my previous post about <a href="http://erikerlandson.github.com/blog/2012/11/13/rethinking-the-semantics-of-group-quotas-and-slot-weights-for-heterogeneous-and-multidimensional-compute-resources">Rethinking the Semantics of Group Quotas and Slot Weights</a>, I proposed a concept for unifying the semantics of accounting group quotas and slot weights across arbitrary resource allocation strategies.</p>

<p>My initial terminology was that the weight of a slot (i.e. resource ad) is a measure of the <em>maximum</em> number of jobs that might match against that ad, given the currently available resource quantities and the allocation policy.  The cost of a match becomes the amount by which that measure is reduced, after the match&#8217;s resources are removed from the ad.</p>

<p>In the HTCondor vocabulary, a job acquires a <em>claim</em> on resources to actually run after it has been matched.  It has been proposed that it may be beneficial for HTCondor to evolve toward a model where there are (aggregate) resource ads, and claims against those ads, as a simplification of the current model which involves static, partitionable and dynamic slots, with claims.  With this in mind, a preferable terminology for group quota and weight semantics might be that a resource ad (or slot) has a measure of the maximum number of claims it could dispense: a <em>claim capacity</em> measure.  The cost of a claim (or match) is the corresponding reduction of the resource&#8217;s claim capacity.</p>

<p>So, this semantic model could be referred to as the Claim Capacity Model of group quotas and slot weights.  With this terminology, the shared &#8216;unit&#8217; for group quotas and slot weights would be <em>claims</em> instead of <em>jobs</em>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rethinking the Semantics of Group Quotas and Slot Weights for Heterogeneous and Multidimensional Compute Resources]]></title>
    <link href="http://erikerlandson.github.com/blog/2012/11/13/rethinking-the-semantics-of-group-quotas-and-slot-weights-for-heterogeneous-and-multidimensional-compute-resources/"/>
    <updated>2012-11-13T15:31:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2012/11/13/rethinking-the-semantics-of-group-quotas-and-slot-weights-for-heterogeneous-and-multidimensional-compute-resources</id>
    <content type="html"><![CDATA[<p>The HTCondor semantic for accounting group quotas and slot weights is currently cpu-centric.  This is an artifact of the historic primacy of cpu as the most commonly-considered limiting resource in computations.  For example the <code>SlotWeight</code> attribute is currently defaulted to <code>Cpus</code>, and when slot weights are disabled, there is logic activated in matchmaking to sum the available cpus on slots to avoid &#8216;undercounting&#8217; total pool quotas.</p>

<p>However, HTCondor slots &#8211; the core model of computational resources in an HTCondor pool &#8211; manage four resources by default: cpu, memory, disk and swap.  Furthermore, slots may now be configured with arbitrary custom resources.  As recently mentioned by <a href="http://spinningmatt.wordpress.com/2012/11/13/no-longer-thinking-in-slots-thinking-in-aggregate-resources-and-consumption-policies">Matthew Farrellee</a>, there is a growing pressure to provide robust support not just for traditional cpu-centric resource presentation, usage and allocation, but also seamlessly mediated with memory-centric, gpu-centric or &#8216;*&#8217;-centric resource allocation policies and more generally allocation policies that are simultaneously aware of all resource dimensions.</p>

<p>This goal immediately raises some questions for the semantics of accounting groups and slot weights when matching jobs against slots during matchmaking.</p>

<p>Consider a pool where 50% of the slots are &#8216;weighted&#8217; in a traditional cpu-centric way, but the other 50% are intended to be allocated in a memory-centric way.  This is currently possible, as the <code>SlotWeight</code> attribute can be configured appropriately to be a function of either <code>Cpus</code> or <code>Memory</code>.</p>

<p>But in a scenario where slots are weighted as functions of heterogeneous resource dimensions, it raises a semantic question:  when we sum these weights to obtain the pool-wide available quota, what &#8216;real world&#8217; quantity does this total represent &#8211; if any?   Is it a purely heuristic numeric value with no well defined unit attached?</p>

<p>This question has import.  Understanding what the answer is, or should be, impacts what story we tell to users about what their accounting group configuration actually means.  When I assign a quota to an accounting group in such a heterogeneous environment, what is that quota regulating?   When a job matches a cpu-centric slot, does the cost of that match have a different meaning than when matching against a memory-centric slot?   When the slots are partitionable, a match implies a certain multi-dimensional slice of resources allocated from that slot.  What is the cost of that slice?  Does the sum of costs add up to the original weight on the partitionable slot?  If not, how does that affect our understanding of quota semantics?</p>

<p>It may be possible unify all of these ideas by adopting the perspective that a slot&#8217;s weight is a measure of the maximum number of jobs that can be matched against it.  The cost of a match is W(S)-W(S&#8217;), where W(S) is the weight function evaluated on the slot prior to match, and W(S&#8217;) is the corresponding weight after the match has extracted its requested resources.  The pool&#8217;s total quota is just the sum of W(S), over all slots S in the pool.  Note, this implies that the &#8216;unit&#8217; attached to both slot weights and accounting group quotas is &#8216;jobs&#8217;.</p>

<p>Consider a simple example from the traditional cpu-centric configuration:   A partitionable slot is configured with 8 cpus, and <code>SlotWeight</code> is just its default <code>Cpus</code>.  Using this model, the allocation policy is: &#8216;each match must use >= 1 cpu&#8221;, and that other resource requests are assumed to be not limiting.  The maximum number of matches is 8 jobs, each requesting 1 cpu.   However, a job might also request 2 cpus.  In this case, note that the cost of the match is 2, since the remaining slot has 6 slots, and so W(S&#8217;) now evaluates to 6.   So, the cost of the match is how many fewer possible jobs the original slot can support after the match takes its requested resources.</p>

<p>This approach can be applied equally well to a memory-centric strategy, or a disk centric strategy, or a gpu-based strategy, or any combination simultaneously.  All weights evaluate to a value with unit &#8216;jobs&#8217;.   All match costs are differences between weights (before and after match), and so their values are also in units of &#8216;jobs&#8217;.  Therefore, the semantics of the sum of weights over a pool is always well defined: it is a number of jobs, and spefically a measure of the maximum number of jobs that might match against all the slots in the pool.  When a match acquires resources that reduce this maximum by more than 1 job, that is not in any way inconsistent.  It means the job used resources that might have supported two or more &#8216;smaller&#8217; jobs.   This means that accounting group quotas (and submitter shares) also have a well defined unit and semantic, which is &#8216;how many (or what fraction of) the maximum possible jobs is this group guaranteed by my accounting policy&#8217;</p>

<p>One implication of this proposed semantic for quotas and weights is that the measure for the maximum number of jobs that may match against any given slot must be some finite number.   It implies that all resource dimensions are quantized in some way by the allocation policy.   This scheme would not support a real-valued resource dimension that had no minimum quantization.  I do not think that this is a very heavy-weight requirement, and in fact we have already been moving in that direction with features such as MODIFY_REQUEST_EXPRS_xxx.</p>

<p>When a slot&#8217;s resource allocation policy is defined over all its resources, what bounds this measure of maximum possible matches?  In a case where each job match <em>must</em> use at least one non-zero quantum of each resource dimension, then the limit is the resource with the mimimum quantized levels.   In a case where jobs may request a zero amount of resources, then the limit is the resource with the maximum quantized levels.  (note, it is required that each match use at least one quantum of at least one resource, otherwise the maximum is not properly bounded).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Accounting Groups With Wallaby]]></title>
    <link href="http://erikerlandson.github.com/blog/2012/11/01/using-accounting-groups-with-wallaby/"/>
    <updated>2012-11-01T07:41:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2012/11/01/using-accounting-groups-with-wallaby</id>
    <content type="html"><![CDATA[<p>In this post I will describe how to use HTCondor accounting groups with <a href="http://getwallaby.com">Wallaby</a>.  I will begin by walking through an accounting group configuration on a pool managed by wallaby.  Following, I will demonstrate the configuration in action.</p>

<p>The gist of this demo will be to create a simple accounting group hierarchy:  A top-level group called <code>Demo</code>, and three child groups <code>Demo.A, Demo.B, Demo.C</code>.  <code>Demo</code> will be given a <em>static</em> quota to simulate the behavior of a pool with a particular number of slots available.  The child groups will use <em>dynamic</em> quotas to express their quota shares from the parent as ratios.</p>

<p>First, it is good practice to snapshot current wallaby configuration for reference:</p>

<pre><code>$ wallaby make-snapshot "pre demo state"
</code></pre>

<p>We will be constructing a wallaby feature called <code>AccountingGroups</code> to hold our accounting group configurations.  This creates the feature:</p>

<pre><code>$ wallaby add-feature AccountingGroups
</code></pre>

<p>Wallaby wants to know about features that are used in configurations, so begin by declaring them to the wallaby store:</p>

<pre><code>$ wallaby add-param GROUP_NAMES
$ wallaby add-param GROUP_QUOTA_Demo
$ wallaby add-param GROUP_QUOTA_DYNAMIC_Demo.A
$ wallaby add-param GROUP_QUOTA_DYNAMIC_Demo.B
$ wallaby add-param GROUP_QUOTA_DYNAMIC_Demo.C
$ wallaby add-param GROUP_ACCEPT_SURPLUS_Demo
$ wallaby add-param NEGOTIATOR_ALLOW_QUOTA_OVERSUBSCRIPTION
$ wallaby add-param NEGOTIATOR_CONSIDER_PREEMPTION
$ wallaby add-param CLAIM_WORKLIFE
</code></pre>

<p>Here we disable the &#8220;claim worklife&#8221; feature by setting claims to expire immediately.   This prevents jobs under one accounting group from acquiring surplus quota and holding on to it when new jobs arrive under a different group:</p>

<pre><code>$ wallaby add-params-to-feature ExecuteNode CLAIM_WORKLIFE=0
$ wallaby add-params-to-subsystem startd CLAIM_WORKLIFE
$ wallaby add-params-to-feature Scheduler CLAIM_WORKLIFE=0
$ wallaby add-params-to-subsystem scheduler CLAIM_WORKLIFE
</code></pre>

<p>If you alter the configuration parameters, you will want the negotiator to reconfigure itself when you activate.  Here we declare the accounting group features as part of the negotiator subsystem:</p>

<pre><code>$ wallaby add-params-to-subsystem negotiator \
GROUP_NAMES \
GROUP_QUOTA_Demo \
GROUP_QUOTA_DYNAMIC_Demo.A \
GROUP_QUOTA_DYNAMIC_Demo.B \
GROUP_QUOTA_DYNAMIC_Demo.C \
NEGOTIATOR_ALLOW_QUOTA_OVERSUBSCRIPTION \
NEGOTIATOR_CONSIDER_PREEMPTION
</code></pre>

<p>Activate the configuration so far to tell subsystems about new parameters for reconfig</p>

<pre><code>$ wallaby activate
</code></pre>

<p>Now we construct the actual configuration as the <code>AccountingGroups</code> wallaby feature.  Here we are constructing a group <code>Demo</code> with three subgroups <code>Demo.{A|B|C}</code>.  In a multi-node pool with several cores, it is often easiest to play with group behavior by creating a sub-hierarchy such as this <code>Demo</code> sub-hierarchy, and configuring <code>GROUP_ACCEPT_SURPLUS_Demo=False</code>, so that the sub-hierarchy behaves with a well-defined total slot quota (in this case 15).  The sub-groups A,B and C each take 1/3 of the parent&#8217;s quota, so in this example each will receive 5 slots.</p>

<pre><code>$ wallaby add-params-to-feature AccountingGroups \
NEGOTIATOR_ALLOW_QUOTA_OVERSUBSCRIPTION=False \
NEGOTIATOR_CONSIDER_PREEMPTION=False \
GROUP_NAMES='Demo, Demo.A, Demo.B, Demo.C' \
GROUP_ACCEPT_SURPLUS=True \
GROUP_QUOTA_Demo=15 \
GROUP_ACCEPT_SURPLUS_Demo=False \
GROUP_QUOTA_DYNAMIC_Demo.A=0.333 \
GROUP_QUOTA_DYNAMIC_Demo.B=0.333 \
GROUP_QUOTA_DYNAMIC_Demo.C=0.333
</code></pre>

<p>With our accounting group feature created, we can apply it to the machine our negotiator daemon is running on.  Then snapshot our configuration modifications for reference, and activate the new configuration:</p>

<pre><code>$ wallaby add-features-to-node negotiator.node.com AccountingGroups
$ wallaby make-snapshot 'new acct group config'
$ wallaby activate
</code></pre>

<p>Now we will demonstrate the new feature in action.  Submit the following file to your pool, which submits 100 jobs each to groups <code>Demo.A</code> with durations randomly chosen between 25 and 35 seconds:</p>

<pre><code>universe = vanilla
cmd = /bin/sleep
args = $$([25 + random(11)])
transfer_executable = false
should_transfer_files = if_needed
when_to_transfer_output = on_exit
+AccountingGroup="Demo.A.user1"
queue 100
</code></pre>

<p>Once you make this submission, allow the jobs to negotiate, and you can check to see what accounting groups are running on slots by inspecting the value of <code>RemoteNegotiatingGroup</code> on slot ads.   You should see that subgroup <code>Demo.A</code> has acquired surplus and is running 15 jobs, as there are no jobs under groups <code>Demo.B</code> or <code>Demo.C</code> that need slots.  Note, due to jobs completing between negotiation cycles, these numbers can be less than the maximum possible at certain times.  If you have any other slots in the pool, they will show up in the output below as having either <code>undefined</code> negotiating group or possibly <code>&lt;none&gt;</code> if any other jobs are running.</p>

<pre><code>$ condor_status -format "%s\n" 'ifThenElse(RemoteNegotiatingGroup isnt undefined, string(RemoteNegotiatingGroup), "undefined")' -constraint 'True' | sort | uniq -c | awk '{ print $0; t += $1 } END { printf("%7d total\n",t) }'
 15 Demo.A
 50 &lt;none&gt;
 50 undefined
115 total
</code></pre>

<p>Now submit some jobs against <code>Demo.B</code> and <code>Demo.C</code>, like so:</p>

<pre><code>universe = vanilla
cmd = /bin/sleep
args = $$([25 + random(11)])
transfer_executable = false
should_transfer_files = if_needed
when_to_transfer_output = on_exit
+AccountingGroup="Demo.B.user1"
queue 100
+AccountingGroup="Demo.C.user1"
queue 100
</code></pre>

<p>Once these jobs begin to negotiate, we expect to see the jobs balanced between the three groups evenly, as we gave each group 1/3 of the quota:</p>

<pre><code>$ condor_status -format "%s\n" 'ifThenElse(RemoteNegotiatingGroup isnt undefined, string(RemoteNegotiatingGroup), "undefined")' -constraint 'True' | sort | uniq -c | awk '{ print $0; t += $1 } END { printf("%7d total\n",t) }'
  5 Demo.A
  5 Demo.B
  5 Demo.C
 50 &lt;none&gt;
 50 undefined
115 total
</code></pre>

<p>Finally, we see what happens if we remove jobs under <code>Demo.B</code>:</p>

<pre><code>$ condor_rm -constraint 'AccountingGroup =?= "Demo.B.user1"'
</code></pre>

<p>Now we should see quota start to share between <code>Demo.A</code> and <code>Demo.C</code>:</p>

<pre><code>$ condor_status -format "%s\n" 'ifThenElse(RemoteNegotiatingGroup isnt undefined, string(RemoteNegotiatingGroup), "undefined")' -constraint 'True' | sort | uniq -c | awk '{ print $0; t += $1 } END { printf("%7d total\n",t) }'
  7 Demo.A
  8 Demo.C
 50 &lt;none&gt;
 50 undefined
115 total
</code></pre>

<p>With this accounting group configuration in place, you can play with changing quotas for the accounting groups and observe the numbers of running jobs change in response.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Randomized Sleep Jobs in HTCondor Using Delayed Evaluation]]></title>
    <link href="http://erikerlandson.github.com/blog/2012/10/31/randomized-sleep-jobs-in-htcondor-using-delayed-evaluation/"/>
    <updated>2012-10-31T14:17:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2012/10/31/randomized-sleep-jobs-in-htcondor-using-delayed-evaluation</id>
    <content type="html"><![CDATA[<p>In some cases, when testing or demonstrating the performance of an HTCondor pool, it is useful to submit a plug of jobs with randomized running times.  The standard technique for controlling run times is to submit a classic &#8216;sleep&#8217; job.  However, randomizing the argument to sleep is another matter.  Luckily there is an easy way to do this with a single submit file, using delayed evaluation syntax.</p>

<p>A classad expression placed inside of a special enclosure, like this: <code>$$([ &lt;expr&gt; ])</code>, causes <code>&lt;expr&gt;</code> to be evaluated at the time the job ad is matched with a slot.  You can read more about delayed evaluation <a href="http://research.cs.wisc.edu/condor/manual/v7.8/condor_submit.html#78367">here</a>.  Consider the following example submit file:</p>

<pre><code>universe = vanilla
executable = /bin/sleep

# generate a random sleep duration when job is matched
args = $$([25 + random(11)])

# boilerplate to avoid file transfers and notifications
transfer_executable = false
should_transfer_files = no
when_to_transfer_output = on_exit
notification = never

# generate 100 copies of this job - each will evaluate the
# randomizing expression independently
queue 100
</code></pre>

<p>As you can see in the example above, the value of <code>args</code> is set to the delayed evaluation expression <code>$$([25 + random(11)])</code>, which will evaluate the classad expression <code>25 + random(11)</code> when each job ad matches a slot to run.  The <code>queue 100</code> command generates 100 separate job ads, and so the net effect is 100 jobs, which will each run a sleep job with a duration <em>randomly chosen</em> between 25 and 35.</p>

<p>If we submit this file to a condor pool, and let the jobs run to completion, we can check the pool history file to see how the <code>Args</code> attribute was set on the job ad using the special generative attribute <code>MATCH_EXP_Args</code>, and the <a href="http://erikerlandson.github.com/blog/2012/06/29/easy-histograms-and-tables-from-condor-jobs-and-slots/">cchist tool</a>:</p>

<pre><code>$ cchist condor_history 'MATCH_EXP_Args'
     11 25
      7 26
     10 27
      9 28
      7 29
     13 30
      8 31
      7 32
      8 33
      9 34
     11 35
    100 total
</code></pre>

<p>We can also sanity check our measure of actual run time, to see that those values are close to our values of <code>Args</code>:</p>

<pre><code>$ cchist condor_history 'CompletionDate-JobCurrentStartDate'
      1 25
     11 26
      9 27
      8 28
      9 29
      9 30
     12 31
      4 32
      8 33
     10 34
     12 35
      6 36
      1 37
    100 total
</code></pre>

<p>Have fun with easy random sleep jobs!</p>
]]></content>
  </entry>
  
</feed>
