
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Deferring Spark Actions to Lazy Transforms With the Promise RDD - tool monkey</title>
  <meta name="author" content="Erik Erlandson">

  
  <meta name="description" content="In a previous post I described a method for implementing the Scala drop transform for Spark RDDs. That implementation came at a cost of subverting &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://erikerlandson.github.com/blog/2014/07/29/deferring-spark-actions-to-lazy-transforms-with-the-promise-rdd/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="tool monkey" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

  <!-- enables inclusion of MathJax LaTeX: http://greglus.com/blog/2011/11/29/integrate-MathJax-LaTeX-and-MathML-Markup-in-Octopress/ -->
  <script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">tool monkey</a></h1>
  
    <h2>adventures of an unfrozen caveman programmer</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:erikerlandson.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Deferring Spark Actions to Lazy Transforms With the Promise RDD</h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-07-29T13:53:00-07:00" pubdate data-updated="true">Jul 29<span>th</span>, 2014</time>
        
        
         | <a href="#feedback">Feedback</a>
        
      </p>
    
  </header>


<div class="entry-content"><p>In a <a href="http://erikerlandson.github.io/blog/2014/07/27/some-implications-of-supporting-the-scala-drop-method-for-spark-rdds/">previous post</a> I described a method for implementing the Scala <code>drop</code> transform for Spark RDDs.  That implementation came at a cost of subverting the RDD lazy transform model; it forced the computation of one or more input RDD partitions at call time instead of deferring partition computation, and so behaved more like a Spark action than a transform.</p>

<p>In this followup post I will describe how to implement <code>drop</code> as a true lazy RDD transform, using a new RDD subclass: the Promise RDD.  A Promise RDD can be used to embed computations in the lazy transform formalism that otherwise would require non-lazy actions.</p>

<p>The Promise RDD (aka <code>PromiseRDD</code> subclass) is designed to encapsulate a single expression value in an RDD having exactly one row, to be evaluated <em>only</em> if and when its single partition is computed. It behaves somewhat analogously to a Scala <code>promise</code> structure, as it abstracts the expression such that any requests for its value (and hence its actual computation) may be deferred.</p>

<p>The definition of PromiseRDD is compact:</p>

<pre><code>class PromisePartition extends Partition {
  // A PromiseRDD has exactly one partition, by construction:
  override def index = 0
}

/**
 * A way to represent the concept of a promised expression as an RDD, so that it
 * can operate naturally inside the lazy-transform formalism
 */
class PromiseRDD[V: ClassTag](expr: =&gt; (TaskContext =&gt; V),
                              context: SparkContext, deps: Seq[Dependency[_]])
  extends RDD[V](context, deps) {

  // This RDD has exactly one partition by definition, since it will contain
  // a single row holding the 'promised' result of evaluating 'expr' 
  override def getPartitions = Array(new PromisePartition)

  // compute evaluates 'expr', yielding an iterator over a sequence of length 1:
  override def compute(p: Partition, ctx: TaskContext) = List(expr(ctx)).iterator
}
</code></pre>

<p>A PromiseRDD is constructed with the expression of choice, embodied as a function from a <code>TaskContext</code> to the implied expression type.   Note that <em>only</em> the task context is a parameter;  Any other inputs needed to evaluate the expression must be present in the closure of <code>expr</code>.  This allows the expression to be of very general form: its value may depend on a single input RDD, or multiple RDDs, or no RDDs at all.  It receives an arbitrary sequence of partition dependencies which is the responsibility of the calling code to assemble.  Again, this allows substantial generality in the form of the expression: the PromiseRDD dependencies can correspond to any arbitrary input dependencies assumed by the expression.  The dependencies can be tuned to exactly what input partitions are required.</p>

<p>As a motivating example, consider how a PromiseRDD can be used to promote <code>drop</code> to a true lazy transform.  The aspect of computing <code>drop</code> that threatens laziness is the necessity of determining the location of the boundary partition (<a href="http://erikerlandson.github.io/blog/2014/07/27/some-implications-of-supporting-the-scala-drop-method-for-spark-rdds/">see previous discussion</a>).  However, this portion of the computation can in fact be encapsulated in a PromiseRDD.  The details of constructing such a PromiseRDD can be <a href="https://github.com/erikerlandson/spark/blob/promise_rdd_blog/core/src/main/scala/org/apache/spark/rdd/DropRDDFunctions.scala#L46">viewed here</a>.  The following illustration summarizes the topology of the dependency DAG that is constructed:</p>

<p><img src="/assets/images/rdd_drop/rdd_drop_promise.png" alt="image" /></p>

<p>As the dependency diagram shows, the PromiseRDD responsible for locating the boundary partition depends on each partition of the original input RDD.  The actual computation is likely to only request the first input partition, but all partitions might be required to handle all possible arguments to <code>drop</code>.   In turn, the location information given by the PromiseRDD is depended upon by each output partition.  Input partitions are either passed to the output, or used to compute the boundary, and so none of the partition computation is wasted.</p>

<p>Observe that the scheduler remains in charge of when partitions are computed.  An advantage to using a PromiseRDD is that it works within Spark&#8217;s computational model, instead of forcing it.</p>

<p>The following brief example demonstrates that <code>drop</code> implemented using a PromiseRDD satisfies the lazy transform model:</p>

<pre><code>// create data rdd with values 0 thru 9
scala&gt; val data = sc.parallelize(0 until 10)
data: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at &lt;console&gt;:12

// drop the first 3 rows
// note that no action is performed -- this transform is lazy
scala&gt; val rdd = data.drop(3)
rdd: org.apache.spark.rdd.RDD[Int] = $anon$1[2] at drop at &lt;console&gt;:14

// collect the values.  This action kicks off job scheduling and execution
scala&gt; rdd.collect
14/07/28 12:16:13 INFO SparkContext: Starting job: collect at &lt;console&gt;:17
... job scheduling and execution output ...

res0: Array[Int] = Array(3, 4, 5, 6, 7, 8, 9)

scala&gt;
</code></pre>

<p>In this post, I have described the Promise RDD, an RDD subclass that can be used to encapsulate computations in the lazy transform formalism that would otherwise require non-lazy actions.  As an example, I have outlined a lazy transform implementation of <code>drop</code> that uses PromiseRDD.</p>
</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Erik Erlandson</span></span>

      








  


<time datetime="2014-07-29T13:53:00-07:00" pubdate data-updated="true">Jul 29<span>th</span>, 2014</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/rdd/'>RDD</a>, <a class='category' href='/blog/categories/computing/'>computing</a>, <a class='category' href='/blog/categories/scala/'>scala</a>, <a class='category' href='/blog/categories/spark/'>spark</a>
  
</span>


      <br>
<a id="feedback"></a>Feedback • 
 
    <script type="text/javascript" src="//platform.twitter.com/widgets.js"></script>
    
  <a href="https://twitter.com/intent/tweet?text=@manyangled%20re:%20http://erikerlandson.github.com/blog/2014/07/29/deferring-spark-actions-to-lazy-transforms-with-the-promise-rdd/">Reply to this post on Twitter</a> • 
 
<a href="mailto:erikerlandson@yahoo.com">Email the author</a>

    </p>
    
      <div class="sharing">
  
  <a href="http://twitter.com/share" class="twitter-share-button" data-url="http://erikerlandson.github.com/blog/2014/07/29/deferring-spark-actions-to-lazy-transforms-with-the-promise-rdd/" data-via="manyangled" data-counturl="http://erikerlandson.github.com/blog/2014/07/29/deferring-spark-actions-to-lazy-transforms-with-the-promise-rdd/" >Tweet</a>
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2014/07/27/some-implications-of-supporting-the-scala-drop-method-for-spark-rdds/" title="Previous Post: Some Implications of Supporting the Scala drop Method for Spark RDDs">&laquo; Some Implications of Supporting the Scala drop Method for Spark RDDs</a>
      
      
        <a class="basic-alignment right" href="/blog/2014/08/09/implementing-an-rdd-scanleft-transform-with-cascade-rdds/" title="Next Post: Implementing an RDD scanLeft Transform With Cascade RDDs">Implementing an RDD scanLeft Transform With Cascade RDDs &raquo;</a>
      
    </p>
  </footer>
</article>

</div>

<aside class="sidebar">
  
    <section>
  <h1>About The Author</h1>
  <p>Erik is a senior software engineer on the <a href="http://www.redhat.com">Red Hat</a> Emerging Technologies Group.</p>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2016/12/19/converging-monoid-addition-for-t-digest/">Converging Monoid Addition for T-Digest</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/09/05/expressing-map-reduce-as-a-left-folding-monoid/">Encoding Map-Reduce As A Monoid With Left Folding</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/08/31/supporting-competing-apis-in-scala-can-better-package-factoring-help/">Supporting Competing APIs in Scala -- Can Better Package Factoring Help?</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/08/03/x-medoids-using-minimum-description-length-to-identify-the-k-in-k-medoids/">Using Minimum Description Length to Optimize the 'K' in K-Medoids</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/07/09/approximating-a-pdf-of-distances-with-a-gamma-distribution/">Approximating a PDF of Distances With a Gamma Distribution</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating...</li>
  </ul>
  
  <a href="https://github.com/erikerlandson">@erikerlandson</a> on GitHub
  
  <script type="text/javascript">
    $.domReady(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'erikerlandson',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>


<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets">
    <li class="loading">Status updating...</li>
  </ul>
  <script type="text/javascript">
    $.domReady(function(){
      getTwitterFeed("manyangled", 4, true);
    });
  </script>
  <script src="/javascripts/twitter.js" type="text/javascript"> </script>
  
    <a href="http://twitter.com/manyangled" class="twitter-follow-button" data-show-count="false">Follow @manyangled</a>
  
</section>





  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2017 - Erik Erlandson -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
