
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>tool monkey</title>
  <meta name="author" content="Erik Erlandson">

  
  <meta name="description" content="On a Condor pool, a Last In First Out (LIFO) preemption policy favors choosing the longest-running job from the available preemption options. &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://erikerlandson.github.com/blog/page/5/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="tool monkey" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

  <!-- enables inclusion of MathJax LaTeX: http://greglus.com/blog/2011/11/29/integrate-MathJax-LaTeX-and-MathML-Markup-in-Octopress/ -->
  <script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">tool monkey</a></h1>
  
    <h2>adventures of an unfrozen caveman programmer</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:erikerlandson.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/07/19/lifo-and-fifo-preemption-policies-for-a-condor-pool/">LIFO and FIFO Preemption Policies for a Condor Pool</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-07-19T13:57:00-07:00" pubdate data-updated="true">Jul 19<span>th</span>, 2012</time>
        
        
         | <a href="/blog/2012/07/19/lifo-and-fifo-preemption-policies-for-a-condor-pool/#feedback">Feedback</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>On a Condor pool, a Last In First Out (LIFO) preemption policy favors choosing the longest-running job from the available preemption options.  Correspondingly, a First In First Out (FIFO) policy favors the most-recent job for preemption.</p>

<p>Configuring a LIFO or FIFO policy is easy, using the <code>PREEMPTION_RANK</code> configuration variable.  <code>PREEMPTION_RANK</code> defines a ClassAd expression that is evaluated for all slots that are candidates for claim preemption, and causes those candidates to be sorted so that the candidates with the highest rank value are considered first.   Therefore, to implement a LIFO (or FIFO) preemption policy, one needs reference an expression that represents the claiming job&#8217;s running time:</p>

<pre><code># LIFO preemption: favor preempting jobs that have been running the longest
PREEMPTION_RANK = TotalJobRunTime
# turn this into FIFO by using (-TotalJobRunTime)
</code></pre>

<p>The attribute <code>TotalJobRunTime</code> represents the amount of time a job has been running on its claim (generally, this is effectively equivalent to total running time, unless your job supports some form of checkpointing), and so ranking preemption candidates by this attribute results in LIFO preemption, and ranking by its negative provides FIFO preemption.</p>

<p>Note that <code>PREEMPTION_RANK</code> applies <em>only</em> to candidates that have already met the requirements defined on <code>PREEMPTION_REQUIREMENTS</code>, or the slot-centric preemption policy defined by <code>RANK</code>.  <code>PREEMPTION_RANK</code> does not itself determine what claimed slots are considered by a job for preemption.</p>

<p>To demonstrate LIFO and FIFO preemption in action, consider the following configuration:</p>

<pre><code># turn off scheduler optimizations, as they can sometimes obscure the
# negotiator/matchmaker behavior
CLAIM_WORKLIFE = 0
CLAIM_PARTITIONABLE_LEFTOVERS = False

# reduce update latencies for faster testing response
UPDATE_INTERVAL = 15
NEGOTIATOR_INTERVAL = 20
SCHEDD_INTERVAL = 15

# for demonstration purposes, make sure basic preemption knobs are 'on'
MAXJOBRETIREMENTTIME = 0
PREEMPTION_REQUIREMENTS = True
NEGOTIATOR_CONSIDER_PREEMPTION = True
RANK = 0.0

# LIFO preemption: favor preempting jobs that have been running the longest
PREEMPTION_RANK = TotalJobRunTime
# turn this into FIFO by using (-TotalJobRunTime)

# define 3 cpus to provide fodder for preemption
NUM_CPUS = 3
</code></pre>

<p>Begin by spinning up a condor pool with the configuration above.  When the pool is operating, fill the three slots with jobs for &#8216;user1&#8217;, with a delay to ensure that jobs have easily distinguishable values for <code>TotalJobRunTime</code>:</p>

<pre><code>$ cat /tmp/user1.jsub 
universe = vanilla
cmd = /bin/sleep
args = 600
should_transfer_files = if_needed
when_to_transfer_output = on_exit
+AccountingGroup="user1"
queue 1

$ condor_submit /tmp/user1.jsub ; sleep 30 ; condor_submit /tmp/user1.jsub ; sleep 30 ; condor_submit /tmp/user1.jsub
</code></pre>

<p>Once these jobs have all started running, verify their run times using <a href="http://erikerlandson.github.com/blog/2012/06/29/easy-histograms-and-tables-from-condor-jobs-and-slots/">ccsort</a>:</p>

<pre><code>$ ccsort condor_status JobID TotalJobRunTime AccountingGroup
1.0 | 78 | user1@localdomain
2.0 | 36 | user1@localdomain
3.0 | 16 | user1@localdomain
</code></pre>

<p>to make preemption easy, give user1 a low priority:</p>

<pre><code>$ condor_userprio -setprio user1@localdomain 10
</code></pre>

<p>Now, we will submit some jobs for &#8216;user2&#8217;: which will be allowed to preempt jobs for &#8216;user1&#8217;.  We should see that the longest-running job for user1 is chosen each time:</p>

<pre><code>$ condor_submit /tmp/user2.jsub
Submitting job(s).
1 job(s) submitted to cluster 4.

$ ccsort condor_status JobID TotalJobRunTime AccountingGroup
2.0 | 81 | user1@localdomain
3.0 | 61 | user1@localdomain
4.0 | 2 | user2@localdomain

$ condor_submit /tmp/user2.jsub
Submitting job(s).
1 job(s) submitted to cluster 5.

$ ccsort condor_status JobID TotalJobRunTime AccountingGroup
3.0 | 91 | user1@localdomain
4.0 | 32 | user2@localdomain
5.0 | 3 | user2@localdomain
</code></pre>

<p>Now we change LIFO to FIFO and demonstrate.  Switch the sign of <code>TotalJobRunTime</code>:</p>

<pre><code># Now I am FIFO!
PREEMPTION_RANK = -TotalJobRunTime
</code></pre>

<p>And restart the negotiator, and check on our currently running jobs:</p>

<pre><code>$ condor_restart -negotiator

$ ccsort condor_status JobID TotalJobRunTime AccountingGroup
3.0 | 151 | user1@localdomain
4.0 | 92 | user2@localdomain
5.0 | 49 | user2@localdomain
</code></pre>

<p>Now, set up &#8216;user2&#8217; for easy preemption like user1:</p>

<pre><code>$ condor_userprio -setprio user2@localdomain 10
</code></pre>

<p>And submit some jobs for user3.  Since we reconfigured for FIFO preemption, we should now see the <em>most recent</em> job preempted each time (in this case, these should both be the &#8216;user2&#8217; jobs):</p>

<pre><code>$ condor_submit /tmp/user3.jsub
Submitting job(s).
1 job(s) submitted to cluster 6.

$ ccsort condor_status JobID TotalJobRunTime AccountingGroup
3.0 | 241 | user1@localdomain
4.0 | 182 | user2@localdomain
6.0 | 15 | user3@localdomain

$ condor_submit /tmp/user3.jsub
Submitting job(s).
1 job(s) submitted to cluster 7.

$ ccsort condor_status JobID TotalJobRunTime AccountingGroup
3.0 | 301 | user1@localdomain
6.0 | 75 | user3@localdomain
7.0 | 17 | user3@localdomain
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/07/10/configuring-minimum-and-maximum-resources-for-mission-critical-jobs-in-a-condor-pool/">Configuring Minimum and Maximum Resources for Mission Critical Jobs in a Condor Pool</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-07-10T15:49:00-07:00" pubdate data-updated="true">Jul 10<span>th</span>, 2012</time>
        
        
         | <a href="/blog/2012/07/10/configuring-minimum-and-maximum-resources-for-mission-critical-jobs-in-a-condor-pool/#feedback">Feedback</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Suppose you are administering a Condor pool for a company or organization where you want to support both &#8220;mission critical&#8221; (MC) jobs and &#8220;regular&#8221; (R) jobs.  Mission critical jobs might include IT functions such as backups, or payroll, or experiment submissions from high profile internal customers.  Regular jobs encompass any jobs that can be delayed, or preempted, with little or no consequence.</p>

<p>As part of your Condor policy for supporting MC jobs, you may want to ensure that these jobs always have access to a minimum set of resources on the pool.  In order to maintain the peace, you may also wish to set a pool-wide maximum on MC jobs, to leave some number of resources available for R jobs as well.  The following configuration, which I will discuss and demonstrate below, configures a pool-wide minimum <em>and maximum</em> for resources allocated to MC jobs.  Additionally, it shows how to dedicate MC resources on specific nodes in the pool.</p>

<pre><code># turn off scheduler optimizations, as they can sometimes obscure the
# negotiator/matchmaker behavior
CLAIM_WORKLIFE = 0

# turn off adaptive loops in negotiation - these give a single
# 'traditional' one-pass negotiation cycle
GROUP_QUOTA_MAX_ALLOCATION_ROUNDS = 1
GROUP_QUOTA_ROUND_ROBIN_RATE = 1e100

# for demonstration purposes, make sure basic preemption knobs are 'on'
MAXJOBRETIREMENTTIME = 0
PREEMPTION_REQUIREMENTS = True
NEGOTIATOR_CONSIDER_PREEMPTION = True
RANK = 0.0

# extracts the acct group name, e.g. "MC.user@localdomain" --&gt; "MC"
SUBMIT_EXPRS = AcctGroupName CCLimits
AcctGroupName = ifThenElse(my.AccountingGroup =!= undefined, \
                           regexps("^([^@]+)\.[^.]+", my.AccountingGroup, "\1"), "&lt;none&gt;")
CCLimits = ifThenElse(my.ConcurrencyLimits isnt undefined, \
                      my.ConcurrencyLimits, "***")
# note - the "my." scoping in the above is important - 
# these attribute names may also occur in a machine ad

# oversubscribe the machine to simulate 20 nodes on a single box
NUM_CPUS = 20

# accounting groups, each with equal quota
# Mission Critical jobs are associated with group 'MC'
# Regular jobs are associated with group 'R'
GROUP_NAMES = MC, R
GROUP_QUOTA_MC = 10
GROUP_QUOTA_R = 10

# enable 'autoregroup' for groups, which gives all grps
# a chance to compete for resources above their quota
GROUP_AUTOREGROUP = TRUE
GROUP_ACCEPT_SURPLUS = FALSE

# a pool-wide limit on MC job resources
# note this is a "hard" limit - with this example config, MC jobs cannot exceed this
# limit even if there are free resources
MC_JOB_LIMIT = 15

# special slot for MC jobs, effectively reserves
# specific resources for MC jobs on a particular node.
SLOT_TYPE_1 = cpus=1
SLOT_TYPE_1_PARTITIONABLE = FALSE
NUM_SLOTS_TYPE_1 = 5

# Allocate any "non-MC" remainders here:
SLOT_TYPE_2 = cpus=1
SLOT_TYPE_2_PARTITIONABLE = FALSE
NUM_SLOTS_TYPE_2 = 15

# note - in the above, I declared static slots for the purposes of 
# demonstration, because partitionable slots interfere with clarity of
# APPEND_RANK expr behavior, due to being peeled off 1 slot at a time
# in the negotiation cycle

# A job counts against MC_JOB_LIMIT if and only if it is of the "MC" 
# accounting group, otherwise it won't be run
START = ($(START)) &amp;&amp; (((AcctGroupName =?= "MC") &amp;&amp; (stringListIMember("mc_job", CCLimits))) \
              || ((AcctGroupName =!= "MC") &amp;&amp; !stringListIMember("mc_job", CCLimits)))

# rank from the slot's POV:
# "MC-reserved" slots (slot type 1) prefer MC jobs,
# while other slots have no preference
RANK = ($(RANK)) + 10.0*ifThenElse((SlotTypeID=?=1) || (SlotTypeID=?=-1), \
                                   1.0 * (AcctGroupName =?= "MC"), 0.0)

# rank from the job's POV:
# "MC" jobs prefer any specially allocated per-node resources
# any other jobs prefer other jobs
APPEND_RANK = 10.0*ifThenElse(AcctGroupName =?= "MC", \
              1.0*((SlotTypeID=?=1) || (SlotTypeID=?=-1)), \
              1.0*((SlotTypeID=!=1) &amp;&amp; (SlotTypeID=!=-1)))

# If a job negotiated under "MC", it may not be preempted by a job that did not.
PREEMPTION_REQUIREMENTS = ($(PREEMPTION_REQUIREMENTS)) &amp;&amp; \
                          ((SubmitterNegotiatingGroup =?= "MC") || \
                           (RemoteNegotiatingGroup =!= "MC"))
</code></pre>

<p>Next I will discuss some of the components from this configuration and their purpose.  The first goal of a pool-wide resource minimum is accomplished by declaring accounting groups for MC and R jobs to run against:</p>

<pre><code>GROUP_NAMES = MC, R
GROUP_QUOTA_MC = 10
GROUP_QUOTA_R = 10
</code></pre>

<p>We will enable the autoregroup feature, which allows jobs to also compete for any unused resources <em>without</em> regard for accounting groups, after all jobs have had an opportunity to match under their group.  This is a good way to allow opportunistic resource usage, and also will facilitate demonstration.</p>

<pre><code>GROUP_AUTOREGROUP = TRUE
</code></pre>

<p>A pool-wide maximum on resource usage by MC jobs can be accomplished with a concurrency limit.  Note that this limit is larger than the group quota for MC jobs:</p>

<pre><code>MC_JOB_LIMIT = 15
</code></pre>

<p>It is also desirable to enforce the semantic that MC jobs <em>must</em> &#8216;charge&#8217; against the MC_JOB concurrency limit, and conversely that any non-MC jobs are not allowed to charge against that limit.   Adding the following clause to the START expression enforces this semantic by preventing any jobs not following this rule from running:</p>

<pre><code>START = ($(START)) &amp;&amp; (((AcctGroupName =?= "MC") &amp;&amp; (stringListIMember("mc_job", CCLimits))) \
                    || ((AcctGroupName =!= "MC") &amp;&amp; !stringListIMember("mc_job", CCLimits)))
</code></pre>

<p>The final resource related goal for MC jobs is to reserve a certain number of resources on specific machines in the pool.  In the configuration above that is accomplished by declaring a special slot type, as here where we declare 5 slots of slot type 1 (the remaining 15 slots are declared via slot type 2, above):</p>

<pre><code>SLOT_TYPE_1 = cpus=1
SLOT_TYPE_1_PARTITIONABLE = FALSE
NUM_SLOTS_TYPE_1 = 5
</code></pre>

<p>Then we add a term to the slot rank expression that will cause any slot of type 1 to preempt a non-MC job in favor of an MC job (the factor of 10.0 is an optional tuning factor to allow this term to either take priority over other terms, or cede priority):</p>

<pre><code>RANK = ($(RANK)) + 10.0*ifThenElse((SlotTypeID=?=1) || (SlotTypeID=?=-1), \
                                   1.0 * (AcctGroupName =?= "MC"), 0.0)
</code></pre>

<p>(Note, slot type -1 would represent a dynamic slot derived from a partitionable slot of type 1.  In this example, all slots are static)</p>

<p>An additional &#8220;job side&#8221; rank term can also be helpful, to allow MC jobs to try and match special MC reserved slots first, and to allow non-MC jobs to avoid reserved slots if possible:</p>

<pre><code>APPEND_RANK = 10.0*ifThenElse(AcctGroupName =?= "MC", \
              1.0*((SlotTypeID=?=1) || (SlotTypeID=?=-1)), \
              1.0*((SlotTypeID=!=1) &amp;&amp; (SlotTypeID=!=-1)))
</code></pre>

<p>Lastly, preemption policy can be configured to help enforce resource allocations for MC jobs.  Here, a preemption clause is added to prevent any non-MC job from preempting a MC job, and specifically one that <em>negotiated</em> under its group quota (that is, it refers to RemoteNegotiatingGroup):</p>

<pre><code>PREEMPTION_REQUIREMENTS = ($(PREEMPTION_REQUIREMENTS)) &amp;&amp; \
                          ((SubmitterNegotiatingGroup =?= "MC") || \
                           (RemoteNegotiatingGroup =!= "MC"))
</code></pre>

<p>With the example policy configuration unpacked, we can demonstrate its behavior.  Begin by spinning up a pool with the above configuration.  Verify that we have the expected slots (You can refer <a href="http://erikerlandson.github.com/blog/2012/06/29/easy-histograms-and-tables-from-condor-jobs-and-slots/">here to learn more about cchist</a>):</p>

<pre><code>$ cchist condor_status RemoteGroup RemoteNegotiatingGroup SlotTypeID
      5 undefined | undefined | 1
     15 undefined | undefined | 2
     20 total
</code></pre>

<p>Next, submit 20 Mission Critical jobs (getting enough sleep is critical):</p>

<pre><code>universe = vanilla
cmd = /bin/sleep
args = 600
should_transfer_files = if_needed
when_to_transfer_output = on_exit
concurrency_limits = mc_job
+AccountingGroup="MC.user"
queue 20
</code></pre>

<p>Since we configured a pool-wide maximum of 15 cores, we want to verify that we did not exceed that limit.  Note that 5 slots were negotiated under &#8220;&lt;none>&#8221;, via the autoregroup feature (denoted by the value in RemoteNegotiatingGroup), as the group quota for MC is 10, and the MC jobs were able to match their pool limit of 15:</p>

<pre><code>$ cchist condor_status RemoteGroup RemoteNegotiatingGroup SlotTypeID
      5 MC | MC | 1
      5 MC | MC | 2
      5 MC | &lt;none&gt; | 2
      5 undefined | undefined | 2
     20 total
</code></pre>

<p>Next we set the MC submitter to a lower priority (i.e. higher prio value):</p>

<pre><code>$ condor_userprio -setprio MC.user@localdomain 10
The priority of MC.user@localdomain was set to 10.000000
</code></pre>

<p>Now we submit 15 &#8220;regular&#8221; R jobs:</p>

<pre><code>universe = vanilla
cmd = /bin/sleep
args = 600
should_transfer_files = if_needed
when_to_transfer_output = on_exit
+AccountingGroup="R.user"
queue 15
</code></pre>

<p>The submitter &#8220;R.user&#8221; currently has higher priority than &#8220;MC.user&#8221;, however our preemption policy will only allow preemption of MC jobs that negotiated under &#8220;&lt;none>&#8221;, as those were matched outside the accounting group&#8217;s quota.  So we see that jobs with RemoteNegotiatingGroup == &#8220;MC&#8221; remain un-preempted:</p>

<pre><code>$ cchist condor_status RemoteGroup RemoteNegotiatingGroup SlotTypeID
      5 MC | MC | 1
      5 MC | MC | 2
     10 R | R | 2
     20 total
</code></pre>

<p>The above demonstrates the pool-wide quota and concurrentcy limits for MC jobs.  To demonstrate per-machine resources, we start by clearing all jobs:</p>

<pre><code>$ condor_rm -all
</code></pre>

<p>Submit 20 &#8220;R&#8221; jobs (similar to above), and verify that they occupy all slots, including the slots with SlotTypeID == 1, which are reserved for MC jobs (but not currently being used):</p>

<pre><code>$ cchist condor_status RemoteGroup RemoteNegotiatingGroup SlotTypeID
      5 R | &lt;none&gt; | 1
      5 R | &lt;none&gt; | 2
     10 R | R | 2
     20 total
</code></pre>

<p>Submit 10 MC jobs.  &#8220;MC.user&#8221; does not have sufficient priority to preempt &#8220;R.user&#8221;, however the slot rank expression <em>will</em> preempt non-MC jobs for an MC job on slots of type 1, and so we see that MC jobs <em>do</em> acquire the 5 type-1 slots reserved on this node:</p>

<pre><code>$ cchist condor_status RemoteGroup RemoteNegotiatingGroup SlotTypeID
      5 MC | MC | 1
      5 R | &lt;none&gt; | 2
     10 R | R | 2
     20 total
</code></pre>

<p>Finally, as an encore you can verify that jobs run against the MC accounting group must also charge against the MC_JOB concurrency limit, and non-MC jobs may not charge against it.  Again, start with an empty queue:</p>

<pre><code>$ condor_rm -all
</code></pre>

<p>Now, submit &#8216;bad&#8217; jobs that use accounting group &#8220;MC&#8221; but does not use the &#8220;mc_job&#8221; concurrency limits:</p>

<pre><code>universe = vanilla
cmd = /bin/sleep
args = 600
should_transfer_files = if_needed
when_to_transfer_output = on_exit
+AccountingGroup="MC.user"
queue 10
</code></pre>

<p>And likewise some &#8216;bad&#8217; regular jobs that attempt to use the &#8220;mc_job&#8221; concurrency limits:</p>

<pre><code>universe = vanilla
cmd = /bin/sleep
args = 600
should_transfer_files = if_needed
when_to_transfer_output = on_exit
concurrency_limits = mc_job
+AccountingGroup="R.user"
queue 10
</code></pre>

<p>You should see that <em>none</em> of these jobs are allowed to run:</p>

<pre><code>$ cchist condor_status RemoteGroup RemoteNegotiatingGroup SlotTypeID
      5 undefined | undefined | 1
     15 undefined | undefined | 2
     20 total
$ cchist condor_q JobStatus
     20 1
     20 total
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/07/05/deriving-an-incremental-form-of-the-polynomial-regression-equations/">Deriving an Incremental Form of the Polynomial Regression Equations</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-07-05T19:46:00-07:00" pubdate data-updated="true">Jul 5<span>th</span>, 2012</time>
        
        
         | <a href="/blog/2012/07/05/deriving-an-incremental-form-of-the-polynomial-regression-equations/#feedback">Feedback</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Incremental, or on-line, algorithms are increasingly popular as data set sizes explode and web enabled applications create environments where new data arrive continuously (that is, incrementally) from clients out on the internet.</p>

<p>Recently I have been doing some <a href="https://github.com/erikerlandson/ratorade">experiments</a> with applying one of the <em>oldest</em> incremental algorithms to the task of rating predictions: computing a linear regression with a coefficient of correlation.  The incremental formulae look like this:</p>

<div markdown="0">
To find coefficients \( a_0, a_1 \) of the linear predictor \( y = a_0 + a_1 x \):
&#92;[
a_1 = &#92;frac {n &#92;Sigma x y - &#92;Sigma x &#92;Sigma y} {n &#92;Sigma x^2 - &#92;left( &#92;Sigma x &#92;right) ^2 }
&#92;hspace{1 cm}
a_0 = &#92;frac { &#92;Sigma y - a_1 &#92;Sigma x } {n}
&#92;]
The correlation coefficient of this predictor is given by:
&#92;[
&#92;rho (x,y) = &#92;frac {n &#92;Sigma x y - &#92;Sigma x &#92;Sigma y} {&#92;sqrt {n &#92;Sigma x^2 - &#92;left( &#92;Sigma x &#92;right) ^ 2 } &#92;sqrt {n &#92;Sigma y^2 - &#92;left( &#92;Sigma y &#92;right) ^ 2 } }
&#92;]
</div>


<p>As you can see from the formulae above, it is sufficient to maintain running sums</p>

<div markdown="0"> &#92;[ n, &#92;Sigma x, &#92;Sigma y, &#92;Sigma x^2, &#92;Sigma y^2, &#92;Sigma x y &#92;] </div>


<p>and so any new data can be included incrementally - that is, the model can be updated without revisiting any previous data.</p>

<p>Working with these models caused me to wonder if there was a way to generalize them to obtain incremental formulae for a quadratic predictor, or generalized polynomials.  As it happens, there is.  To show how, I&#8217;ll derive an incremental formula for the coefficients of the quadratic predictor:</p>

<div markdown="0">
&#92;[
y = a_0 + a_1 x + a_2 x^2
&#92;]
</div>


<p>Recall the <a href="http://en.wikipedia.org/wiki/Polynomial_regression#Matrix_form_and_calculation_of_estimates">matrix formula</a> for polynomial regression:</p>

<div markdown="0">
&#92;[ &#92;vec{a} = &#92;left( X^T X &#92;right) ^ {-1} X^T &#92;vec{y} &#92;]

where, in the quadratic case:

&#92;[
&#92;vec{a} = &#92;left( &#92;begin{array} {c}
a_0 &#92;&#92;
a_1 &#92;&#92;
a_2 &#92;&#92;
&#92;end{array} &#92;right)
&#92;hspace{1 cm}
X = &#92;left( &#92;begin{array} {ccc}
1 & x_1 & x_1^2 &#92;&#92;
1 & x_2 & x_2^2 &#92;&#92;
  &  \vdots  & &#92;&#92;
1 & x_n & x_n^2 &#92;&#92;
&#92;end{array} &#92;right)
&#92;hspace{1 cm}
&#92;vec{y} = &#92;left( &#92;begin{array} {c}
y_1 &#92;&#92;
y_2 &#92;&#92;
\vdots &#92;&#92;
y_n &#92;&#92;
&#92;end{array} &#92;right)
&#92;]

Note that we can apply the definition of matrix multiplication and express the two products &#92;( X^T X &#92;) and &#92;( X^T &#92;vec{y} &#92;) from the above formula like so:
&#92;[
X^T X = 
&#92;left( &#92;begin{array} {ccc}
n & &#92;Sigma x & &#92;Sigma x^2 &#92;&#92;
&#92;Sigma x & &#92;Sigma x^2 & &#92;Sigma x^3 &#92;&#92;
&#92;Sigma x^2 & &#92;Sigma x^3 & &#92;Sigma x^4 &#92;&#92;
&#92;end{array} &#92;right)
&#92;hspace{1 cm}
X^T &#92;vec{y} =
&#92;left( &#92;begin{array} {c}
&#92;Sigma y &#92;&#92;
&#92;Sigma x y &#92;&#92;
&#92;Sigma x^2 y &#92;&#92;
&#92;end{array} &#92;right)
&#92;]
</div>


<p>And so now we can express the formula for our quadratic coefficients in this way:</p>

<div markdown="0">
&#92;[
&#92;left( &#92;begin{array} {c}
a_0 &#92;&#92;
a_1 &#92;&#92;
a_2 &#92;&#92;
&#92;end{array} &#92;right)
=
&#92;left( &#92;begin{array} {ccc}
n & &#92;Sigma x & &#92;Sigma x^2 &#92;&#92;
&#92;Sigma x & &#92;Sigma x^2 & &#92;Sigma x^3 &#92;&#92;
&#92;Sigma x^2 & &#92;Sigma x^3 & &#92;Sigma x^4 &#92;&#92;
&#92;end{array} &#92;right)
^ {-1}
&#92;left( &#92;begin{array} {c}
&#92;Sigma y &#92;&#92;
&#92;Sigma x y &#92;&#92;
&#92;Sigma x^2 y &#92;&#92;
&#92;end{array} &#92;right)
&#92;]
</div>


<p>Note that we now have a matrix formula that is expressed entirely in sums of various terms in x and y, which means that it can be maintained incrementally, as we desired.  If you have access to a matrix math package, you might very well declare victory right here, as you can easily construct these matrices and do the matrix arithmetic at will to obtain the model coefficients.  However, as an additional step I applied <a href="http://www.sagemath.org/">sage</a> to do the symbolic matrix inversion and multiplication to give:</p>

<div markdown="0">
&#92;[
&#92;small
a_0 =
&#92;frac {1} {Z}
&#92;left( 
- &#92;left( &#92;Sigma x^3 &#92;Sigma x - &#92;left( &#92;Sigma x^2 &#92;right)^2 &#92;right) &#92;Sigma x^2 y  +  &#92;left( &#92;Sigma x^4  &#92;Sigma x - &#92;Sigma x^3 &#92;Sigma x^2 &#92;right) &#92;Sigma x y  -  &#92;left( &#92;Sigma x^4 &#92;Sigma x^2 - &#92;left( &#92;Sigma x^3 &#92;right)^2 &#92;right) &#92;Sigma y 
&#92;right)
&#92;normalsize
&#92;]
&#92;[
&#92;small
a_1 =
&#92;frac {1} {Z}
&#92;left( 
&#92;left( n &#92;Sigma x^3  - &#92;Sigma x^2 &#92;Sigma x &#92;right) &#92;Sigma x^2 y  -  &#92;left( n &#92;Sigma x^4 - &#92;left( &#92;Sigma x^2 &#92;right) ^2 &#92;right) &#92;Sigma x y  +  &#92;left( &#92;Sigma x^4 &#92;Sigma x - &#92;Sigma x^3 &#92;Sigma x^2 &#92;right) &#92;Sigma y
&#92;right)
&#92;normalsize
&#92;]
&#92;[
&#92;small
a_2 =
&#92;frac {1} {Z}
&#92;left( 
- &#92;left( n &#92;Sigma x^2 - &#92;left( &#92;Sigma x &#92;right) ^2 &#92;right) &#92;Sigma x^2 y  +  &#92;left( n &#92;Sigma x^3 - &#92;Sigma x^2 &#92;Sigma x &#92;right) &#92;Sigma x y  -  &#92;left( &#92;Sigma x^3 &#92;Sigma x - &#92;left( &#92;Sigma x^2 &#92;right) ^2 &#92;right) &#92;Sigma y 
&#92;right)
&#92;normalsize
&#92;]
where:
&#92;[
Z = n &#92;left( &#92;Sigma x^3 &#92;right) ^ 2 - 2 &#92;Sigma x^3 &#92;Sigma x^2 &#92;Sigma x + &#92;left( &#92;Sigma x^2 &#92;right) ^3 - &#92;left( n &#92;Sigma x^2 - &#92;left( &#92;Sigma x &#92;right) ^2  &#92;right) &#92;Sigma x^4
&#92;]
</div>


<p>Inspecting the quadratic derivation above, it is now fairly easy to see that the general form of the incremental matrix formula for the coefficients of a degree-m polynomial looks like this:</p>

<div markdown="0">
&#92;[
&#92;left( &#92;begin{array} {c}
a_0 &#92;&#92;
a_1 &#92;&#92;
\vdots &#92;&#92;
a_m &#92;&#92;
&#92;end{array} &#92;right)
=
&#92;left( &#92;begin{array} {cccc}
n & &#92;Sigma x & &#92;cdots & &#92;Sigma x^m &#92;&#92;
&#92;Sigma x & &#92;Sigma x^2 & &#92;cdots & &#92;Sigma x^{m+1} &#92;&#92;
&#92;vdots & & &#92;ddots & &#92;vdots &#92;&#92;
&#92;Sigma x^m & &#92;Sigma x^{m+1} & &#92;cdots & &#92;Sigma x^{2 m} &#92;&#92;
&#92;end{array} &#92;right)
^ {-1}
&#92;left( &#92;begin{array} {c}
&#92;Sigma y &#92;&#92;
&#92;Sigma x y &#92;&#92;
&#92;vdots &#92;&#92;
&#92;Sigma x^m y &#92;&#92;
&#92;end{array} &#92;right)
&#92;]
</div>


<p>Having an incremental formula for generalized polynomial regression leaves open the question of how one might generalize the correlation coefficient.  There is such a generalization, called the <a href="http://en.wikipedia.org/wiki/Multiple_correlation">coefficient of multiple determination</a>, which is defined:</p>

<div markdown="0">
&#92;[
r = &#92;sqrt { &#92;vec{c} ^ T  R^{-1}  &#92;vec{c} }
&#92;]
Where
&#92;[
&#92;vec{c} = 
&#92;left ( &#92;begin{array} {c}
&#92;rho (x,y) &#92;&#92;
&#92;rho (x^2,y) &#92;&#92;
&#92;vdots &#92;&#92;
&#92;rho (x^m,y) &#92;&#92;
&#92;end{array} &#92;right)
&#92;hspace{1 cm}
R =
&#92;left( &#92;begin{array} {cccc}
1 & &#92;rho (x,x^2) & &#92;cdots & &#92;rho(x,x^m) &#92;&#92;
&#92;rho (x^2,x) & 1 & &#92;cdots & &#92;rho(x^2,x^m) &#92;&#92;
&#92;vdots & & &#92;ddots & &#92;vdots &#92;&#92;
&#92;rho (x^m,x) & &#92;rho (x^m,x^2) & &#92;cdots & 1 &#92;&#92;
&#92;end{array} &#92;right)
&#92;]
and &#92;( &#92;rho (x,y) &#92;) is the traditional pairwise correlation coefficient.
</div>


<p>But we already have an incremental formula for any pairwise correlation coefficient, which is defined above.  And so we can maintain the running sums needed to fill the matrix entries, and compute the coefficient of multiple determination for our polynomial model at any time.</p>

<p>So we now have incremental formulae to maintain any polynomial model in an on-line environment where we either can&#8217;t or prefer not to store the data history, and also incrementally evaluate the &#8216;generalized correlation coefficient&#8217; for that model.</p>

<p>Readers familiar with linear regression may notice that there is also nothing special about polynomial regression, in the sense that powers of x may also be replaced with arbitrary functions of x, and the same regression equations hold.  And so we might generalize the incremental matrix formulae further to replace products of powers of x with products of functions of x:</p>

<div markdown="0">
for a linear regression model &#92;( y = a_1 f_1 (x) + a_2 f_2 (x) + &#92;cdots + a_m f_m(x) &#92;) :
&#92;[
&#92;left( &#92;begin{array} {c}
a_1 &#92;&#92;
a_2 &#92;&#92;
\vdots &#92;&#92;
a_m &#92;&#92;
&#92;end{array} &#92;right)
=
&#92;left( &#92;begin{array} {cccc}
&#92;Sigma f_1 (x) f_1 (x) & &#92;Sigma f_1 (x) f_2 (x) & &#92;cdots & &#92;Sigma f_1 (x) f_m (x) &#92;&#92;
&#92;Sigma f_2 (x) f_1 (x) & &#92;Sigma f_2 (x) f_2 (x) & &#92;cdots & &#92;Sigma f_2 (x) f_m (x) &#92;&#92;
&#92;vdots & & &#92;ddots & &#92;vdots &#92;&#92;
&#92;Sigma f_m (x) f_1 (x) & &#92;Sigma f_m (x) f_2 (x) & &#92;cdots & &#92;Sigma f_m (x) f_m (x) &#92;&#92;
&#92;end{array} &#92;right)
^ {-1}
&#92;left( &#92;begin{array} {c}
&#92;Sigma y f_1 (x) &#92;&#92;
&#92;Sigma y f_2 (x) &#92;&#92;
&#92;vdots &#92;&#92;
&#92;Sigma y f_m (x) &#92;&#92;
&#92;end{array} &#92;right)
&#92;]
</div>


<p>The coefficient of multiple determination generalizes in the analogous way.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/06/29/easy-histograms-and-tables-from-condor-jobs-and-slots/">Easy Histograms and Tables from Condor Jobs and Slots</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-06-29T09:46:00-07:00" pubdate data-updated="true">Jun 29<span>th</span>, 2012</time>
        
        
         | <a href="/blog/2012/06/29/easy-histograms-and-tables-from-condor-jobs-and-slots/#feedback">Feedback</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Several <a href="http://research.cs.wisc.edu/condor/">Condor</a> commands, including condor_status, condor_q and condor_history, provide a nice feature for outputting formatted subsets of classad attributes: the <code>-format &lt;format&gt; &lt;attr&gt;</code> option.  In this post, I assume basic familiarity with <code>-format</code>.  You can read more <a href="http://research.cs.wisc.edu/condor/manual/v7.8/condor_status.html#SECTION0011453000000000000000">here</a></p>

<p>The <code>-format</code> option can be used to generate tables and histograms of attributes, in a classic &#8216;unix one-liner&#8217; fashion.  For example, supposing I wanted to use condor_status to create a nice histogram of the values for slot type, state, activity and accounting group.  I might issue a one-liner like this:</p>

<pre><code>$ condor_status -format "%s" 'ifThenElse(SlotType =!= undefined, string(SlotType), "undefined")' \
&gt; -format " | %s" 'ifThenElse(State =!= undefined, string(State), "undefined")' \
&gt; -format " | %s" 'ifThenElse(Activity =!= undefined, string(Activity), "undefined")' \
&gt; -format " | %s\n" 'ifThenElse(AccountingGroup =!= undefined, string(AccountingGroup), "undefined")' \
&gt; | sort | uniq -c | awk '{ print $0; t += $1 } END { printf("%7d total\n",t) }'
      3 Static | Claimed | Busy | A.user@localdomain
      2 Static | Claimed | Busy | B.user@localdomain
     10 Static | Unclaimed | Idle | undefined
     15 total
</code></pre>

<p>Note that in this command I was extra pedantic and careful about converting expressions to strings, and using the ClassAd ifThenElse to trap and handle possible undefined values (which do indeed occur for AccountingGroup, when a slot is not in use).</p>

<p>We can see that a lot of this would benefit from some programmatic automation.  To that end I wrote some <a href="https://github.com/erikerlandson/bash_condor_tools">convenience bash functions</a> for automating the tedious portions of this process: <code>cchist</code>, <code>ccsort</code> and <code>ccdump</code>.  For example I could use <code>cchist</code> to generate the histogram from the example above much more cleanly:</p>

<pre><code>$ cchist condor_status SlotType State Activity AccountingGroup
      3 Static | Claimed | Busy | A.user@localdomain
      2 Static | Claimed | Busy | B.user@localdomain
     10 Static | Unclaimed | Idle | undefined
     15 total
</code></pre>

<p>The <code>ccdump</code> command simply dumps the table of values, uncollated, while <code>ccsort</code> outputs the table of values, but sorted:</p>

<pre><code>$ ccdump condor_status SlotType State Activity AccountingGroup
Static | Claimed | Busy | A.user@localdomain
Static | Claimed | Busy | A.user@localdomain
Static | Claimed | Busy | B.user@localdomain
Static | Unclaimed | Idle | undefined
Static | Claimed | Busy | A.user@localdomain
Static | Unclaimed | Idle | undefined
Static | Unclaimed | Idle | undefined
Static | Claimed | Busy | B.user@localdomain
Static | Unclaimed | Idle | undefined
Static | Unclaimed | Idle | undefined
Static | Unclaimed | Idle | undefined
Static | Unclaimed | Idle | undefined
Static | Unclaimed | Idle | undefined
Static | Unclaimed | Idle | undefined
Static | Unclaimed | Idle | undefined
$ ccsort condor_status SlotType State Activity AccountingGroup
Static | Claimed | Busy | A.user@localdomain
Static | Claimed | Busy | A.user@localdomain
Static | Claimed | Busy | A.user@localdomain
Static | Claimed | Busy | B.user@localdomain
Static | Claimed | Busy | B.user@localdomain
Static | Unclaimed | Idle | undefined
Static | Unclaimed | Idle | undefined
Static | Unclaimed | Idle | undefined
Static | Unclaimed | Idle | undefined
Static | Unclaimed | Idle | undefined
Static | Unclaimed | Idle | undefined
Static | Unclaimed | Idle | undefined
Static | Unclaimed | Idle | undefined
Static | Unclaimed | Idle | undefined
Static | Unclaimed | Idle | undefined
</code></pre>

<p>If you are interested in providing the actual raw unix command that was executed, you can use the <code>-cmd</code> option (note, this currently must appear <em>first</em>)</p>

<pre><code>$ cchist -cmd condor_status SlotType State Activity AccountingGroup
condor_status -format "%s" 'ifThenElse(SlotType isnt undefined, string(SlotType), "undefined")' -format " | %s" 'ifThenElse(State isnt undefined, string(State), "undefined")' -format " | %s" 'ifThenElse(Activity isnt undefined, string(Activity), "undefined")' -format " | %s\n" 'ifThenElse(AccountingGroup isnt undefined, string(AccountingGroup), "undefined")' -constraint 'True' | sort | uniq -c | awk '{ print $0; t += $1 } END { printf("%7d total\n",t) }'
</code></pre>

<p>As you can see, the command condor_status is a parameter.  You can also use the same commands with condor_q and condor_history:</p>

<pre><code>$ cchist condor_q AccountingGroup LastJobStatus
      3 A.user | 1
      2 B.user | 1
      5 total
$ cchist condor_history AccountingGroup LastJobStatus
     18 A.user | 2
     26 B.user | 2
     20 C.user | 2
     64 total
</code></pre>

<p>You can obtain cchist and friends at the <a href="https://github.com/erikerlandson/bash_condor_tools">bash_condor_tools github repo</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/06/27/maintaining-accounting-group-quotas-with-preemption-policy/">Maintaining Accounting Group Quotas With Preemption Policy</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-06-27T20:33:00-07:00" pubdate data-updated="true">Jun 27<span>th</span>, 2012</time>
        
        
         | <a href="/blog/2012/06/27/maintaining-accounting-group-quotas-with-preemption-policy/#feedback">Feedback</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>There is a straightforward technique to leverage a Condor <a href="http://research.cs.wisc.edu/condor/manual/v7.8/3_3Configuration.html#20480">preemption policy</a> to direct preemptions in a way that helps maintain resource usages as close as possible to the defined <a href="http://research.cs.wisc.edu/condor/manual/v7.8/3_4User_Priorities.html#SECTION00447000000000000000">accounting group quotas</a>.</p>

<p>I will begin by simply giving the configuration and then describe how it works, with a short demonstration.  The actual configuration is simply a clause that can be added to the preemption policy defined by <code>PREEMPTION_REQUIREMENTS</code>:</p>

<pre><code>PREEMPTION_REQUIREMENTS = $(PREEMPTION_REQUIREMENTS) &amp;&amp; (((SubmitterGroupResourcesInUse &lt; SubmitterGroupQuota) &amp;&amp; (RemoteGroupResourcesInUse &gt; RemoteGroupQuota)) || (SubmitterGroup =?= RemoteGroup))
</code></pre>

<p>Unpacking the above logic: the term <code>(SubmitterGroupResourcesInUse &lt; SubmitterGroupQuota)</code> captures the idea that to best maintain quota-driven resource usage, we only want to allow preemption if the submitting accounting group has not yet reached its quota, as acquiring more resources moves the usage closer to the group&#8217;s quota.  Conversely, if the accounting group&#8217;s resource usage is <em>already</em> at or above its quota, acquiring more resources via preemption will only drive the usage <em>farther</em> from the configured quota.</p>

<p>The term <code>(RemoteGroupResourcesInUse &gt; RemoteGroupQuota)</code> captures a similar idea from the &#8216;remote&#8217; side (the candidate for preemption).  Provided the remote&#8217;s resource usage is greater than its quota, allowing preemption will move its usage closer to the configured quota.</p>

<p>The last term <code>(SubmitterGroup =?= RemoteGroup)</code> (a disjunction) ensures that with an accounting group preemption may always occur, deferring to any other clauses in the expression.</p>

<p>A brief aside: in the following example, I use the &#8216;svhist&#8217; bash function for ease and clarity.  For example, the command <code>svhist AccountingGroup State Activity</code> is shorthand for: <code>condor_status -format "%s" 'AccountingGroup' -format " | %s" 'State' -format " | %s\n" 'Activity' -constraint 'True' | sort | uniq -c | awk '{ print $0; t += $1 } END { printf("%7d total\n",t) }'</code>  The svhist command is available <a href="https://github.com/erikerlandson/bash_condor_tools">here</a>.</p>

<p>To demonstrate this preemption policy, consider the following example configuration:</p>

<pre><code># turn off scheduler optimizations, as they can sometimes obscure the
# negotiator/matchmaker behavior
CLAIM_WORKLIFE = 0

# for demonstration purposes, make sure basic preemption knobs are 'on'
MAXJOBRETIREMENTTIME = 0
PREEMPTION_REQUIREMENTS = True
NEGOTIATOR_CONSIDER_PREEMPTION = True

NUM_CPUS = 15

# 3 accounting groups, each with equal quota
GROUP_NAMES = A, B, C
GROUP_QUOTA_A = 5
GROUP_QUOTA_B = 5
GROUP_QUOTA_C = 5

# groups may use each others' surplus
GROUP_ACCEPT_SURPLUS = TRUE
# (an alternative way for groups to acquire surplus is to enable GROUP_AUTOREGROUP)
# GROUP_AUTOREGROUP = TRUE

# A preepmption policy clause that only allows preemptions that move usages closer to configured quotas
PREEMPTION_REQUIREMENTS = $(PREEMPTION_REQUIREMENTS) &amp;&amp; (((SubmitterGroupResourcesInUse &lt; SubmitterGroupQuota) &amp;&amp; (RemoteGroupResourcesInUse &gt; RemoteGroupQuota)) || (SubmitterGroup =?= RemoteGroup))
</code></pre>

<p>Begin by submitting 5 jobs to accounting group A, and 10 jobs to group B:</p>

<pre><code>universe = vanilla
cmd = /bin/sleep
args = 3600
should_transfer_files = if_needed
when_to_transfer_output = on_exit
+AccountingGroup="A.user"
queue 5
+AccountingGroup="B.user"
queue 10
</code></pre>

<p>Confirm that group B&#8217;s resource usage is 10 (note, this is over its quota of 5):</p>

<pre><code>$ svhist AccountingGroup State Activity
      5 A.user@localdomain | Claimed | Busy
     10 B.user@localdomain | Claimed | Busy
     15 total
</code></pre>

<p>Now set submitter priorities to allow preemption, provided preemption policy supports it</p>

<pre><code>$ condor_userprio -setprio A.user@localdomain 10
The priority of A.user@localdomain was set to 10.000000
$ condor_userprio -setprio B.user@localdomain 10
The priority of B.user@localdomain was set to 10.000000
</code></pre>

<p>Now submit 10 jobs to group C.</p>

<pre><code>universe = vanilla
cmd = /bin/sleep
args = 3600
should_transfer_files = if_needed
when_to_transfer_output = on_exit
+AccountingGroup="C.user"
queue 10
</code></pre>

<p>Finally, we verify that our preemption policy drove the resource usages to quota:</p>

<pre><code>$ svhist AccountingGroup State Activity
      5 A.user@localdomain | Claimed | Busy
      5 B.user@localdomain | Claimed | Busy
      5 C.user@localdomain | Claimed | Busy
     15 total
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/05/20/the-joy-of-anonymized-data/">The Joy of Anonymized Data</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-05-20T11:31:00-07:00" pubdate data-updated="true">May 20<span>th</span>, 2012</time>
        
        
         | <a href="/blog/2012/05/20/the-joy-of-anonymized-data/#feedback">Feedback</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I&#8217;ve been fooling around with an <a href="https://github.com/erikerlandson/ratorade/tree/master/data">anonymized data set</a> on the side.  Although this can be frustrating in its own way, it occurred to me that it <em>does</em> have the advantage of forcing me to see the data in the same way my algorithms see it: that is, the data is just some anonymous strings, values and identifiers.  To the code, strings like &#8220;120 minute IPA&#8221; or &#8220;Dogfish Head Brewery&#8221; have no more significance than &#8220;Beer-12&#8221; or &#8220;Brewer-5317&#8221;, and the anonymous identifiers remove any subconscious or conscious tendencies of mine to impart more meaning to an identifier string than is present to the algorithms.</p>

<p>On the other hand, having anonymous identifiers prevents me from drawing any actual inspirations for utilizing semantics that <em>might</em> genuinely be leveragable by an algorithm.  However, my current goal is to produce tools that are generically useful across data domains.  In that respect, I think developing on anonymized data could actually be helping.  Time will tell.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/05/16/pretty-good-random-sampling-from-database-queries/">Pretty Good Random Sampling from Database Queries</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-05-16T07:05:00-07:00" pubdate data-updated="true">May 16<span>th</span>, 2012</time>
        
        
         | <a href="/blog/2012/05/16/pretty-good-random-sampling-from-database-queries/#feedback">Feedback</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Suppose you want to add random sampling to a database query, but your database does not support it.  One known technique is to add a field, say &#8220;rk&#8221;, that contains a random key value in [0,1), index on that field, and add a clause to the query:  <code>("rk" &gt;= x  &amp;&amp;  "rk" &lt; x+p)</code>, where p is your desired random sampling probability and x is randomly chosen from [0,1-p).</p>

<p>This is not bad, but we can see it is not <em>truly</em> randomized, as the sliding window [x,x+p) over the &#8220;rk&#8221; random key field generates overlap in the samplings.  The larger the value of p, the more significant the overlapping effect will be.</p>

<p>Eliminating this effect absolutely (and maintaining query efficiency) is difficult without direct database support, however we can take steps to significantly reduce it.  Suppose we generated <em>two</em> independently randomized keys &#8220;rk0&#8221; and &#8220;rk1&#8221;.  We could sample using a slightly more complex clause: <code>(("rk0" &gt;= x0  &amp;&amp; "rk0" &lt; x0+d) || ("rk1" &gt;= x1  &amp;&amp;  "rk1" &lt; x1+d))</code>, where x0 and x1 are randomly selected from [0,1-d).</p>

<p>What value do we use for d to maintain a random sampling factor of p?  As &#8220;rk0&#8221; and &#8220;rk1&#8221; are independent random variables, the effective sampling factor p is given by p = d + d - d<sup>2,</sup> where the d<sup>2</sup> accounts for query results present in both the &#8220;rk0&#8221; and &#8220;rk1&#8221; subqueries.  Applying the quadratic formula to solve for d gives us: d = 1-sqrt(1-p).</p>

<p>This approach should be useable with any database.  Here is example code I wrote for generating the random sampling portion of a mongodb query in pymongo:</p>

<pre><code>def random_sampling_query(p, rk0="rk0", rk1="rk1", pad = 0):
    d = (1.0 - sqrt(1.0-p)) * (1.0 + pad)
    if d &gt; 1.0: d = 1.0
    if d &lt; 0.0: d = 0.0
    s0 = random.random()*(1.0 - d)
    s1 = random.random()*(1.0 - d)
    return {"$or":[{rk0:{"$gte":s0, "$lt":s0+d}}, {rk1:{"$gte":s1, "$lt":s1+d}}]}
</code></pre>

<p>I included an optional &#8216;pad&#8217; parameter to support a case where one might want a particular (integer) sample size s, and so set p = s/(db-table-size), and use padding to mitigate the probability of getting less than s records due to random sampling jitter.  In mongodb one could then append <code>limit(s)</code> to the query return, and get exactly s returns in most cases, with the correct padding.</p>

<p>Here is a pymongo example of using the <code>random_sampling_query()</code> above:</p>

<pre><code># get a query that does random sampling of 1% of the results:
query = random_sampling_query(0.01)
# other query clauses can be added if desired:
query[user] = "eje"
# issue the final query to get results with random sampling:
qres = data.find(query)
</code></pre>

<p>One could extend the logic above by using 3 independent random fields rk0,rk1,rk2 and applying the cubic formula, or four fields and the quartic formula, but I suspect that is passing the point of diminishing returns on storage cost, query cost and algebra.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/03/19/interaction-between-mktime-and-tm-isdst-a-compute-cycle-landmine/">Interaction between mktime() and tm_isdst - a compute cycle landmine</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-03-19T13:18:00-07:00" pubdate data-updated="true">Mar 19<span>th</span>, 2012</time>
        
        
         | <a href="/blog/2012/03/19/interaction-between-mktime-and-tm-isdst-a-compute-cycle-landmine/#feedback">Feedback</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I was recently profiling the <a href="http://research.cs.wisc.edu/condor/">Condor</a> collector, and was a bit stunned to discover that the standard C library function <a href="http://www.cplusplus.com/reference/clibrary/ctime/mktime/">mktime</a>() was burning <em>60% of the collector&#8217;s cycles</em>.</p>

<p><a href="http://spinningmatt.wordpress.com/">Matt</a> helpfully attempted to reproduce, but his profile showed <code>mktime()</code> using almost none of the cycles, which is exactly the sane result one would expect.</p>

<p>In the code, I noticed that <code>tm_isdst</code> was set to 1, in other words &#8220;assert that DST is in effect.&#8221;  This made my eye twitch, because I live in Arizona, where we boldy do not observe DST.  I created a little test rig to help confirm my suspicion that time zone might have something to do with it:</p>

<pre><code>#include &lt;stdlib.h&gt;
#include &lt;time.h&gt;
#include &lt;iostream&gt;

using std::cout;

time_t mktA(struct tm* tmp) {
    tmp-&gt;tm_isdst = -1;
    return mktime(tmp);
}

time_t mktB(struct tm* tmp) {
    tmp-&gt;tm_isdst = 0;
    return mktime(tmp);
}

time_t mktC(struct tm* tmp) {
    tmp-&gt;tm_isdst = 1;
    return mktime(tmp);
}

int main(int argc, char** argv) {
    struct tm stm;
    stm.tm_year = 2012 - 1900;
    stm.tm_mon = 3-1;
    stm.tm_mday = 17-1;
    stm.tm_hour = 0;
    stm.tm_min = 0;
    stm.tm_sec = 0;

    // this gets altered for each testing function:
    stm.tm_isdst = 0;

    cout &lt;&lt; mktA(&amp;stm) &lt;&lt; "\n";
    cout &lt;&lt; mktB(&amp;stm) &lt;&lt; "\n";
    cout &lt;&lt; mktC(&amp;stm) &lt;&lt; "\n";

    return 0;
}
</code></pre>

<p>Then I built the test rig, which I expertly named <code>test_mktime</code>, and profiled it using valgrind/callgrind:</p>

<pre><code># build the test rig
$ make test_mktime
g++     test_mktime.cpp   -o test_mktime

# profile using valgrind/callgrind:
$ valgrind --tool=callgrind ./test_mktime
==2671== Callgrind, a call-graph generating cache profiler
==2671== Copyright (C) 2002-2009, and GNU GPL'd, by Josef Weidendorfer et al.
==2671== Using Valgrind-3.5.0 and LibVEX; rerun with -h for copyright info
==2671== Command: ./test_mktime
==2671== 
==2671== For interactive control, run 'callgrind_control -h'.
1331881200
1331881200
1331881200
==2671== 
==2671== Events    : Ir
==2671== Collected : 4125723
==2671== 
==2671== I   refs:      4,125,723

# massage the raw output into something (more or less) human readable:
$ callgrind_annotate --inclusive=yes --tree=calling callgrind.out.2671 &gt; mktprof.txt
</code></pre>

<p>Examining the massaged output in <code>mktprof.txt</code>, I observed that calling <code>mktime()</code> with <code>tm_isdst = {-1|0}</code> (<code>mktA()</code> and <code>mktB()</code>) takes the small amount of time one would expect, calling with <code>tm_isdst = 1</code> (<code>mktC()</code>) uses a completely insane number of cycles, and clearly nearly all of the cycles burned by the test rig:</p>

<pre><code>2,749,933  *  ???:main [/home/eje/mktime/test_mktime]
2,655,457  &gt;   ???:mktC(tm*) (1x) [/home/eje/mktime/test_mktime]
    4,428  &gt;   ???:std::basic_ostream&lt;char, std::char_traits&lt;char&gt; &gt;&amp; std::operator&lt;&lt; &lt;std::char_traits&lt;char&gt; &gt;(std::basic_ostream&lt;char, std::char_traits&lt;char&gt; &gt;&amp;, char const*) (3x) [/usr/lib64/libstdc++.so.6.0.13]
   11,260  &gt;   ???:std::ostream::operator&lt;&lt;(long) (3x) [/usr/lib64/libstdc++.so.6.0.13]
    4,064  &gt;   ???:mktB(tm*) (1x) [/home/eje/mktime/test_mktime]
    3,989  &gt;   ???:_dl_runtime_resolve (2x) [/lib64/ld-2.11.2.so]
   74,212  &gt;   ???:mktA(tm*) (1x) [/home/eje/mktime/test_mktime]
</code></pre>

<p>Again, Matt verified that he could reproduce the weird behavior if he set <em>his</em> timezone to &#8220;Arizona&#8221;.</p>

<p>The bottom line appears to be that invoking <code>mktime()</code> with <code>tm_isdst = 1</code>, in a time zone that does not observe DST, can set off a nuclear cycle-stealing land mine of inefficiency and horror.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/03/19/dont-try-to-stop-me/">Don&#8217;t try to stop me. I&#8217;m on a rampage.</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-03-19T12:08:00-07:00" pubdate data-updated="true">Mar 19<span>th</span>, 2012</time>
        
        
         | <a href="/blog/2012/03/19/dont-try-to-stop-me/#feedback">Feedback</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>In which I join the 21st century, kicking and screaming.</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/4/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>About The Author</h1>
  <p>Erik is a senior software engineer on the <a href="http://www.redhat.com">Red Hat</a> Emerging Technologies Group.</p>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2016/12/19/converging-monoid-addition-for-t-digest/">Converging Monoid Addition for T-Digest</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/09/05/expressing-map-reduce-as-a-left-folding-monoid/">Encoding Map-Reduce As A Monoid With Left Folding</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/08/31/supporting-competing-apis-in-scala-can-better-package-factoring-help/">Supporting Competing APIs in Scala &#8211; Can Better Package Factoring Help?</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/08/03/x-medoids-using-minimum-description-length-to-identify-the-k-in-k-medoids/">Using Minimum Description Length to Optimize the &#8216;K&#8217; in K-Medoids</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/07/09/approximating-a-pdf-of-distances-with-a-gamma-distribution/">Approximating a PDF of Distances With a Gamma Distribution</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/erikerlandson">@erikerlandson</a> on GitHub
  
  <script type="text/javascript">
    $.domReady(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'erikerlandson',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>


<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  <script type="text/javascript">
    $.domReady(function(){
      getTwitterFeed("manyangled", 4, true);
    });
  </script>
  <script src="/javascripts/twitter.js" type="text/javascript"> </script>
  
    <a href="http://twitter.com/manyangled" class="twitter-follow-button" data-show-count="false">Follow @manyangled</a>
  
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2016 - Erik Erlandson -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
