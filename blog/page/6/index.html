
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>tool monkey</title>
  <meta name="author" content="Erik Erlandson">

  
  <meta name="description" content="There is a straightforward technique to leverage a Condor preemption policy to direct preemptions in a way that helps maintain resource usages as &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://erikerlandson.github.com/blog/page/6/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="tool monkey" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

  <!-- enables inclusion of MathJax LaTeX: http://greglus.com/blog/2011/11/29/integrate-MathJax-LaTeX-and-MathML-Markup-in-Octopress/ -->
  <script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">tool monkey</a></h1>
  
    <h2>adventures of an unfrozen caveman programmer</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:erikerlandson.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/06/27/maintaining-accounting-group-quotas-with-preemption-policy/">Maintaining Accounting Group Quotas With Preemption Policy</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-06-27T20:33:00-07:00" pubdate data-updated="true">Jun 27<span>th</span>, 2012</time>
        
        
         | <a href="/blog/2012/06/27/maintaining-accounting-group-quotas-with-preemption-policy/#feedback">Feedback</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>There is a straightforward technique to leverage a Condor <a href="http://research.cs.wisc.edu/condor/manual/v7.8/3_3Configuration.html#20480">preemption policy</a> to direct preemptions in a way that helps maintain resource usages as close as possible to the defined <a href="http://research.cs.wisc.edu/condor/manual/v7.8/3_4User_Priorities.html#SECTION00447000000000000000">accounting group quotas</a>.</p>

<p>I will begin by simply giving the configuration and then describe how it works, with a short demonstration.  The actual configuration is simply a clause that can be added to the preemption policy defined by <code>PREEMPTION_REQUIREMENTS</code>:</p>

<pre><code>PREEMPTION_REQUIREMENTS = $(PREEMPTION_REQUIREMENTS) &amp;&amp; (((SubmitterGroupResourcesInUse &lt; SubmitterGroupQuota) &amp;&amp; (RemoteGroupResourcesInUse &gt; RemoteGroupQuota)) || (SubmitterGroup =?= RemoteGroup))
</code></pre>

<p>Unpacking the above logic: the term <code>(SubmitterGroupResourcesInUse &lt; SubmitterGroupQuota)</code> captures the idea that to best maintain quota-driven resource usage, we only want to allow preemption if the submitting accounting group has not yet reached its quota, as acquiring more resources moves the usage closer to the group&#8217;s quota.  Conversely, if the accounting group&#8217;s resource usage is <em>already</em> at or above its quota, acquiring more resources via preemption will only drive the usage <em>farther</em> from the configured quota.</p>

<p>The term <code>(RemoteGroupResourcesInUse &gt; RemoteGroupQuota)</code> captures a similar idea from the &#8216;remote&#8217; side (the candidate for preemption).  Provided the remote&#8217;s resource usage is greater than its quota, allowing preemption will move its usage closer to the configured quota.</p>

<p>The last term <code>(SubmitterGroup =?= RemoteGroup)</code> (a disjunction) ensures that with an accounting group preemption may always occur, deferring to any other clauses in the expression.</p>

<p>A brief aside: in the following example, I use the &#8216;svhist&#8217; bash function for ease and clarity.  For example, the command <code>svhist AccountingGroup State Activity</code> is shorthand for: <code>condor_status -format "%s" 'AccountingGroup' -format " | %s" 'State' -format " | %s\n" 'Activity' -constraint 'True' | sort | uniq -c | awk '{ print $0; t += $1 } END { printf("%7d total\n",t) }'</code>  The svhist command is available <a href="https://github.com/erikerlandson/bash_condor_tools">here</a>.</p>

<p>To demonstrate this preemption policy, consider the following example configuration:</p>

<pre><code># turn off scheduler optimizations, as they can sometimes obscure the
# negotiator/matchmaker behavior
CLAIM_WORKLIFE = 0

# for demonstration purposes, make sure basic preemption knobs are 'on'
MAXJOBRETIREMENTTIME = 0
PREEMPTION_REQUIREMENTS = True
NEGOTIATOR_CONSIDER_PREEMPTION = True

NUM_CPUS = 15

# 3 accounting groups, each with equal quota
GROUP_NAMES = A, B, C
GROUP_QUOTA_A = 5
GROUP_QUOTA_B = 5
GROUP_QUOTA_C = 5

# groups may use each others' surplus
GROUP_ACCEPT_SURPLUS = TRUE
# (an alternative way for groups to acquire surplus is to enable GROUP_AUTOREGROUP)
# GROUP_AUTOREGROUP = TRUE

# A preepmption policy clause that only allows preemptions that move usages closer to configured quotas
PREEMPTION_REQUIREMENTS = $(PREEMPTION_REQUIREMENTS) &amp;&amp; (((SubmitterGroupResourcesInUse &lt; SubmitterGroupQuota) &amp;&amp; (RemoteGroupResourcesInUse &gt; RemoteGroupQuota)) || (SubmitterGroup =?= RemoteGroup))
</code></pre>

<p>Begin by submitting 5 jobs to accounting group A, and 10 jobs to group B:</p>

<pre><code>universe = vanilla
cmd = /bin/sleep
args = 3600
should_transfer_files = if_needed
when_to_transfer_output = on_exit
+AccountingGroup="A.user"
queue 5
+AccountingGroup="B.user"
queue 10
</code></pre>

<p>Confirm that group B&#8217;s resource usage is 10 (note, this is over its quota of 5):</p>

<pre><code>$ svhist AccountingGroup State Activity
      5 A.user@localdomain | Claimed | Busy
     10 B.user@localdomain | Claimed | Busy
     15 total
</code></pre>

<p>Now set submitter priorities to allow preemption, provided preemption policy supports it</p>

<pre><code>$ condor_userprio -setprio A.user@localdomain 10
The priority of A.user@localdomain was set to 10.000000
$ condor_userprio -setprio B.user@localdomain 10
The priority of B.user@localdomain was set to 10.000000
</code></pre>

<p>Now submit 10 jobs to group C.</p>

<pre><code>universe = vanilla
cmd = /bin/sleep
args = 3600
should_transfer_files = if_needed
when_to_transfer_output = on_exit
+AccountingGroup="C.user"
queue 10
</code></pre>

<p>Finally, we verify that our preemption policy drove the resource usages to quota:</p>

<pre><code>$ svhist AccountingGroup State Activity
      5 A.user@localdomain | Claimed | Busy
      5 B.user@localdomain | Claimed | Busy
      5 C.user@localdomain | Claimed | Busy
     15 total
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/05/20/the-joy-of-anonymized-data/">The Joy of Anonymized Data</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-05-20T11:31:00-07:00" pubdate data-updated="true">May 20<span>th</span>, 2012</time>
        
        
         | <a href="/blog/2012/05/20/the-joy-of-anonymized-data/#feedback">Feedback</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I&#8217;ve been fooling around with an <a href="https://github.com/erikerlandson/ratorade/tree/master/data">anonymized data set</a> on the side.  Although this can be frustrating in its own way, it occurred to me that it <em>does</em> have the advantage of forcing me to see the data in the same way my algorithms see it: that is, the data is just some anonymous strings, values and identifiers.  To the code, strings like &#8220;120 minute IPA&#8221; or &#8220;Dogfish Head Brewery&#8221; have no more significance than &#8220;Beer-12&#8221; or &#8220;Brewer-5317&#8221;, and the anonymous identifiers remove any subconscious or conscious tendencies of mine to impart more meaning to an identifier string than is present to the algorithms.</p>

<p>On the other hand, having anonymous identifiers prevents me from drawing any actual inspirations for utilizing semantics that <em>might</em> genuinely be leveragable by an algorithm.  However, my current goal is to produce tools that are generically useful across data domains.  In that respect, I think developing on anonymized data could actually be helping.  Time will tell.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/05/16/pretty-good-random-sampling-from-database-queries/">Pretty Good Random Sampling from Database Queries</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-05-16T07:05:00-07:00" pubdate data-updated="true">May 16<span>th</span>, 2012</time>
        
        
         | <a href="/blog/2012/05/16/pretty-good-random-sampling-from-database-queries/#feedback">Feedback</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Suppose you want to add random sampling to a database query, but your database does not support it.  One known technique is to add a field, say &#8220;rk&#8221;, that contains a random key value in [0,1), index on that field, and add a clause to the query:  <code>("rk" &gt;= x  &amp;&amp;  "rk" &lt; x+p)</code>, where p is your desired random sampling probability and x is randomly chosen from [0,1-p).</p>

<p>This is not bad, but we can see it is not <em>truly</em> randomized, as the sliding window [x,x+p) over the &#8220;rk&#8221; random key field generates overlap in the samplings.  The larger the value of p, the more significant the overlapping effect will be.</p>

<p>Eliminating this effect absolutely (and maintaining query efficiency) is difficult without direct database support, however we can take steps to significantly reduce it.  Suppose we generated <em>two</em> independently randomized keys &#8220;rk0&#8221; and &#8220;rk1&#8221;.  We could sample using a slightly more complex clause: <code>(("rk0" &gt;= x0  &amp;&amp; "rk0" &lt; x0+d) || ("rk1" &gt;= x1  &amp;&amp;  "rk1" &lt; x1+d))</code>, where x0 and x1 are randomly selected from [0,1-d).</p>

<p>What value do we use for d to maintain a random sampling factor of p?  As &#8220;rk0&#8221; and &#8220;rk1&#8221; are independent random variables, the effective sampling factor p is given by p = d + d - d<sup>2,</sup> where the d<sup>2</sup> accounts for query results present in both the &#8220;rk0&#8221; and &#8220;rk1&#8221; subqueries.  Applying the quadratic formula to solve for d gives us: d = 1-sqrt(1-p).</p>

<p>This approach should be useable with any database.  Here is example code I wrote for generating the random sampling portion of a mongodb query in pymongo:</p>

<pre><code>def random_sampling_query(p, rk0="rk0", rk1="rk1", pad = 0):
    d = (1.0 - sqrt(1.0-p)) * (1.0 + pad)
    if d &gt; 1.0: d = 1.0
    if d &lt; 0.0: d = 0.0
    s0 = random.random()*(1.0 - d)
    s1 = random.random()*(1.0 - d)
    return {"$or":[{rk0:{"$gte":s0, "$lt":s0+d}}, {rk1:{"$gte":s1, "$lt":s1+d}}]}
</code></pre>

<p>I included an optional &#8216;pad&#8217; parameter to support a case where one might want a particular (integer) sample size s, and so set p = s/(db-table-size), and use padding to mitigate the probability of getting less than s records due to random sampling jitter.  In mongodb one could then append <code>limit(s)</code> to the query return, and get exactly s returns in most cases, with the correct padding.</p>

<p>Here is a pymongo example of using the <code>random_sampling_query()</code> above:</p>

<pre><code># get a query that does random sampling of 1% of the results:
query = random_sampling_query(0.01)
# other query clauses can be added if desired:
query[user] = "eje"
# issue the final query to get results with random sampling:
qres = data.find(query)
</code></pre>

<p>One could extend the logic above by using 3 independent random fields rk0,rk1,rk2 and applying the cubic formula, or four fields and the quartic formula, but I suspect that is passing the point of diminishing returns on storage cost, query cost and algebra.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/03/19/interaction-between-mktime-and-tm-isdst-a-compute-cycle-landmine/">Interaction between mktime() and tm_isdst - a compute cycle landmine</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-03-19T13:18:00-07:00" pubdate data-updated="true">Mar 19<span>th</span>, 2012</time>
        
        
         | <a href="/blog/2012/03/19/interaction-between-mktime-and-tm-isdst-a-compute-cycle-landmine/#feedback">Feedback</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>I was recently profiling the <a href="http://research.cs.wisc.edu/condor/">Condor</a> collector, and was a bit stunned to discover that the standard C library function <a href="http://www.cplusplus.com/reference/clibrary/ctime/mktime/">mktime</a>() was burning <em>60% of the collector&#8217;s cycles</em>.</p>

<p><a href="http://spinningmatt.wordpress.com/">Matt</a> helpfully attempted to reproduce, but his profile showed <code>mktime()</code> using almost none of the cycles, which is exactly the sane result one would expect.</p>

<p>In the code, I noticed that <code>tm_isdst</code> was set to 1, in other words &#8220;assert that DST is in effect.&#8221;  This made my eye twitch, because I live in Arizona, where we boldy do not observe DST.  I created a little test rig to help confirm my suspicion that time zone might have something to do with it:</p>

<pre><code>#include &lt;stdlib.h&gt;
#include &lt;time.h&gt;
#include &lt;iostream&gt;

using std::cout;

time_t mktA(struct tm* tmp) {
    tmp-&gt;tm_isdst = -1;
    return mktime(tmp);
}

time_t mktB(struct tm* tmp) {
    tmp-&gt;tm_isdst = 0;
    return mktime(tmp);
}

time_t mktC(struct tm* tmp) {
    tmp-&gt;tm_isdst = 1;
    return mktime(tmp);
}

int main(int argc, char** argv) {
    struct tm stm;
    stm.tm_year = 2012 - 1900;
    stm.tm_mon = 3-1;
    stm.tm_mday = 17-1;
    stm.tm_hour = 0;
    stm.tm_min = 0;
    stm.tm_sec = 0;

    // this gets altered for each testing function:
    stm.tm_isdst = 0;

    cout &lt;&lt; mktA(&amp;stm) &lt;&lt; "\n";
    cout &lt;&lt; mktB(&amp;stm) &lt;&lt; "\n";
    cout &lt;&lt; mktC(&amp;stm) &lt;&lt; "\n";

    return 0;
}
</code></pre>

<p>Then I built the test rig, which I expertly named <code>test_mktime</code>, and profiled it using valgrind/callgrind:</p>

<pre><code># build the test rig
$ make test_mktime
g++     test_mktime.cpp   -o test_mktime

# profile using valgrind/callgrind:
$ valgrind --tool=callgrind ./test_mktime
==2671== Callgrind, a call-graph generating cache profiler
==2671== Copyright (C) 2002-2009, and GNU GPL'd, by Josef Weidendorfer et al.
==2671== Using Valgrind-3.5.0 and LibVEX; rerun with -h for copyright info
==2671== Command: ./test_mktime
==2671== 
==2671== For interactive control, run 'callgrind_control -h'.
1331881200
1331881200
1331881200
==2671== 
==2671== Events    : Ir
==2671== Collected : 4125723
==2671== 
==2671== I   refs:      4,125,723

# massage the raw output into something (more or less) human readable:
$ callgrind_annotate --inclusive=yes --tree=calling callgrind.out.2671 &gt; mktprof.txt
</code></pre>

<p>Examining the massaged output in <code>mktprof.txt</code>, I observed that calling <code>mktime()</code> with <code>tm_isdst = {-1|0}</code> (<code>mktA()</code> and <code>mktB()</code>) takes the small amount of time one would expect, calling with <code>tm_isdst = 1</code> (<code>mktC()</code>) uses a completely insane number of cycles, and clearly nearly all of the cycles burned by the test rig:</p>

<pre><code>2,749,933  *  ???:main [/home/eje/mktime/test_mktime]
2,655,457  &gt;   ???:mktC(tm*) (1x) [/home/eje/mktime/test_mktime]
    4,428  &gt;   ???:std::basic_ostream&lt;char, std::char_traits&lt;char&gt; &gt;&amp; std::operator&lt;&lt; &lt;std::char_traits&lt;char&gt; &gt;(std::basic_ostream&lt;char, std::char_traits&lt;char&gt; &gt;&amp;, char const*) (3x) [/usr/lib64/libstdc++.so.6.0.13]
   11,260  &gt;   ???:std::ostream::operator&lt;&lt;(long) (3x) [/usr/lib64/libstdc++.so.6.0.13]
    4,064  &gt;   ???:mktB(tm*) (1x) [/home/eje/mktime/test_mktime]
    3,989  &gt;   ???:_dl_runtime_resolve (2x) [/lib64/ld-2.11.2.so]
   74,212  &gt;   ???:mktA(tm*) (1x) [/home/eje/mktime/test_mktime]
</code></pre>

<p>Again, Matt verified that he could reproduce the weird behavior if he set <em>his</em> timezone to &#8220;Arizona&#8221;.</p>

<p>The bottom line appears to be that invoking <code>mktime()</code> with <code>tm_isdst = 1</code>, in a time zone that does not observe DST, can set off a nuclear cycle-stealing land mine of inefficiency and horror.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2012/03/19/dont-try-to-stop-me/">Don&#8217;t try to stop me. I&#8217;m on a rampage.</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-03-19T12:08:00-07:00" pubdate data-updated="true">Mar 19<span>th</span>, 2012</time>
        
        
         | <a href="/blog/2012/03/19/dont-try-to-stop-me/#feedback">Feedback</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>In which I join the 21st century, kicking and screaming.</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/5/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>About The Author</h1>
  <p>Erik is a software engineer at <a href="http://www.redhat.com">Red Hat</a> where he contributes to the <a href="https://radanalytics.io/">radanalytics.io</a> upstream community.
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2018/09/08/equality-constraints-for-cubic-b-splines/">Equality Constraints for Cubic B-Splines</a>
      </li>
    
      <li class="post">
        <a href="/blog/2018/09/02/putting-cubic-b-splines-into-standard-polynomial-form/">Putting Cubic B-Splines into Standard Polynomial Form</a>
      </li>
    
      <li class="post">
        <a href="/blog/2018/06/03/solving-feasible-points-with-smooth-max/">Solving Feasible Points With Smooth-Max</a>
      </li>
    
      <li class="post">
        <a href="/blog/2018/05/28/computing-smooth-max-and-its-gradients-without-over-and-underflow/">Computing Smooth Max and its Gradients Without Over- and Underflow</a>
      </li>
    
      <li class="post">
        <a href="/blog/2018/05/27/the-gradient-and-hessian-of-the-smooth-max-over-functions/">The Gradient and Hessian of the Smooth Max Over Functions</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/erikerlandson">@erikerlandson</a> on GitHub
  
  <script type="text/javascript">
    $.domReady(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'erikerlandson',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>


<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  <script type="text/javascript">
    $.domReady(function(){
      getTwitterFeed("manyangled", 4, true);
    });
  </script>
  <script src="/javascripts/twitter.js" type="text/javascript"> </script>
  
    <a href="http://twitter.com/manyangled" class="twitter-follow-button" data-show-count="false">Follow @manyangled</a>
  
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2018 - Erik Erlandson -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
