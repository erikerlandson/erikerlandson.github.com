<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: condor | tool monkey]]></title>
  <link href="http://erikerlandson.github.com/blog/categories/condor/atom.xml" rel="self"/>
  <link href="http://erikerlandson.github.com/"/>
  <updated>2012-11-15T17:39:56-07:00</updated>
  <id>http://erikerlandson.github.com/</id>
  <author>
    <name><![CDATA[Erik Erlandson]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Using Accounting Groups With Wallaby]]></title>
    <link href="http://erikerlandson.github.com/blog/2012/11/01/using-accounting-groups-with-wallaby/"/>
    <updated>2012-11-01T07:41:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2012/11/01/using-accounting-groups-with-wallaby</id>
    <content type="html"><![CDATA[<p>In this post I will describe how to use HTCondor accounting groups with <a href="http://getwallaby.com">Wallaby</a>.  I will begin by walking through an accounting group configuration on a pool managed by wallaby.  Following, I will demonstrate the configuration in action.</p>

<p>The gist of this demo will be to create a simple accounting group hierarchy:  A top-level group called <code>Demo</code>, and three child groups <code>Demo.A, Demo.B, Demo.C</code>.  <code>Demo</code> will be given a <em>static</em> quota to simulate the behavior of a pool with a particular number of slots available.  The child groups will use <em>dynamic</em> quotas to express their quota shares from the parent as ratios.</p>

<p>First, it is good practice to snapshot current wallaby configuration for reference:</p>

<pre><code>$ wallaby make-snapshot "pre demo state"
</code></pre>

<p>We will be constructing a wallaby feature called <code>AccountingGroups</code> to hold our accounting group configurations.  This creates the feature:</p>

<pre><code>$ wallaby add-feature AccountingGroups
</code></pre>

<p>Wallaby wants to know about features that are used in configurations, so begin by declaring them to the wallaby store:</p>

<pre><code>$ wallaby add-param GROUP_NAMES
$ wallaby add-param GROUP_QUOTA_Demo
$ wallaby add-param GROUP_QUOTA_DYNAMIC_Demo.A
$ wallaby add-param GROUP_QUOTA_DYNAMIC_Demo.B
$ wallaby add-param GROUP_QUOTA_DYNAMIC_Demo.C
$ wallaby add-param GROUP_ACCEPT_SURPLUS_Demo
$ wallaby add-param NEGOTIATOR_ALLOW_QUOTA_OVERSUBSCRIPTION
$ wallaby add-param NEGOTIATOR_CONSIDER_PREEMPTION
$ wallaby add-param CLAIM_WORKLIFE
</code></pre>

<p>Here we disable the "claim worklife" feature by setting claims to expire immediately.   This prevents jobs under one accounting group from acquiring surplus quota and holding on to it when new jobs arrive under a different group:</p>

<pre><code>$ wallaby add-params-to-feature ExecuteNode CLAIM_WORKLIFE=0
$ wallaby add-params-to-subsystem startd CLAIM_WORKLIFE
$ wallaby add-params-to-feature Scheduler CLAIM_WORKLIFE=0
$ wallaby add-params-to-subsystem scheduler CLAIM_WORKLIFE
</code></pre>

<p>If you alter the configuration parameters, you will want the negotiator to reconfigure itself when you activate.  Here we declare the accounting group features as part of the negotiator subsystem:</p>

<pre><code>$ wallaby add-params-to-subsystem negotiator \
GROUP_NAMES \
GROUP_QUOTA_Demo \
GROUP_QUOTA_DYNAMIC_Demo.A \
GROUP_QUOTA_DYNAMIC_Demo.B \
GROUP_QUOTA_DYNAMIC_Demo.C \
NEGOTIATOR_ALLOW_QUOTA_OVERSUBSCRIPTION \
NEGOTIATOR_CONSIDER_PREEMPTION
</code></pre>

<p>Activate the configuration so far to tell subsystems about new parameters for reconfig</p>

<pre><code>$ wallaby activate
</code></pre>

<p>Now we construct the actual configuration as the <code>AccountingGroups</code> wallaby feature.  Here we are constructing a group <code>Demo</code> with three subgroups <code>Demo.{A|B|C}</code>.  In a multi-node pool with several cores, it is often easiest to play with group behavior by creating a sub-hierarchy such as this <code>Demo</code> sub-hierarchy, and configuring <code>GROUP_ACCEPT_SURPLUS_Demo=False</code>, so that the sub-hierarchy behaves with a well-defined total slot quota (in this case 15).  The sub-groups A,B and C each take 1/3 of the parent's quota, so in this example each will receive 5 slots.</p>

<pre><code>$ wallaby add-params-to-feature AccountingGroups \
NEGOTIATOR_ALLOW_QUOTA_OVERSUBSCRIPTION=False \
NEGOTIATOR_CONSIDER_PREEMPTION=False \
GROUP_NAMES='Demo, Demo.A, Demo.B, Demo.C' \
GROUP_ACCEPT_SURPLUS=True \
GROUP_QUOTA_Demo=15 \
GROUP_ACCEPT_SURPLUS_Demo=False \
GROUP_QUOTA_DYNAMIC_Demo.A=0.333 \
GROUP_QUOTA_DYNAMIC_Demo.B=0.333 \
GROUP_QUOTA_DYNAMIC_Demo.C=0.333
</code></pre>

<p>With our accounting group feature created, we can apply it to the machine our negotiator daemon is running on.  Then snapshot our configuration modifications for reference, and activate the new configuration:</p>

<pre><code>$ wallaby add-features-to-node negotiator.node.com AccountingGroups
$ wallaby make-snapshot 'new acct group config'
$ wallaby activate
</code></pre>

<p>Now we will demonstrate the new feature in action.  Submit the following file to your pool, which submits 100 jobs each to groups <code>Demo.A</code> with durations randomly chosen between 25 and 35 seconds:</p>

<pre><code>universe = vanilla
cmd = /bin/sleep
args = $$([25 + random(11)])
transfer_executable = false
should_transfer_files = if_needed
when_to_transfer_output = on_exit
+AccountingGroup="Demo.A.user1"
queue 100
</code></pre>

<p>Once you make this submission, allow the jobs to negotiate, and you can check to see what accounting groups are running on slots by inspecting the value of <code>RemoteNegotiatingGroup</code> on slot ads.   You should see that subgroup <code>Demo.A</code> has acquired surplus and is running 15 jobs, as there are no jobs under groups <code>Demo.B</code> or <code>Demo.C</code> that need slots.  Note, due to jobs completing between negotiation cycles, these numbers can be less than the maximum possible at certain times.  If you have any other slots in the pool, they will show up in the output below as having either <code>undefined</code> negotiating group or possibly <code>&lt;none&gt;</code> if any other jobs are running.</p>

<pre><code>$ condor_status -format "%s\n" 'ifThenElse(RemoteNegotiatingGroup isnt undefined, string(RemoteNegotiatingGroup), "undefined")' -constraint 'True' | sort | uniq -c | awk '{ print $0; t += $1 } END { printf("%7d total\n",t) }'
 15 Demo.A
 50 &lt;none&gt;
 50 undefined
115 total
</code></pre>

<p>Now submit some jobs against <code>Demo.B</code> and <code>Demo.C</code>, like so:</p>

<pre><code>universe = vanilla
cmd = /bin/sleep
args = $$([25 + random(11)])
transfer_executable = false
should_transfer_files = if_needed
when_to_transfer_output = on_exit
+AccountingGroup="Demo.B.user1"
queue 100
+AccountingGroup="Demo.C.user1"
queue 100
</code></pre>

<p>Once these jobs begin to negotiate, we expect to see the jobs balanced between the three groups evenly, as we gave each group 1/3 of the quota:</p>

<pre><code>$ condor_status -format "%s\n" 'ifThenElse(RemoteNegotiatingGroup isnt undefined, string(RemoteNegotiatingGroup), "undefined")' -constraint 'True' | sort | uniq -c | awk '{ print $0; t += $1 } END { printf("%7d total\n",t) }'
  5 Demo.A
  5 Demo.B
  5 Demo.C
 50 &lt;none&gt;
 50 undefined
115 total
</code></pre>

<p>Finally, we see what happens if we remove jobs under <code>Demo.B</code>:</p>

<pre><code>$ condor_rm -constraint 'AccountingGroup =?= "Demo.B.user1"'
</code></pre>

<p>Now we should see quota start to share between <code>Demo.A</code> and <code>Demo.C</code>:</p>

<pre><code>$ condor_status -format "%s\n" 'ifThenElse(RemoteNegotiatingGroup isnt undefined, string(RemoteNegotiatingGroup), "undefined")' -constraint 'True' | sort | uniq -c | awk '{ print $0; t += $1 } END { printf("%7d total\n",t) }'
  7 Demo.A
  8 Demo.C
 50 &lt;none&gt;
 50 undefined
115 total
</code></pre>

<p>With this accounting group configuration in place, you can play with changing quotas for the accounting groups and observe the numbers of running jobs change in response.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Randomized Sleep Jobs in HTCondor Using Delayed Evaluation]]></title>
    <link href="http://erikerlandson.github.com/blog/2012/10/31/randomized-sleep-jobs-in-htcondor-using-delayed-evaluation/"/>
    <updated>2012-10-31T14:17:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2012/10/31/randomized-sleep-jobs-in-htcondor-using-delayed-evaluation</id>
    <content type="html"><![CDATA[<p>In some cases, when testing or demonstrating the performance of an HTCondor pool, it is useful to submit a plug of jobs with randomized running times.  The standard technique for controlling run times is to submit a classic 'sleep' job.  However, randomizing the argument to sleep is another matter.  Luckily there is an easy way to do this with a single submit file, using delayed evaluation syntax.</p>

<p>A classad expression placed inside of a special enclosure, like this: <code>$$([ &lt;expr&gt; ])</code>, causes <code>&lt;expr&gt;</code> to be evaluated at the time the job ad is matched with a slot.  You can read more about delayed evaluation <a href="http://research.cs.wisc.edu/condor/manual/v7.8/condor_submit.html#78367">here</a>.  Consider the following example submit file:</p>

<pre><code>universe = vanilla
executable = /bin/sleep

# generate a random sleep duration when job is matched
args = $$([25 + random(11)])

# boilerplate to avoid file transfers and notifications
transfer_executable = false
should_transfer_files = no
when_to_transfer_output = on_exit
notification = never

# generate 100 copies of this job - each will evaluate the
# randomizing expression independently
queue 100
</code></pre>

<p>As you can see in the example above, the value of <code>args</code> is set to the delayed evaluation expression <code>$$([25 + random(11)])</code>, which will evaluate the classad expression <code>25 + random(11)</code> when each job ad matches a slot to run.  The <code>queue 100</code> command generates 100 separate job ads, and so the net effect is 100 jobs, which will each run a sleep job with a duration <em>randomly chosen</em> between 25 and 35.</p>

<p>If we submit this file to a condor pool, and let the jobs run to completion, we can check the pool history file to see how the <code>Args</code> attribute was set on the job ad using the special generative attribute <code>MATCH_EXP_Args</code>, and the <a href="http://erikerlandson.github.com/blog/2012/06/29/easy-histograms-and-tables-from-condor-jobs-and-slots/">cchist tool</a>:</p>

<pre><code>$ cchist condor_history 'MATCH_EXP_Args'
     11 25
      7 26
     10 27
      9 28
      7 29
     13 30
      8 31
      7 32
      8 33
      9 34
     11 35
    100 total
</code></pre>

<p>We can also sanity check our measure of actual run time, to see that those values are close to our values of <code>Args</code>:</p>

<pre><code>$ cchist condor_history 'CompletionDate-JobCurrentStartDate'
      1 25
     11 26
      9 27
      8 28
      9 29
      9 30
     12 31
      4 32
      8 33
     10 34
     12 35
      6 36
      1 37
    100 total
</code></pre>

<p>Have fun with easy random sleep jobs!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Improved Parse Checking for ClassAd Log Files in Condor]]></title>
    <link href="http://erikerlandson.github.com/blog/2012/09/26/improved-parse-checking-for-classad-log-files-in-condor/"/>
    <updated>2012-09-26T10:06:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2012/09/26/improved-parse-checking-for-classad-log-files-in-condor</id>
    <content type="html"><![CDATA[<p>Condor maintains certain key transactional information using the ClassAd Log system.  For example, both the negotiator's accountant log ("Accountantnew.log") and the scheduler's job queue log ("job_queue.log") are maintained in ClassAd Log format.</p>

<p>As of <a href="http://www.redhat.com/products/mrg/grid/">Red Hat Grid 2.2</a> (upstream: <a href="http://research.cs.wisc.edu/condor/">condor 7.9.0</a>), the ClassAd Log system provides significantly improved parse checking.  This upgraded format checking allows a much wider variety of log corruptions to be detected, and also provides detailed information on the location of corruptions encountered.</p>

<h3>ClassAd Log Format</h3>

<p>A bit of familiarity with ClassAd Log format will aid in understanding subsequent discussion.  The ClassAd Log system serializes a ClassAd collection history as a sequence of tuples:  <code>opcode, [key, [args]]</code>.  For example, here is an annotated ClassAd log excerpt (NOTE: annotations or comments are illegal in an actual file):</p>

<pre><code>105                               &lt;- open a transaction
103 1.0 LastSuspensionTime 0      &lt;- for classad '1.0', set LastSuspentionTime to 0
103 1.0 CurrentHosts 1            &lt;- for classad '1.0', set CurrentHosts to 1
106                               &lt;- close the transaction
</code></pre>

<p>ClassAd Log parse checking works by detecting any occurrence of an invalid op-code, or any invalid ClassAd expression in the RHS of an attribute update operation (opcode 103, as in the example above)</p>

<h3>Examples of Parse Failure Detection</h3>

<p>Consider a ClassAd Log with a corrupted op-code 'ZMG' (in this case, not even a proper integer):</p>

<pre><code>107 1 CreationTimestamp 1334245749
101 0.0 Job Machine
103 0.0 NextClusterNum 1
105
ZMG 1.0 JobStatus 2                        &lt;- Oh no, a bad opcode!
103 1.0 EnteredCurrentStatus 1334245771
103 1.0 LastSuspensionTime 0
103 1.0 CurrentHosts 1
106
105
103 1.1 LastJobStatus 1
103 1.1 JobStatus 2
</code></pre>

<p>Parse checking will result in the following log message in the scheduler, which provides its assessment of what operation line/tuple it found the corruption, and the following 3 lines for additional context:</p>

<pre><code>09/12/12 15:30:35 WARNING: Encountered corrupt log record 5 (byte offset 89)
09/12/12 15:30:35 Lines following corrupt log record 5 (up to 3):
09/12/12 15:30:35     103 1.0 EnteredCurrentStatus 1334245771
09/12/12 15:30:35     103 1.0 LastSuspensionTime 0
09/12/12 15:30:35     103 1.0 CurrentHosts 1
09/12/12 15:30:35 ERROR "Error: corrupt log record 5 (byte offset 89) occurred inside closed transaction, recovery failed" at line 1136 in file /home/eje/git/grid/src/condor_utils/classad_log.cpp
</code></pre>

<p>Note that here the scheduler halted with an exception, as strict parsing was enabled, and the error was inside a completed transaction.</p>

<p>Here is a second example that contains a badly-formed ClassAd expression:</p>

<pre><code>107 1 CreationTimestamp 1334245749
101 0.0 Job Machine
103 0.0 NextClusterNum 1
105
103 1.0 JobStatus 2
103 1.0 EnteredCurrentStatus 1334245749
103 1.0 LastSuspensionTime 0
103 1.0 CurrentHosts 1
106
105
103 1.1 LastJobStatus 1 + eek!             &lt;- bad ClassAd expr!
103 1.1 JobStatus 2
</code></pre>

<p>Note that parse errors detected in unterminated transactions (the last transaction in a file may be uncompleted) are considered non-fatal:</p>

<pre><code>09/12/12 15:43:29 WARNING: Encountered corrupt log record 11 (byte offset 211)
09/12/12 15:43:29 Lines following corrupt log record 11 (up to 3):
09/12/12 15:43:29     103 1.1 JobStatus 2
09/12/12 15:43:29 Detected unterminated log entry in ClassAd Log /home/eje/condor/local/spool/job_queue.log. Forcing rotation.
</code></pre>

<h3>Disabling Strict Parse Checking</h3>

<p>Strict parse checking means that detected errors are fatal (unless in an unterminated transaction).  One consequence of the former lax error checking for Classad Log files is that some log file output was generated that was not properly formed.  Most such instances have been identified and corrected.  However, in order to accomodate legacy ClassAd Log files and any hidden bugs in log output generation, a condor configuration variable has been provided to disable strict checking:</p>

<pre><code># Disable strict parsing: parse errors will not be fatal
CLASSAD_LOG_STRICT_PARSING = False
</code></pre>

<p>In Red Hat Grid 2.2, <code>CLASSAD_LOG_STRICT_PARSING</code> defaults to <code>False</code>.  In the upstream condor repository, the default value has been set to <code>True</code>, in order to allow strict parsing failures to capture any remaining infrequent bugs in ClassAd log generation.</p>

<p>Note that strict checking can also be disabled or enabled <em>selectively</em>.  For example, this configuration disables strict checking only on the negotiator:</p>

<pre><code>CLASSAD_LOG_STRICT_PARSING = True
NEGOTIATOR.CLASSAD_LOG_STRICT_PARSING = False
</code></pre>

<h3>Categories of Undetectable Corruption</h3>

<p>In the ClassAd Log format, the key is considered an arbitrary string.  Therefore, any corruption that alters a key value is not detectable:</p>

<pre><code>103 1.rats! LastSuspensionTime 0   &lt;- weird key '1.rats!' will go undetected
</code></pre>

<p>Similarly, ClassAd attribute names are by nature arbitrary, and so corruptions to a name can go undetected:</p>

<pre><code>103 1.0 LastOopsie 0   &lt;- LastOopsie is a valid attribute name
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Driving a Condor Job Renice Policy with Accounting Groups]]></title>
    <link href="http://erikerlandson.github.com/blog/2012/07/27/driving-a-condor-job-renice-policy-with-accounting-groups/"/>
    <updated>2012-07-27T13:50:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2012/07/27/driving-a-condor-job-renice-policy-with-accounting-groups</id>
    <content type="html"><![CDATA[<p>Condor can run its jobs with a renice priority level specified by <code>JOB_RENICE_INCREMENT</code>, which defaults simply to 10, but can in fact be any ClassAd expression, and is evaluated in the context of the job ad corresponding to the job being run.</p>

<p>This opens up an opportunity to create a renice <em>policy</em>, driven by accounting groups.  Consider a <a href="http://erikerlandson.github.com/blog/2012/07/10/configuring-minimum-and-maximum-resources-for-mission-critical-jobs-in-a-condor-pool/">scenario I discussed previously</a>, where a condor pool caters to mission critical (MC) jobs and regular (R) jobs.</p>

<p>An additional configuration trick we could apply is to add a renice policy that gives a higher renice value (that is, a lower priority) to any jobs that aren't run under the mission-critical (MC) rubric, as in this example configuration:</p>

<pre><code># A convenience expression that extracts group, e.g. "mc.user@domain.com" --&gt; "mc"
SUBMIT_EXPRS = AcctGroupName
AcctGroupName = ifThenElse(my.AccountingGroup =!= undefined, \
                           regexps("^([^@]+)\.[^.]+", my.AccountingGroup, "\1"), "&lt;none&gt;")

NUM_CPUS = 3

# Groups representing mission critical and regular jobs:
GROUP_NAMES = MC, R
GROUP_QUOTA_MC = 2
GROUP_QUOTA_R = 1

# Any group not MC gets a renice increment of 10:
JOB_RENICE_INCREMENT = 10 * (AcctGroupName =!= "MC")
</code></pre>

<p>To demonstrate this policy in action, I wrote a little shell script I called <code>burn</code>, whose only function is to burn cycles for a given number of seconds:</p>

<pre><code>#!/bin/sh

# usage: burn [n]
# where n is number of seconds to burn cycles
s="$1"
if [ -z "$s" ]; then s=60; fi

t0=`date +%s`
while [ 1 ]; do
    x=0
    # burn some cycles:
    while [ $x -lt 10000 ]; do let x=$x+1; done
    t=`date +%s`
    let e=$t-$t0
    # halt when the requested time is up:
    if [ $e -gt $s ]; then exit ; fi
done
</code></pre>

<p>Begin by standing up a condor pool including the configuration above.   Make sure the <code>burn</code> script is readable.  Also, it is preferable to make sure your system is unloaded (load average should be as close to zero as reasonably possible).  Then submit the following, which instantiates two <code>burn</code> jobs running under accounting group <code>MC</code> and a third under group <code>R</code>:</p>

<pre><code>universe = vanilla
cmd = /path/to/burn
args = 600
should_transfer_files = if_needed
when_to_transfer_output = on_exit
+AccountingGroup = "MC.user"
queue 2
+AccountingGroup = "R.user"
queue 1
</code></pre>

<p>Allow the jobs to negotiate and then run for a couple minutes.  You should then see something similar to the following load-average information from the slot ads:</p>

<pre><code>$ condor_status -format "%s" SlotID -format " | %.2f" LoadAvg -format " | %.2f" CondorLoadAvg -format " | %.2f" TotalLoadAvg -format " | %.2f" TotalCondorLoadAvg -format " | %s\n" AccountingGroup | sort
1 | 1.33 | 1.33 | 2.75 | 2.70 | MC.user@localdomain
2 | 1.28 | 1.24 | 2.75 | 2.70 | MC.user@localdomain
3 | 0.13 | 0.13 | 2.77 | 2.72 | R.user@localdomain
</code></pre>

<p>Note, which particular <code>SlotID</code> runs which job may vary.  However, we expect to see that the load averages for the slot running group <code>R</code> are much lower than the load averages for slots running jobs under group <code>MC</code>, as seen above.</p>

<p>We can explicitly verify the renice numbers from our policy to see that our one <code>R</code> job has a nice value of 10 (and is using only a fraction of the cpu):</p>

<pre><code># tell 'ps' to give us (pid, %cpu, nice, cmd+args):
$ ps -eo "%p %C %n %a" | grep 'burn 600'
22403 10.2  10 /bin/sh /home/eje/bin/burn 600
22406 93.2   0 /bin/sh /home/eje/bin/burn 600
22411 90.6   0 /bin/sh /home/eje/bin/burn 600
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[LIFO and FIFO Preemption Policies for a Condor Pool]]></title>
    <link href="http://erikerlandson.github.com/blog/2012/07/19/lifo-and-fifo-preemption-policies-for-a-condor-pool/"/>
    <updated>2012-07-19T13:57:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2012/07/19/lifo-and-fifo-preemption-policies-for-a-condor-pool</id>
    <content type="html"><![CDATA[<p>On a Condor pool, a Last In First Out (LIFO) preemption policy favors choosing the longest-running job from the available preemption options.  Correspondingly, a First In First Out (FIFO) policy favors the most-recent job for preemption.</p>

<p>Configuring a LIFO or FIFO policy is easy, using the <code>PREEMPTION_RANK</code> configuration variable.  <code>PREEMPTION_RANK</code> defines a ClassAd expression that is evaluated for all slots that are candidates for claim preemption, and causes those candidates to be sorted so that the candidates with the highest rank value are considered first.   Therefore, to implement a LIFO (or FIFO) preemption policy, one needs reference an expression that represents the claiming job's running time:</p>

<pre><code># LIFO preemption: favor preempting jobs that have been running the longest
PREEMPTION_RANK = TotalJobRunTime
# turn this into FIFO by using (-TotalJobRunTime)
</code></pre>

<p>The attribute <code>TotalJobRunTime</code> represents the amount of time a job has been running on its claim (generally, this is effectively equivalent to total running time, unless your job supports some form of checkpointing), and so ranking preemption candidates by this attribute results in LIFO preemption, and ranking by its negative provides FIFO preemption.</p>

<p>Note that <code>PREEMPTION_RANK</code> applies <em>only</em> to candidates that have already met the requirements defined on <code>PREEMPTION_REQUIREMENTS</code>, or the slot-centric preemption policy defined by <code>RANK</code>.  <code>PREEMPTION_RANK</code> does not itself determine what claimed slots are considered by a job for preemption.</p>

<p>To demonstrate LIFO and FIFO preemption in action, consider the following configuration:</p>

<pre><code># turn off scheduler optimizations, as they can sometimes obscure the
# negotiator/matchmaker behavior
CLAIM_WORKLIFE = 0
CLAIM_PARTITIONABLE_LEFTOVERS = False

# reduce update latencies for faster testing response
UPDATE_INTERVAL = 15
NEGOTIATOR_INTERVAL = 20
SCHEDD_INTERVAL = 15

# for demonstration purposes, make sure basic preemption knobs are 'on'
MAXJOBRETIREMENTTIME = 0
PREEMPTION_REQUIREMENTS = True
NEGOTIATOR_CONSIDER_PREEMPTION = True
RANK = 0.0

# LIFO preemption: favor preempting jobs that have been running the longest
PREEMPTION_RANK = TotalJobRunTime
# turn this into FIFO by using (-TotalJobRunTime)

# define 3 cpus to provide fodder for preemption
NUM_CPUS = 3
</code></pre>

<p>Begin by spinning up a condor pool with the configuration above.  When the pool is operating, fill the three slots with jobs for 'user1', with a delay to ensure that jobs have easily distinguishable values for <code>TotalJobRunTime</code>:</p>

<pre><code>$ cat /tmp/user1.jsub 
universe = vanilla
cmd = /bin/sleep
args = 600
should_transfer_files = if_needed
when_to_transfer_output = on_exit
+AccountingGroup="user1"
queue 1

$ condor_submit /tmp/user1.jsub ; sleep 30 ; condor_submit /tmp/user1.jsub ; sleep 30 ; condor_submit /tmp/user1.jsub
</code></pre>

<p>Once these jobs have all started running, verify their run times using <a href="http://erikerlandson.github.com/blog/2012/06/29/easy-histograms-and-tables-from-condor-jobs-and-slots/">ccsort</a>:</p>

<pre><code>$ ccsort condor_status JobID TotalJobRunTime AccountingGroup
1.0 | 78 | user1@localdomain
2.0 | 36 | user1@localdomain
3.0 | 16 | user1@localdomain
</code></pre>

<p>to make preemption easy, give user1 a low priority:</p>

<pre><code>$ condor_userprio -setprio user1@localdomain 10
</code></pre>

<p>Now, we will submit some jobs for 'user2': which will be allowed to preempt jobs for 'user1'.  We should see that the longest-running job for user1 is chosen each time:</p>

<pre><code>$ condor_submit /tmp/user2.jsub
Submitting job(s).
1 job(s) submitted to cluster 4.

$ ccsort condor_status JobID TotalJobRunTime AccountingGroup
2.0 | 81 | user1@localdomain
3.0 | 61 | user1@localdomain
4.0 | 2 | user2@localdomain

$ condor_submit /tmp/user2.jsub
Submitting job(s).
1 job(s) submitted to cluster 5.

$ ccsort condor_status JobID TotalJobRunTime AccountingGroup
3.0 | 91 | user1@localdomain
4.0 | 32 | user2@localdomain
5.0 | 3 | user2@localdomain
</code></pre>

<p>Now we change LIFO to FIFO and demonstrate.  Switch the sign of <code>TotalJobRunTime</code>:</p>

<pre><code># Now I am FIFO!
PREEMPTION_RANK = -TotalJobRunTime
</code></pre>

<p>And restart the negotiator, and check on our currently running jobs:</p>

<pre><code>$ condor_restart -negotiator

$ ccsort condor_status JobID TotalJobRunTime AccountingGroup
3.0 | 151 | user1@localdomain
4.0 | 92 | user2@localdomain
5.0 | 49 | user2@localdomain
</code></pre>

<p>Now, set up 'user2' for easy preemption like user1:</p>

<pre><code>$ condor_userprio -setprio user2@localdomain 10
</code></pre>

<p>And submit some jobs for user3.  Since we reconfigured for FIFO preemption, we should now see the <em>most recent</em> job preempted each time (in this case, these should both be the 'user2' jobs):</p>

<pre><code>$ condor_submit /tmp/user3.jsub
Submitting job(s).
1 job(s) submitted to cluster 6.

$ ccsort condor_status JobID TotalJobRunTime AccountingGroup
3.0 | 241 | user1@localdomain
4.0 | 182 | user2@localdomain
6.0 | 15 | user3@localdomain

$ condor_submit /tmp/user3.jsub
Submitting job(s).
1 job(s) submitted to cluster 7.

$ ccsort condor_status JobID TotalJobRunTime AccountingGroup
3.0 | 301 | user1@localdomain
6.0 | 75 | user3@localdomain
7.0 | 17 | user3@localdomain
</code></pre>
]]></content>
  </entry>
  
</feed>
