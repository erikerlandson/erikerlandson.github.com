<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: clustering | tool monkey]]></title>
  <link href="http://erikerlandson.github.com/blog/categories/clustering/atom.xml" rel="self"/>
  <link href="http://erikerlandson.github.com/"/>
  <updated>2015-08-17T08:07:37-07:00</updated>
  <id>http://erikerlandson.github.com/</id>
  <author>
    <name><![CDATA[Erik Erlandson]]></name>
    <email><![CDATA[erikerlandson@yahoo.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Parallel K-Medoids Using Scala ParSeq]]></title>
    <link href="http://erikerlandson.github.com/blog/2015/05/06/parallel-k-medoids-using-scala-parseq/"/>
    <updated>2015-05-06T16:33:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2015/05/06/parallel-k-medoids-using-scala-parseq</id>
    <content type="html"><![CDATA[<p>Scala supplies a <a href="http://docs.scala-lang.org/overviews/parallel-collections/overview.html">parallel collections library</a> that was designed to make it easy for a programmer to add parallel computing over the elements in a collection.  In this post, I will describe a case study of applying Scala's parallel collections to cleanly implement multithreading support for training a K-Medoids clustering model.</p>

<h3>Motivation</h3>

<p><a href="http://en.wikipedia.org/wiki/K-medoids">K-Medoids clustering</a> is a relative of K-Means clustering that does not require an algebra over input data elements.  That is, K-Medoids requires only a distance metric defined on elements in the data space, and can cluster objects which do not have a well-defined concept of addition or division that is necessary for computing the <a href="http://en.wikipedia.org/wiki/Centroid">centroids</a> required by K-Means.  For example, K-Medoids can cluster character strings, which have a notion of <a href="http://en.wikipedia.org/wiki/Edit_distance">distance</a>, but no notion of summation that could be used to compute a geometric centroid.</p>

<p>This additional generality comes at a cost.  The medoid of a collection of elements is the member of the collection that minimizes some function F of the distances from that element to all the other elements in the collection.  For example, F might be the sum of distances from one element to all the elements, or perhaps the maximum distance, etc.  <strong>It is not hard to see that the cost of computing a medoid of (n) elements is quadratic in (n)</strong>: Evaluating F is linear in (n) and F in turn must be evaluated with respect to each element.  Furthermore, unlike centroid-based computations used in K-Means, computing a medoid does not naturally lend itself to common scale-out computing formalisms such as Spark RDDs, due to the full-cross-product nature of the computation.</p>

<p>With this in mind, a more traditional multithreading approach is a good candidate to achieve some practical parallelism on modern multi-core hardware.  I'll demonstrate that this is easy to implement in Scala with parallel sequences.</p>

<h3>Non-Parallel Code</h3>

<p>Consider a baseline non-parallel implementation of K-Medoids, as in the following example skeleton code.  (A working version of this code, under review at the time of this post, can be <a href="https://github.com/erikerlandson/silex/blob/parseq_blog/src/main/scala/com/redhat/et/silex/cluster/KMedoids.scala">viewed here</a>)</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>A skeleton K-Medoids implementation </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">class</span> <span class="nc">KMedoids</span><span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s">&quot;k:%20Int,%20metric:%20(T,%20T&quot;</span><span class="o">&gt;</span><span class="n">T</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="k">=&gt;</span> <span class="nc">Double</span><span class="o">)</span> <span class="o">{&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>  <span class="c1">// Train a K-Medoids cluster on some input data</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">train</span><span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s">&quot;data:%20Seq[T]&quot;</span><span class="o">&gt;</span><span class="n">T</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="o">{&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="k">var</span> <span class="n">current</span> <span class="k">=</span> <span class="c1">// randomly select k data elements as initial cluster</span>
</span><span class='line'>
</span><span class='line'><span class="k">var</span> <span class="n">model_converged</span> <span class="k">=</span> <span class="kc">false</span>
</span><span class='line'><span class="k">while</span> <span class="o">(!</span><span class="n">model_converged</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>  <span class="c1">// assign each element to its closest medoid</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">clusters</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">medoidIdx</span><span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">current</span><span class="o">)).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">// recompute the medoid from the latest cluster elements</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">next</span> <span class="k">=</span> <span class="n">benchmark</span><span class="o">(</span><span class="s">&quot;medoids&quot;</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">clusters</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">medoid</span><span class="o">)</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="n">model_converged</span> <span class="k">=</span> <span class="c1">// test for model convergence</span>
</span><span class='line'>
</span><span class='line'>  <span class="n">current</span> <span class="k">=</span> <span class="n">next</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>  <span class="o">}&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>  <span class="c1">// Return the medoid of some collection of elements</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">medoid</span><span class="o">(</span><span class="n">data</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">T</span><span class="o">])</span> <span class="k">=</span> <span class="o">{&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="n">benchmark</span><span class="o">(</span><span class="n">s</span><span class="s">&quot;medoid: n= ${data.length}&quot;</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>  <span class="n">data</span><span class="o">.</span><span class="n">minBy</span><span class="o">(</span><span class="n">medoidCost</span><span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">data</span><span class="o">)</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>  <span class="o">}&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>  <span class="c1">// The sum of an element&#39;s distance to all the elements in its cluster</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">medoidCost</span><span class="o">(</span><span class="n">e</span><span class="k">:</span> <span class="kt">T</span><span class="o">,</span> <span class="n">data</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">T</span><span class="o">])</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">iterator</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">metric</span><span class="o">(</span><span class="n">e</span><span class="o">,</span> <span class="k">_</span><span class="o">)).</span><span class="n">sum</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>  <span class="c1">// Index of the closest medoid to an element</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">medoidIdx</span><span class="o">(</span><span class="n">e</span><span class="k">:</span> <span class="kt">T</span><span class="o">,</span> <span class="n">mv</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">T</span><span class="o">])</span> <span class="k">=</span> <span class="n">mv</span><span class="o">.</span><span class="n">iterator</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">metric</span><span class="o">(</span><span class="n">e</span><span class="o">,</span> <span class="o">&lt;</span><span class="n">em</span><span class="o">&gt;)).</span><span class="n">zipWithIndex</span><span class="o">.</span><span class="n">min</span><span class="o">.&lt;/</span><span class="n">em</span><span class="o">&gt;</span><span class="mi">2</span><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>  <span class="c1">// Output a benchmark timing of some expression</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">benchmark</span><span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s">&quot;label:%20String&quot;</span><span class="o">&gt;</span><span class="n">T</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;(</span><span class="n">blk</span><span class="k">:</span> <span class="o">=&gt;</span> <span class="n">T</span><span class="o">)</span> <span class="k">=</span> <span class="o">{&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="k">val</span> <span class="n">t0</span> <span class="k">=</span> <span class="nc">System</span><span class="o">.</span><span class="n">nanoTime</span>
</span><span class='line'><span class="k">val</span> <span class="n">t</span> <span class="k">=</span> <span class="n">blk</span>
</span><span class='line'><span class="k">val</span> <span class="n">sec</span> <span class="k">=</span> <span class="o">(</span><span class="nc">System</span><span class="o">.</span><span class="n">nanoTime</span> <span class="o">-</span> <span class="n">t0</span><span class="o">)</span> <span class="o">/</span> <span class="mi">1</span><span class="n">e9</span>
</span><span class='line'><span class="n">println</span><span class="o">(</span><span class="n">f</span><span class="s">&quot;Run time for $label = $sec%.1f&quot;</span><span class="o">);</span> <span class="nc">System</span><span class="o">.</span><span class="n">out</span><span class="o">.</span><span class="n">flush</span>
</span><span class='line'><span class="n">t</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>If we run the code above (de-skeletonized), then we might see something like this output from our benchmarking, where I clustered a dataset of 40,000 randomly-generated (x,y,z) points by Gaussian sampling around 5 chosen centers.  (This data is numeric, but I provide only a distance metric on the points.  K-Medoids has no knowledge of the data except that it can run the given metric function on it):</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>One iteration of a clustering run (k = 5) </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Run time for medoid: n= 8299 = 7.7
</span><span class='line'>Run time for medoid: n= 3428 = 1.2
</span><span class='line'>Run time for medoid: n= 12581 = 17.0
</span><span class='line'>Run time for medoid: n= 5731 = 3.3
</span><span class='line'>Run time for medoid: n= 9961 = 10.2
</span><span class='line'>Run time for medoids = 39.8</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Observe that cluster sizes are generally not the same, and we can see the time per cluster varying quadratically with respect to cluster size.</p>

<h3>A First Take On Parallel K-Medoids</h3>

<p>Studying our non-parallel code above, we can see that the computation of each new medoid is independent, which makes it a likely place to inject some parallelism. A Scala sequence can be transformed into a corresponding parallel sequence using the <code>par</code> method, and so parallelizing our code is literally this simple:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>Parallelizing a collection with .par </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span>  <span class="c1">// recompute the medoid from the latest cluster elements</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">next</span> <span class="k">=</span> <span class="n">benchmark</span><span class="o">(</span><span class="s">&quot;medoids&quot;</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">clusters</span><span class="o">.</span><span class="n">par</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">medoid</span><span class="o">).</span><span class="n">seq</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>In this block, I also apply <code>.seq</code> at the end, which is not always necessary but can avoid type mismatches between <code>Seq[T]</code> and <code>ParSeq[T]</code> under some circumstances.</p>

<p>In my case I also wish to exercise some control over the threading used by the parallelism, and so I explicitly assign a <code>ForkJoinPool</code> thread pool to the sequence:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>Set the threading used by a Scala ParSeq </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="o">&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span>  <span class="c1">// establish a thread pool for use by K-Medoids</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">threadPool</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ForkJoinPool</span><span class="o">(</span><span class="n">numThreads</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">// ...</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">// recompute the medoid from the latest cluster elements</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">next</span> <span class="k">=</span> <span class="n">benchmark</span><span class="o">(</span><span class="s">&quot;medoids&quot;</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">pseq</span> <span class="k">=</span> <span class="n">clusters</span><span class="o">.</span><span class="n">par</span>
</span><span class='line'>    <span class="n">pseq</span><span class="o">.</span><span class="n">tasksupport</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ForkJoinTaskSupport</span><span class="o">(</span><span class="n">threadPool</span><span class="o">)</span>
</span><span class='line'>    <span class="n">pseq</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">medoid</span><span class="o">).</span><span class="n">seq</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Minor grievance: it would be nice if Scala supported some 'in-line' methods, like <code>seq.par(n)...</code> and <code>seq.par(threadPool)...</code>, instead of requiring the programmer to break the flow of the code to invoke <code>tasksupport =</code>, which returns <code>Unit</code>.</p>

<p>Now that we've parallelized our K-Medoids training, we should see how well it responds to additional threads.  I ran the above parallelized version using <code>{1, 2, 4, 8, 16, 32}</code> threads, on a machine with 40 cores, so that my benchmarking would not be impacted by attempting to run more threads than there are cores to support them.  I also ran two versions of test data.  The first I generated with clusters of equal size (5 clusters of ~8000 elements), and the second with one cluster being twice as large (1 cluster of ~13300 and 4 clusters of ~6700).  Following is a plot of throughput (iterations / second) versus threads:</p>

<p><img class="left" src="/assets/images/parseq/by_cluster_1.png" title="Throughput As A Function Of Threads" ></p>

<p>In the best of all possible worlds, our throughput would increase linearly with the number of threads; double the threads, double our iterations per second.  Instead, our throughput starts to increase nicely as we add threads, but hits a hard ceiling at 8 threads.  It is not hard to see why: our parallelism is limited by the number of elements in our collection of clusters.  In our case that is k = 5, and so we reach our ceiling at 8 threads, the first thread number >= 5.  Furthermore, we see that when the size of clusters is unequal, the throughput suffers even more.  The time required to complete the clustering is dominated by the most expensive element.  In our case, the cluster that is twice the size of other clusters:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>Run time is dominated by largest cluster </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Run time for medoid: n= 6695 = 5.1
</span><span class='line'>Run time for medoid: n= 6686 = 5.2
</span><span class='line'>Run time for medoid: n= 6776 = 5.3
</span><span class='line'>Run time for medoid: n= 6682 = 5.4
</span><span class='line'>Run time for medoid: n= 13161 = 19.9
</span><span class='line'>Run time for medoids = 19.9</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<h3>Take 2: Improving The Use Of Threads</h3>

<p>Fortunately it is not hard to improve on this situation.  If parallelizing by cluster is too coarse, we can try pushing our parallelism down one level of granularity.  In our case, that means parallelizing the outer loop of our medoid function, and it is just as easy as before:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><figcaption><span>Parallelize the outer loop of medoid computation </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'>  <span class="c1">// Return the medoid of some collection of elements</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">medoid</span><span class="o">(</span><span class="n">data</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">T</span><span class="o">])</span> <span class="k">=</span> <span class="o">{&lt;/</span><span class="n">p</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;&lt;</span><span class="n">code</span><span class="o">&gt;</span><span class="n">benchmark</span><span class="o">(</span><span class="n">s</span><span class="s">&quot;medoid: n= ${data.length}&quot;</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">pseq</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">par</span>
</span><span class='line'>  <span class="n">pseq</span><span class="o">.</span><span class="n">tasksupport</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ForkJoinTaskSupport</span><span class="o">(</span><span class="n">threadPool</span><span class="o">)</span>
</span><span class='line'>  <span class="n">pseq</span><span class="o">.</span><span class="n">minBy</span><span class="o">(</span><span class="n">medoidCost</span><span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">data</span><span class="o">)</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'><span class="o">&lt;/</span><span class="n">code</span><span class="o">&gt;&lt;/</span><span class="n">pre</span><span class="o">&gt;</span>
</span><span class='line'>
</span><span class='line'><span class="o">&lt;</span><span class="n">p</span><span class="o">&gt;</span>  <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>Note that I retained the previous parallelism at the cluster level, otherwise the algorithm would execute parallel medoids, but one cluster at a time.  Also observe that we are applying the same thread pool we supplied to the ParSeq at the cluster level.  Scala's parallel logic can utilize the same thread pool at multiple granularities without blocking.  This makes it very clean to control the total number of threads used by some computation, by simply re-using the same threadpool across all points of parallelism.</p>

<p>Now, when we re-run our experiment, we see that our throughput continues to increase as we add threads.  The following plot illustrates the throughput increasing in comparison to the previous ceiling, and also that throughput is less sensitive to the cluster size, as threads can be allocated flexibly across clusters as they are available:</p>

<p><img class="left" src="/assets/images/parseq/all_1.png" title="Thread utilization improves at finer granularity" ></p>

<p>I hope this short case study has demonstrated how easy it is to add multithreading to computations with Scala parallel sequences, and some considerations for making the best use of available threads.  Happy Parallel Programming!</p>
]]></content>
  </entry>
  
</feed>
