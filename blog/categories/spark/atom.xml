<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: spark | tool monkey]]></title>
  <link href="http://erikerlandson.github.com/blog/categories/spark/atom.xml" rel="self"/>
  <link href="http://erikerlandson.github.com/"/>
  <updated>2015-03-31T08:36:59-07:00</updated>
  <id>http://erikerlandson.github.com/</id>
  <author>
    <name><![CDATA[Erik Erlandson]]></name>
    <email><![CDATA[erikerlandson@yahoo.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Hygienic Closures for Scala Function Serialization]]></title>
    <link href="http://erikerlandson.github.com/blog/2015/03/31/hygienic-closures-for-scala-function-serialization/"/>
    <updated>2015-03-31T06:06:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2015/03/31/hygienic-closures-for-scala-function-serialization</id>
    <content type="html"><![CDATA[<p>In most use cases of Scala closures, what you see is what you get, but there are exceptions where looks can be deceiving and this can have a big impact on closure serialization.  Closure serialization is of more than academic interest.  Tools like Apache Spark cannot operate without serializing functions over the network.  In this post I'll describe some scenarios where closures include more than what is evident in the code, and then a technique for preventing unwanted inclusions.</p>

<p>To establish a bit of context, consider this simple example that obtains a function and serializes it to disk, and which <em>does</em> behave as expected:</p>

<pre><code>object Demo extends App {
  def write[A](obj: A, fname: String) {
    import java.io._
    new ObjectOutputStream(new FileOutputStream(fname)).writeObject(obj)
  }

  object foo {
    val v = 42
    // The returned function includes 'v' in its closure
    def f() = (x: Int) =&gt; v * x
  }

  // The function 'f' will serialize as expected
  val f = foo.f
  write(f, "/tmp/demo.f")
}
</code></pre>

<p>When this app is compiled and run, it will serialize <code>f</code> to "/tmp/demo.f1", which of course includes the value of <code>v</code> as part of the closure for <code>f</code>.</p>

<pre><code>$ scalac -d /tmp closures.scala
$ scala -cp /tmp Demo
$ ls /tmp/demo*
/tmp/demo.f
</code></pre>

<p>Now, imagine you wanted to make a straightforward change, where <code>object foo</code> becomes <code>class foo</code>:</p>

<pre><code>object Demo extends App {
  def write[A](obj: A, fname: String) {
    import java.io._
    new ObjectOutputStream(new FileOutputStream(fname)).writeObject(obj)
  }

  // foo is a class instead of an object
  class foo() {
    val v = 42
    // The returned function includes 'v' in its closure, but also a secret surprise
    def f() = (x: Int) =&gt; v * x
  }

  // This will throw an exception!
  val f = new foo().f
  write(f, "/tmp/demo.f")
}
</code></pre>

<p>It would be reasonable to expect that this minor variation behaves exactly as the previous one, but instead it throws an exception!</p>

<pre><code>$ scalac -d /tmp closures.scala
$ scala -cp /tmp Demo
java.io.NotSerializableException: Demo$foo
</code></pre>

<p>If we look at the exception message, we see that it's complaining about not knowing how to serialize objects of class <code>foo</code>.  But we weren't including any values of <code>foo</code> in the closure for <code>f</code>, only a particular member 'v'!  What gives?  Scala is not very helpful with diagnosing this problem, but when a class member value shows up in a closure that is defined <em>inside</em> the class body, the <em>entire instance</em>, including any and all other member values, is included in the closure.  Presumably this is because a class may have any number of instances, and the compiler is including the entire instance in the closure to properly resolve the correct member value.</p>

<p>One straightforward way to fix this is to simply make class <code>foo</code> serializable:</p>

<pre><code>class foo() extends Serializable {
  // ...
}
</code></pre>

<p>If you make this change to the above code, the example with <code>class foo</code> now works correctly, but it is working by serializing the entire <code>foo</code> instance, not just the value of <code>v</code>.</p>

<p>In many cases, this is not a problem and will work fine.  Serializing a few additional members may be inexpensive.  In other cases, however, it can be an impractical or impossible option.  For example, <code>foo</code> might include other very large members, which will be expensive or outright impossible to serialize:</p>

<pre><code>class foo() extends Serializable {
  val v = 42    // easy to serialize
  val w = 4.5   // easy to serialize
  val data = (1 to 1000000000).toList  // serialization landmine hiding in your closure

  // The returned function includes all of 'foo' instance in its closure
  def f() = (x: Int) =&gt; v * x
}
</code></pre>

<p>A variation on the above problem is class members that are small or moderate in size, but serialized many times.  In this case, the serialization cost can become intractable via repetition of unwanted inclusions.</p>

<p>Another potential problem is class members that are not serializable, and perhaps not under your control:</p>

<pre><code>class foo() extends Serializable {
  import some.class.NotSerializable

  val v = 42                      // easy to serialize
  val x = new NotSerializable     // I'll hide in your closure and fail to serialize

  // The returned function includes all of 'foo' instance in its closure
  def f() = (x: Int) =&gt; v * x
}
</code></pre>

<p>There is a relatively painless way to decouple values from their parent instance, so that only desired values are included in a closure.  Passing desired values as parameters to a shim function whose job is to assemble the closure will prevent the parent instance from being pulled into the closure.  In the following example, a shim function named <code>closureFunction</code> is defined for this purpose:</p>

<pre><code>object Demo extends App {
  def write[A](obj: A, fname: String) {
    import java.io._
    new ObjectOutputStream(new FileOutputStream(fname)).writeObject(obj)
  }

  // apply a generator to create a function with safe decoupled closures
  def closureFunction[E,D,R](enclosed: E)(gen: E =&gt; (D =&gt; R)) = gen(enclosed)

  class NotSerializable {}

  class foo() {
    val v1 = 42
    val v2 = 73
    val n = new NotSerializable

    // use shim function to enclose *only* the values of 'v1' and 'v2'
    def f() = closureFunction((v1, v2)) { enclosed =&gt;
      val (v1, v2) = enclosed
      (x: Int) =&gt; (v1 + v2) * x   // Desired function, with 'v1' and 'v2' enclosed
    }
  }

  // This will work!
  val f = new foo().f
  write(f, "/tmp/demo.f")
}
</code></pre>

<p>Being aware of the scenarios where parent instances are pulled into closures, and how to keep your closures clean, can save some frustration and wasted time.  Happy programming!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Faster Random Samples With Gap Sampling]]></title>
    <link href="http://erikerlandson.github.com/blog/2014/09/11/faster-random-samples-with-gap-sampling/"/>
    <updated>2014-09-11T07:57:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2014/09/11/faster-random-samples-with-gap-sampling</id>
    <content type="html"><![CDATA[<p>Generating a random sample of a collection is, logically, a O(np) operation, where (n) is the sample size and (p) is the sampling probability.  For example, extracting a random sample, without replacement, from an array might look like this in pseudocode:</p>

<pre><code>sample(data: array, p: real) {
    n = length(data)
    m = floor(p * n)
    for j = 0 to m-1 {
        k = random(j, n-1)
        swap(data[j], data[k])
    }
    emit the first m elements of 'data' to output
}
</code></pre>

<p>We can see that this sampling algorithm is indeed O(np).  However, it makes some nontrivial assumptions about its input data:</p>

<ul>
<li>It is random access</li>
<li>It is writable</li>
<li>Its size is known</li>
<li>It can be destructively modified</li>
</ul>


<p>These assumptions can be violated in several ways.  The input data might not support random access, for example it might be a list, or stream, or an iterator over the same.  We might not know its size a priori.  It might be read-only.  It might be up-cast to some superclass where knowledge about these assumed properties is no longer available.</p>

<p>In cases such as this, there is another common sampling algorithm:</p>

<pre><code>sample(data: sequence, p: real) {
    while not end(data) {
        v = next(data)
        if random(0.0, 1.0) &lt; p then emit v to output
    }
}
</code></pre>

<p>The above algorithm enjoys all the advantage in flexibility.  It requires only linear access, does not require writable input, and makes no assumptions about input size.  However it comes at a price: this algorithm is no longer O(np), it is O(n).  Each element must be traversed directly, and worse yet the random number generagor (RNG) must be invoked on each element.  O(n) invocation of the RNG is a substantial cost -- random number generation is typically very expensive compared to the cost of iterating to the next element in a sequence.</p>

<p>But... does linear sampling truly require us to invoke our RNG on every element?   Consider the pattern of data access, divorced from code.   It looks like a sequence of choices: for each element we either (skip) or (sample):</p>

<pre><code>(skip) (skip) (sample) (skip) (sample) (skip) (sample) (sample) (skip) (skip) (sample) ...
</code></pre>

<p>The number of consecutive (skip) events between each (sample) -- the <em>sampling gap</em> -- can itself be modeled as a random variable.  Each (skip)/(sample) choice is an independent Bernoulli trial, where the probability of (skip) is (1-p).   The PMF of the sampling gap for gap of {0, 1, 2, ...} is therefore a geometric distribution: P(k) = p(1-p)<sup>k</sup></p>

<p>This suggests an alternative algorithm for sampling, where we only need to randomly choose sample gaps instead of randomly choosing whether we sample each individual element:</p>

<pre><code>// choose a random sampling gap 'k' from P(k) = p(1-p)^k
// caution: this explodes for p = 0 or p = 1
random_gap(p: real) {
    u = max(random(0.0, 1.0), epsilon)
    return floor(log(u) / log(1-p))
}

sample(data: sequence, p: real) {
    advance(data, random_gap(p))
    while not end(data) {
        emit next(data) to output
        advance(data, random_gap(p))
    }
}
</code></pre>

<p>The above algorithm calls the RNG only once per actual collected sample, and so the cost of RNG calls is O(np).  Note that the algorithm is still O(n), but the cost of the RNG tends to dominate the cost of sequence traversal, and so the resulting efficiency improvement is substantial.  I measured the following performance improvements with gap sampling, compared to traditional linear sequence sampling, on a <a href="https://gist.github.com/erikerlandson/05db1f15c8d623448ff6">Scala prototype testing rig</a>:</p>

<p><head><style>
table, th, td {
border: 1px solid black;
border-collapse: collapse;
}
th, td {
padding: 10px;
}
th {
text-align: center;
}
</style></head></p>

<table>
<tr> <th>Type</th> <th>p</th> <th>linear</th> <th>gap</th> </tr>
<tr> <td>Array</td> <td>0.001</td> <td>2833</td> <td>29</td> </tr>
<tr> <td>Array</td> <td>0.01</td> <td>2825</td> <td>76</td> </tr>
<tr> <td>Array</td> <td>0.1</td> <td>2985</td> <td>787</td> </tr>
<tr> <td>Array</td> <td>0.5</td> <td>3526</td> <td>3478</td> </tr>
<tr> <td>Array</td> <td>0.9</td> <td>3023</td> <td>6081</td> </tr>
<tr> <td>List</td> <td>0.001</td> <td>2213</td> <td>230</td> </tr>
<tr> <td>List</td> <td>0.01</td> <td>2220</td> <td>265</td> </tr>
<tr> <td>List</td> <td>0.1</td> <td>2337</td> <td>796</td> </tr>
<tr> <td>List</td> <td>0.5</td> <td>2794</td> <td>3151</td> </tr>
<tr> <td>List</td> <td>0.9</td> <td>2513</td> <td>4849</td> </tr>
</table>




<br>


<p>In the results above, we see that the gap sampling times are essentially linear in (p), as expected.  In the case of the linear-access List type, there is a higher baseline time (230 vs 29) due to the constant cost of actual data traversal.  Efficiency improvements are substantial at small sampling probabilities.</p>

<p>We can also see that the cost of gap sampling begins to meet and then exceed the cost of traditinal linear sampling, in the vicinnity (p) = 0.5.  This is due to the fact that the gap sampling logic is about twice the cost (in my test environment) of simply calling the RNG once.  For example, the gap sampling invokes a call to the numeric logarithm code that isn't required in traditional sampling.  And so at (p) = 0.5 the time spent doing the gap sampling approximates the time spent invoking the RNG once per sample, and at higher values of (p) the cost is greater.</p>

<p>This suggests that one should in fact fall back to traditional linear sampling when the sampling probability (p) >= some threshold.  That threshold appears to be about 0.5 or 0.6 in my testing rig, but is likely to depend on underlying numeric libraries, the particular RNG being used, etc, and so I would expect it to benefit from customized tuning on a per-environment basis.  With this in mind, a sample algorithm as deployed would look like this:</p>

<pre><code>// threshold is a tuning parameter
threshold = 0.5

sample(data: sequence, p: real) {
    if (p &lt; threshold) {
        gap_sample(data, p)
    } else {
        traditional_linear_sample(data, p)
    }
}
</code></pre>

<p>The gap-sampling algorithm described above is for sampling <em>without</em> replacement.   However, the same approach can be modified to generate sampling <em>with</em> replacement.</p>

<p>When sampling with replacement, it is useful to consider the <em>replication factor</em> of each element (where a replication factor of zero means the element wasn't sampled).  Pretend for the moment that the actual data size (n) is known.  The sample size (m) = (n)(p).  The probability that each element gets sampled, per trial, is 1/n, with (m) independent trials, and so the replication factor (r) for each element obeys a binomial distribution: Binomial(m, 1/n).  If we substitute (n)(p) for (m), we have Binomial(np, 1/n).  As the (n) grows, the Binomial is <a href="http://en.wikipedia.org/wiki/Binomial_distribution#Poisson_approximation">well approximated by a Poisson distribution</a> Poisson(L), where (L) = (np)(1/n) = (p).  And so for our purposes we may sample from Poisson(p), where P(r) = (p<sup>r</sup> / r!)e<sup>(-p),</sup> for our sampling replication factors.  Note that we have now discarded any dependence on sample size (n), as we desire.</p>

<p>In our gap-sampling context, the sampling gaps are now elements whose replication factor is zero, which occurs with probability P(0) = e<sup>(-p).</sup>  And so our sampling gaps are now drawn from geometric distribution P(k) = (1-q)(q)<sup>k,</sup> where q = e<sup>(-p).</sup>   When we <em>do</em> sample an element, its replication factor is drawn from Poisson(p), however <em>conditioned such that the value is >= 1.</em>  It is straightforward to adapt a <a href="http://en.wikipedia.org/wiki/Poisson_distribution#Generating_Poisson-distributed_random_variables">standard Poisson generator</a>, as shown below.</p>

<p>Given the above, gap sampling with replacement in pseudocode looks like:</p>

<pre><code>// sample 'k' from Poisson(p), conditioned to k &gt;= 1
poisson_ge1(p: real) {
    q = e^(-p)
    // simulate a poisson trial such that k &gt;= 1
    t = q + (1-q)*random(0.0, 1.0)
    k = 1

    // continue standard poisson generation trials
    t = t * random(0.0, 1.0)
    while (t &gt; q) {
        k = k + 1
        t = t * random(0.0, 1.0)
    }
    return k
}

// choose a random sampling gap 'k' from P(k) = p(1-p)^k
// caution: this explodes for p = 0 or p = 1
random_gap(p: real) {
    u = max(random(0.0, 1.0), epsilon)
    return floor(log(u) / -p)
}

sample(data: sequence, p: real) {
    advance(data, random_gap(p))
    while not end(data) {
        rf = poisson_ge1(p)
        v = next(data)
        emit (rf) copies of (v) to output
        advance(data, random_gap(p))
    }
}
</code></pre>

<p>The efficiency improvements I have measured for gap sampling with replacement are shown here:</p>

<table>
<tr> <th>Type</th> <th>p</th> <th>linear</th> <th>gap</th> </tr>
<tr> <td>Array</td> <td>0.001</td> <td>2604</td> <td>45</td> </tr>
<tr> <td>Array</td> <td>0.01</td> <td>3442</td> <td>117</td> </tr>
<tr> <td>Array</td> <td>0.1</td> <td>3653</td> <td>1044</td> </tr>
<tr> <td>Array</td> <td>0.5</td> <td>5643</td> <td>5073</td> </tr>
<tr> <td>Array</td> <td>0.9</td> <td>7668</td> <td>8388</td> </tr>
<tr> <td>List</td> <td>0.001</td> <td>2431</td> <td>233</td> </tr>
<tr> <td>List</td> <td>0.01</td> <td>2450</td> <td>299</td> </tr>
<tr> <td>List</td> <td>0.1</td> <td>2984</td> <td>1330</td> </tr>
<tr> <td>List</td> <td>0.5</td> <td>5331</td> <td>4752</td> </tr>
<tr> <td>List</td> <td>0.9</td> <td>6744</td> <td>7811</td> </tr>
</table>




<br>


<p>As with the results for sampling without replacement, we see that gap sampling cost is linear with (p), which yields large cost savings at small sampling, but begins to exceed traditional linear sampling at higher sampling probabilities.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Implementing Parallel Prefix Scan as a Spark RDD Transform]]></title>
    <link href="http://erikerlandson.github.com/blog/2014/08/12/implementing-parallel-prefix-scan-as-a-spark-rdd-transform/"/>
    <updated>2014-08-12T11:37:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2014/08/12/implementing-parallel-prefix-scan-as-a-spark-rdd-transform</id>
    <content type="html"><![CDATA[<p>In my <a href="/blog/2014/08/09/implementing-an-rdd-scanleft-transform-with-cascade-rdds/">previous post</a>, I described how to implement the Scala <code>scanLeft</code> function as an RDD transform.  By definition <code>scanLeft</code> invokes a sequential-only prefix scan algorithm; it does not assume that either its input function <code>f</code> or its initial-value <code>z</code> can be applied in a parallel fashion.   Its companion function <code>scan</code>, however, computes a <em>parallel</em> prefix scan.  In this post I will describe an implementation of parallel prefix <code>scan</code> as an RDD transform.</p>

<p>As was the case with <code>scanLeft</code>, a basic strategy is to begin by applying <code>scan</code> to each RDD partition.  Provided that appropriate "offsets" <code>{z1, z2, ...}</code> can be computed for each partition, these can be applied to the partial, per-partition results to yield the output.   In fact, the desired <code>{z1, z2, ...}</code> are the parallel prefix scan of the last element in each per-partition scan.  The following diagram illustrates:</p>

<p><img src="/assets/images/rdd_scan/rdd_scan_4.png" alt="image" /></p>

<p>The diagram above glosses over the details of computing <code>scan</code> to obtain <code>{z1, z2, ...}</code>.   I will first describe the implementation I currently use, and then also discuss a possible alternative.  The current implementation takes the approach of encoding the <a href="http://en.wikipedia.org/wiki/Prefix_sum#Parallel_algorithm">logic of a parallel prefix scan</a> directly into an RDD computation DAG.   Each iteration, or "ply," of the parallel algorithm is represented by an RDD.  Each element resides in its own partition, and so the computation dependency for each element is directly representable in the RDD dependency substructure.  This construction is illustrated in the following schematic (for a vector of 8 z-values):</p>

<p><img src="/assets/images/rdd_scan/rdd_scan_5.png" alt="image" /></p>

<p>The parallel prefix scan algorithm executes O(log(n)) plies, which materializes as O(log(n)) RDDs shown in the diagram above.  In this context, (n) is the number of input RDD <em>partitions</em>, not to be confused with the number of data rows in the RDD.   There are O((n)log(n)) partitions, each having a single row containing the z-value for a corresponding output partition.   Some z-values are determined earlier than others.  For example z1 is immediately available in ply(0), and ply(3) can refer directly back to that ply(0) partition in the interest of efficiency, as called out by the red DAG arcs.</p>

<p>This scheme allows each final output partition to obtain its z-value directly from a single dedicated partition, which ensures that minimal data needs to be transferred across worker processes.  Final output partitions can be computed local to their corresponding input partitions.  Data transfer may be limited to the intermediate z-values, which are small single-row affairs by construction.</p>

<p>The code implementing the logic above can be <a href="https://github.com/erikerlandson/spark/blob/rdd_scan_blog/core/src/main/scala/org/apache/spark/rdd/ScanRDDFunctions.scala#L161">viewed here.</a></p>

<p>I will conclude by noting that there is an alternative to this highly distributed computation of <code>{z1, z2, ...}</code>, which is to collect the last-values in the per-partition intermediate scan ouputs into a single array, and run <code>scan</code> directly on that array.   This has the advantage of avoiding the construction of log(n) intermediate RDDs.   It does, however, require a monolithic 'fan-in' of data into a single RDD to receive the collection of values.  That is followed by a fan-out of the array, where each output partition picks its single z-value from the array.  It is for this reason I suspect this alternative incurs substantially more transfer overhead across worker processes.  However, one might also partition the resulting z-values in some optimal way, so that each final output partition needs to request only the partition that contains its z-value.  Future experimentation might show that this can out-perform the current fully-distributed implementation.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Implementing an RDD scanLeft Transform With Cascade RDDs]]></title>
    <link href="http://erikerlandson.github.com/blog/2014/08/09/implementing-an-rdd-scanleft-transform-with-cascade-rdds/"/>
    <updated>2014-08-09T09:10:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2014/08/09/implementing-an-rdd-scanleft-transform-with-cascade-rdds</id>
    <content type="html"><![CDATA[<p>In Scala, sequence (and iterator) data types support the <code>scanLeft</code> method for computing a sequential prefix scan on sequence elements:</p>

<pre><code>// Use scanLeft to compute the cumulative sum of some integers
scala&gt; List(1, 2, 3).scanLeft(0)(_ + _)
res0: List[Int] = List(0, 1, 3, 6)
</code></pre>

<p>Spark RDDs are logically a sequence of row objects, and so <code>scanLeft</code> is in principle well defined on RDDs.  In this post I will describe how to cleanly implement a <code>scanLeft</code> RDD transform by applying an RDD variation called Cascade RDDs.</p>

<p>A Cascade RDD is an RDD having one partition which is a function of an input RDD partition and an optional predecessor Cascade RDD partition.  You can see that this definition is somewhat recursive, where the basis case is a Cascade RDD having no precedessor.  The following diagram illustrates both cases of Cascade RDD:</p>

<p><img src="/assets/images/rdd_scanleft/rdd_scan_1.png" alt="image" /></p>

<p>As implied by the above diagram, a series of Cascade RDDs falling out of an input RDD will have as many Cascade RDDs as there are input partitions.  This situation begs for an abstraction to re-assemble the cascade back into a single output RDD, and so the method <code>cascadePartitions</code> is defined, as illustrated:</p>

<p><img src="/assets/images/rdd_scanleft/rdd_scan_3.png" alt="image" /></p>

<p>The <code>cascadePartitions</code> method takes a function argument <code>f</code>, with the signature:</p>

<pre><code>f(input: Iterator[T], cascade: Option[Iterator[U]]): Iterator[U]
</code></pre>

<p>in a manner somewhat analogous to <code>mapPartitions</code>.  The function <code>f</code> must address the fact that <code>cascade</code> is optional and will be <code>None</code> in case where there is no predecessor Cascade RDD.  The interested reader can examine the details of how the <code>CascadeRDD</code> class and its companion method <code>cascadePartitions</code> are <a href="https://github.com/erikerlandson/spark/blob/rdd_scan_blog/core/src/main/scala/org/apache/spark/rdd/CascadeRDDFunctions.scala">implemented here.</a></p>

<p>With Cascade RDDs it is now straightforward to define a <code>scanLeft</code> transform for RDDs.  We wish to run <code>scanLeft</code> on each input partition, with the condition that we want to start where the previous input partition left off.  The Scala <code>scanLeft</code> function makes this easy, as the starting point is its first parameter (z): <code>scanLeft(z)(f)</code>.  The following figure illustrates what this looks like:</p>

<p><img src="/assets/images/rdd_scanleft/rdd_scan_2.png" alt="image" /></p>

<p>As the above schematic demonstrates, almost all the work is accomplished with a single call to <code>cascadePartitions</code>, using a thin wrapper around <code>f</code> which determines where to start the next invocation of Scala <code>scanLeft</code> -- either the input parameter <code>z</code>, or the last output element of the previous cascade.   One final transform must be applied to remove the initial element that Scala <code>scanLeft</code> inserts into its output, excepting the first output partition, where it is kept to be consistent with the <code>scanLeft</code> definition.</p>

<p>All computation is accomplished in the standard RDD formalism, and so <code>scanLeft</code> is a proper lazy RDD transform.</p>

<p>The actual implementation is as compact as the above description implies, and you can see the <a href="https://github.com/erikerlandson/spark/blob/rdd_scan_blog/core/src/main/scala/org/apache/spark/rdd/ScanRDDFunctions.scala#L144">code here.</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Deferring Spark Actions to Lazy Transforms With the Promise RDD]]></title>
    <link href="http://erikerlandson.github.com/blog/2014/07/29/deferring-spark-actions-to-lazy-transforms-with-the-promise-rdd/"/>
    <updated>2014-07-29T13:53:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2014/07/29/deferring-spark-actions-to-lazy-transforms-with-the-promise-rdd</id>
    <content type="html"><![CDATA[<p>In a <a href="http://erikerlandson.github.io/blog/2014/07/27/some-implications-of-supporting-the-scala-drop-method-for-spark-rdds/">previous post</a> I described a method for implementing the Scala <code>drop</code> transform for Spark RDDs.  That implementation came at a cost of subverting the RDD lazy transform model; it forced the computation of one or more input RDD partitions at call time instead of deferring partition computation, and so behaved more like a Spark action than a transform.</p>

<p>In this followup post I will describe how to implement <code>drop</code> as a true lazy RDD transform, using a new RDD subclass: the Promise RDD.  A Promise RDD can be used to embed computations in the lazy transform formalism that otherwise would require non-lazy actions.</p>

<p>The Promise RDD (aka <code>PromiseRDD</code> subclass) is designed to encapsulate a single expression value in an RDD having exactly one row, to be evaluated <em>only</em> if and when its single partition is computed. It behaves somewhat analogously to a Scala <code>promise</code> structure, as it abstracts the expression such that any requests for its value (and hence its actual computation) may be deferred.</p>

<p>The definition of PromiseRDD is compact:</p>

<pre><code>class PromisePartition extends Partition {
  // A PromiseRDD has exactly one partition, by construction:
  override def index = 0
}

/**
 * A way to represent the concept of a promised expression as an RDD, so that it
 * can operate naturally inside the lazy-transform formalism
 */
class PromiseRDD[V: ClassTag](expr: =&gt; (TaskContext =&gt; V),
                              context: SparkContext, deps: Seq[Dependency[_]])
  extends RDD[V](context, deps) {

  // This RDD has exactly one partition by definition, since it will contain
  // a single row holding the 'promised' result of evaluating 'expr' 
  override def getPartitions = Array(new PromisePartition)

  // compute evaluates 'expr', yielding an iterator over a sequence of length 1:
  override def compute(p: Partition, ctx: TaskContext) = List(expr(ctx)).iterator
}
</code></pre>

<p>A PromiseRDD is constructed with the expression of choice, embodied as a function from a <code>TaskContext</code> to the implied expression type.   Note that <em>only</em> the task context is a parameter;  Any other inputs needed to evaluate the expression must be present in the closure of <code>expr</code>.  This allows the expression to be of very general form: its value may depend on a single input RDD, or multiple RDDs, or no RDDs at all.  It receives an arbitrary sequence of partition dependencies which is the responsibility of the calling code to assemble.  Again, this allows substantial generality in the form of the expression: the PromiseRDD dependencies can correspond to any arbitrary input dependencies assumed by the expression.  The dependencies can be tuned to exactly what input partitions are required.</p>

<p>As a motivating example, consider how a PromiseRDD can be used to promote <code>drop</code> to a true lazy transform.  The aspect of computing <code>drop</code> that threatens laziness is the necessity of determining the location of the boundary partition (<a href="http://erikerlandson.github.io/blog/2014/07/27/some-implications-of-supporting-the-scala-drop-method-for-spark-rdds/">see previous discussion</a>).  However, this portion of the computation can in fact be encapsulated in a PromiseRDD.  The details of constructing such a PromiseRDD can be <a href="https://github.com/erikerlandson/spark/blob/promise_rdd_blog/core/src/main/scala/org/apache/spark/rdd/DropRDDFunctions.scala#L46">viewed here</a>.  The following illustration summarizes the topology of the dependency DAG that is constructed:</p>

<p><img src="/assets/images/rdd_drop/rdd_drop_promise.png" alt="image" /></p>

<p>As the dependency diagram shows, the PromiseRDD responsible for locating the boundary partition depends on each partition of the original input RDD.  The actual computation is likely to only request the first input partition, but all partitions might be required to handle all possible arguments to <code>drop</code>.   In turn, the location information given by the PromiseRDD is depended upon by each output partition.  Input partitions are either passed to the output, or used to compute the boundary, and so none of the partition computation is wasted.</p>

<p>Observe that the scheduler remains in charge of when partitions are computed.  An advantage to using a PromiseRDD is that it works within Spark's computational model, instead of forcing it.</p>

<p>The following brief example demonstrates that <code>drop</code> implemented using a PromiseRDD satisfies the lazy transform model:</p>

<pre><code>// create data rdd with values 0 thru 9
scala&gt; val data = sc.parallelize(0 until 10)
data: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at &lt;console&gt;:12

// drop the first 3 rows
// note that no action is performed -- this transform is lazy
scala&gt; val rdd = data.drop(3)
rdd: org.apache.spark.rdd.RDD[Int] = $anon$1[2] at drop at &lt;console&gt;:14

// collect the values.  This action kicks off job scheduling and execution
scala&gt; rdd.collect
14/07/28 12:16:13 INFO SparkContext: Starting job: collect at &lt;console&gt;:17
... job scheduling and execution output ...

res0: Array[Int] = Array(3, 4, 5, 6, 7, 8, 9)

scala&gt;
</code></pre>

<p>In this post, I have described the Promise RDD, an RDD subclass that can be used to encapsulate computations in the lazy transform formalism that would otherwise require non-lazy actions.  As an example, I have outlined a lazy transform implementation of <code>drop</code> that uses PromiseRDD.</p>
]]></content>
  </entry>
  
</feed>
