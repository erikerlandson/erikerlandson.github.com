<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: computing | tool monkey]]></title>
  <link href="http://erikerlandson.github.com/blog/categories/computing/atom.xml" rel="self"/>
  <link href="http://erikerlandson.github.com/"/>
  <updated>2014-07-29T13:53:05-07:00</updated>
  <id>http://erikerlandson.github.com/</id>
  <author>
    <name><![CDATA[Erik Erlandson]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Deferring Spark Actions to Lazy Transforms With the Promise RDD]]></title>
    <link href="http://erikerlandson.github.com/blog/2014/07/29/deferring-spark-actions-to-lazy-transforms-with-the-promise-rdd/"/>
    <updated>2014-07-29T13:53:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2014/07/29/deferring-spark-actions-to-lazy-transforms-with-the-promise-rdd</id>
    <content type="html"><![CDATA[<p>In a <a href="http://erikerlandson.github.io/blog/2014/07/27/some-implications-of-supporting-the-scala-drop-method-for-spark-rdds/">previous post</a> I described a method for implementing the Scala <code>drop</code> transform for Spark RDDs.  That implementation came at a cost of subverting the RDD lazy transform model; it forced the computation of one or more input RDD partitions at call time instead of deferring partition computation, and so behaved more like a Spark action than a transform.</p>

<p>In this followup post I will describe how to implement <code>drop</code> as a true lazy RDD transform, using a new RDD subclass: the Promise RDD.  A Promise RDD can be used to embed computations in the lazy transform formalism that otherwise would require non-lazy actions.</p>

<p>The Promise RDD (aka <code>PromiseRDD</code> subclass) is designed to encapsulate a single expression value in an RDD having exactly one row, to be evaluated <em>only</em> if and when its single partition is computed. It behaves somewhat analogously to a Scala <code>promise</code> structure, as it abstracts the expression such that any requests for its value (and hence its actual computation) may be deferred.</p>

<p>The definition of PromiseRDD is compact:</p>

<pre><code>class PromisePartition extends Partition {
  // A PromiseRDD has exactly one partition, by construction:
  override def index = 0
}

/**
 * A way to represent the concept of a promised expression as an RDD, so that it
 * can operate naturally inside the lazy-transform formalism
 */
class PromiseRDD[V: ClassTag](expr: =&gt; (TaskContext =&gt; V),
                              context: SparkContext, deps: Seq[Dependency[_]])
  extends RDD[V](context, deps) {

  // This RDD has exactly one partition by definition, since it will contain
  // a single row holding the 'promised' result of evaluating 'expr' 
  override def getPartitions = Array(new PromisePartition)

  // compute evaluates 'expr', yielding an iterator over a sequence of length 1:
  override def compute(p: Partition, ctx: TaskContext) = List(expr(ctx)).iterator
}
</code></pre>

<p>A PromiseRDD is constructed with the expression of choice, embodied as a function from a <code>TaskContext</code> to the implied expression type.   Note that <em>only</em> the task context is a parameter;  Any other inputs needed to evaluate the expression must be present in the closure of <code>expr</code>.  This allows the expression to be of very general form: its value may depend on a single input RDD, or multiple RDDs, or no RDDs at all.  It receives an arbitrary sequence of partition dependencies which is the responsibility of the calling code to assemble.  Again, this allows substantial generality in the form of the expression: the PromiseRDD dependencies can correspond to any arbitrary input dependencies assumed by the expression.  The dependencies can be tuned to exactly what input partitions are required.</p>

<p>As a motivating example, consider how a PromiseRDD can be used to promote <code>drop</code> to a true lazy transform.  The aspect of computing <code>drop</code> that threatens laziness is the necessity of determining the location of the boundary partition (<a href="http://erikerlandson.github.io/blog/2014/07/27/some-implications-of-supporting-the-scala-drop-method-for-spark-rdds/">see previous discussion</a>).  However, this portion of the computation can in fact be encapsulated in a PromiseRDD.  The details of constructing such a PromiseRDD can be <a href="https://github.com/erikerlandson/spark/blob/promise_rdd_blog/core/src/main/scala/org/apache/spark/rdd/DropRDDFunctions.scala#L46">viewed here</a>.  The following illustration summarizes the topology of the dependency DAG that is constructed:</p>

<p><img src="/assets/images/rdd_drop/rdd_drop_promise.png" alt="image" /></p>

<p>As the dependency diagram shows, the PromiseRDD responsible for locating the boundary partition depends on each partition of the original input RDD.  The actual computation is likely to only request the first input partition, but all partitions might be required to handle all possible arguments to <code>drop</code>.   In turn, the location information given by the PromiseRDD is depended upon by each output partition.  Input partitions are either passed to the output, or used to compute the boundary, and so none of the partition computation is wasted.</p>

<p>Observe that the scheduler remains in charge of when partitions are computed.  An advantage to using a PromiseRDD is that it works within Spark's computational model, instead of forcing it.</p>

<p>The following brief example demonstrates that <code>drop</code> implemented using a PromiseRDD satisfies the lazy transform model:</p>

<pre><code>// create data rdd with values 0 thru 9
scala&gt; val data = sc.parallelize(0 until 10)
data: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at &lt;console&gt;:12

// drop the first 3 rows
// note that no action is performed -- this transform is lazy
scala&gt; val rdd = data.drop(3)
rdd: org.apache.spark.rdd.RDD[Int] = $anon$1[2] at drop at &lt;console&gt;:14

// collect the values.  This action kicks off job scheduling and execution
scala&gt; rdd.collect
14/07/28 12:16:13 INFO SparkContext: Starting job: collect at &lt;console&gt;:17
... job scheduling and execution output ...

res0: Array[Int] = Array(3, 4, 5, 6, 7, 8, 9)

scala&gt;
</code></pre>

<p>In this post, I have described the Promise RDD, an RDD subclass that can be used to encapsulate computations in the lazy transform formalism that would otherwise require non-lazy actions.  As an example, I have outlined a lazy transform implementation of <code>drop</code> that uses PromiseRDD.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Some Implications of Supporting the Scala drop Method for Spark RDDs]]></title>
    <link href="http://erikerlandson.github.com/blog/2014/07/27/some-implications-of-supporting-the-scala-drop-method-for-spark-rdds/"/>
    <updated>2014-07-27T17:08:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2014/07/27/some-implications-of-supporting-the-scala-drop-method-for-spark-rdds</id>
    <content type="html"><![CDATA[<p>In Scala, sequence data types support the <code>drop</code> method for skipping (aka "dropping") the first elements of the sequence:</p>

<pre><code>// drop the first element of a list
scala&gt; List(1, 2, 3).drop(1)
res1: List[Int] = List(2, 3)
</code></pre>

<p>Spark RDDs also support various standard sequence methods, for example <code>filter</code>, as they are logically a sequence of row objects.  One might suppose that <code>drop</code> could be a useful sequence method for RDDs, as it would support useful idioms like:</p>

<pre><code>// Use drop (hypothetically) to skip the header of a text file:
val data = sparkContext.textFile("data.txt").drop(1)
</code></pre>

<p>Implementing <code>drop</code> for RDDs is possible, and in fact can be done with a <a href="https://github.com/erikerlandson/spark/compare/erikerlandson:rdd_drop_blogpost_base...rdd_drop_blogpost">small amount of code</a>, however it comes at the price of an impact to the RDD lazy computing model.</p>

<p>To see why, recall that RDDs are composed of partitions, and so in order to drop the first (n) rows of an RDD, one must first identify the partition that contains the (n-1),(n) row boundary.  In the resulting RDD, this partition will be the first one to contain any data.  Identifying this "boundary" partition cannot have a closed-form solution, because partition sizes are not in general equal;  the partition interface does not even support the concept of a <code>count</code> method.  In order to obtain the size of a partition, one is forced to actually compute its contents.  The diagram below illustrates one example of why this is so -- the contents of the partitions in the filtered RDD on the right cannot be known without actually running the filter on the parent RDD:</p>

<p><img src="/assets/images/rdd_drop/rdd-drop-1.png" alt="image" /></p>

<p>Given all this, the structure of a <code>drop</code> implementation is to compute the first partition, find its length, and see if it contains the requested (n-1),(n) boundary.  If not, compute the next partition, and so on, until the boundary partition is identified.  All prior partitions are ignored in the result.  All subsequent partitions are passed on with no change.  The boundary partition is passed through its own <code>drop</code> to eliminate rows up to (n).</p>

<p>The code implementing the concept described above can be viewed here:
<a href="https://github.com/erikerlandson/spark/compare/erikerlandson:rdd_drop_blogpost_base...rdd_drop_blogpost">https://github.com/erikerlandson/spark/compare/erikerlandson:rdd_drop_blogpost_base...rdd_drop_blogpost</a></p>

<p>The following diagram illustrates the relation between input and output partitions in a call to <code>drop</code>:</p>

<p><img src="/assets/images/rdd_drop/rdd-drop-2.png" alt="image" /></p>

<p>Arguably, this represents a potential subversion of the RDD lazy compute model, as it forces the computation of at least one (and possibly more) partitions.  It behaves like a "partial action", instead of a transform, but an action that returns another RDD.</p>

<p>In many cases, the impact of this might be relatively small.  For example, dropping the first few rows in a text file is likely to only force computation of a single partition, and it is a partition that will eventually be computed anyway.  Furthermore, such a use case is generally not inside a tight loop.</p>

<p>However, it is not hard to construct cases where computing even the first partition of one RDD recursively forces the computation of <em>all</em> the partitions in its parents, as in this example:</p>

<p><img src="/assets/images/rdd_drop/rdd-drop-3.png" alt="image" /></p>

<p>Whether the benefits of supporting <code>drop</code> for RDDs outweigh the costs is an open question.  It is likely to depend on whether or not the Spark community yields any compelling use cases for <code>drop</code>, and whether a transform that behaves like a "partial action" is considered an acceptable addition to the RDD formalism.</p>

<p>RDD support for <code>drop</code> has been proposed as issue <a href="https://issues.apache.org/jira/browse/SPARK-2315">SPARK-2315</a>, with corresponding pull request <a href="https://github.com/apache/spark/pull/1254/">1254</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[A Bi-directional Variation of the O(NP) Edit Distance Algorithm]]></title>
    <link href="http://erikerlandson.github.com/blog/2014/02/20/a-bi-directional-variation-of-the-o-np-edit-distance-algorithm/"/>
    <updated>2014-02-20T19:51:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2014/02/20/a-bi-directional-variation-of-the-o-np-edit-distance-algorithm</id>
    <content type="html"><![CDATA[<p>The O(ND) edit distance algorithm <a href="#ref1">[1]</a> is a standard for efficient computation of the edit distance between two sequences, appearing in applications such as the GNU diff tool.  There is also a variation <a href="#ref2">[2]</a> that operates in O(NP) time, where P is the number of deletions in the shortest edit path, and which has lower computational complexity, since P &lt;= D (and may be &lt;&lt; D in some circumstances).  In order to apply these algorithms to obtain an <em>edit script</em> in linear space, they must be adapted into a bidirectional form that enables recursive divide-and-conquer.   The basic principles of a bidirectional adaptation of the O(ND) algorithm are described in <a href="#ref1">[1]</a>.   However, no such discussion of a bidirectional O(NP) algorithm is provided in <a href="#ref2">[2]</a>.  Understanding this adaptation involves some observations that aren't immediately obvious.  In this post, I will describe these key observations.</p>

<h3>Notation</h3>

<p>My code segments are written as C/C++, however written in a simplified style I hope will be clear regardless of what languages the reader is familiar with.  If you wish to port this (pseudo-ish)code, it may be worth keeping in mind that indexing is zero-based in C/C++.</p>

<h3>Sequence Lengths</h3>

<p>A brief note on the O(NP) algorithm and sequence lengths: the algorithm assumes that the length of its second sequence argument is >= its first (that is, N >= M).   In the following discussions, I will be making the same assumption, however the modification to address N &lt; M is relatively easy, and can be seen in the references to actual source code below.</p>

<h3>Indexing</h3>

<p>A note on naming:  In <a href="#ref2">[2]</a>, the authors use 'fp' for the name of the array holding path endpoints.  I will use 'Vf' for the array holding forward endpoints, and 'Vr' for the corresponding array holding reverse endpoints.</p>

<p>The O(ND) and O(NP) algorithms operate by iteratively extending the frontier of edit paths through the implicit graph of possible paths, where each iteration is computed as a function of the previous.  In the O(NP) algorithm, this computation has to proceed from the outside in, as described in the paper:</p>

<pre><code>for (k = -P;  k &lt; delta;  k += 1) {
    y = max(Vf[k-1] + 1, Vf[k+1]);
    Vf[k] = snake(y-k, y);
}
for (k = P + delta;  k &gt;= delta;  k -= 1) {
    y = max(Vf[k-1] + 1, Vf[k+1]);
    Vf[k] = snake(y-k, y);
}
</code></pre>

<p>In order to implement a bi-directional algorithm, we must also run the algorithm in reverse, beginning at the "lower right corner" of the graph (M,N) and working backward to the origin (0,0).  The indexing is the mirror image of the above:</p>

<pre><code>for (k = P+delta;  k &gt; 0;  k -= 1) {
    y = min(Vr[k-1], Vr[k+1] - 1);
    Vr[k] = rsnake(y-k, y);
}
for (k = -P;  k &lt;= 0;  k += 1) {
    y = min(Vr[k-1], Vr[k+1] - 1);
    Vr[k] = rsnake(y-k, y);
}
</code></pre>

<p>In the above, 'rsnake' is the reverse-direction snake function.  A note on initialization:  whereas the forward algorithm initializes its Vf array to (-1), the symmetric initial value for the reverse algorithm Vr array is (N+1) (In the general case, 1 plus the length of the longest sequence).</p>

<h3>Detecting Path Overlap</h3>

<p>The uni-directional O(NP) algorithm halts when Vf[delta] == N.  However, the bi-directional algorithms halt when shortest opposing paths meet -- or overlap -- each other, as described in the O(ND) paper <a href="#ref1">[1]</a>.  The semantics of storing paths in working arrays is the same in both algorithms, with the exception that in the O(NP) algorithm it is the (y) values that are stored.  Myers describes the predicate for detecting meeting paths in O(ND) as: (x >= u)  &amp;&amp;  (x-y == u-v), where (x,y) are forward endpoints and (u,v) are reverse endpoints.  Observe that since y = x-k, then (x-y == u-v) is equivalent to "forward-k == reverse-k".  However, in operation one always checks the opposing path with the <em>same</em> k index, and so this clause is redundant.  It is sufficient to check that (x >= u), or in the case of O(NP), that (y >= v).  In the code, this looks something like:</p>

<pre><code>y = max(Vf[k-1] + 1, Vf[k+1]);
if (y &gt;= Vr[k]) {
    // overlapping paths detected 
}
</code></pre>

<p>The other checks for forward and reverse are similar.  Note that these checks happen at the <em>beginning</em> of each 'snake', that is prior to invoking the snake extension logic.  The semantic is that the opposing path overlaps the run (snake) one is about to start.</p>

<h3>Computing Distance</h3>

<p>When two overlapping paths are detected, we must compute the path distance associated with their union.  In the O(ND) algorithm, we know that distance implicitly, as the paths are extended over successive iterations of D.  In the O(NP) algorithm, however, the current path endpoints are associated with a particular value of P, and so we must consider how to obtain the actual distance.</p>

<p>A little algebra comes to the rescue.  At iteration P, consider the number of deletions along the forward-path at the kth endpoint, which I will denote as 'vf' (the authors refer to it as V(x,y)).  In <a href="#ref2">[2]</a>, the authors show that P == vf when k &lt; delta, and P == vf+k-delta, when k > delta (note that either formula applies for k == delta).  Solving for vf, we have:   vf == P for k &lt; delta and vf == P+delta-k for k > delta.  The authors also show that: vf = (df-k)/2, where df is the total edit distance along the path up to the current endpoint (the authors refer to df as D(x,y)).   Therefore, we have: df = 2(vf)+k, where we can obtain vf from the expression we just derived.</p>

<p>It remains to derive the expressions for the reverse direction, where we want 'vr' and 'dr'.  Here, I note that the mirror-image indexing of the reverse algorithm implies that the expressions above work if we transform k --> delta-k.  Making that transform gives us:   vr == P for k > 0 and vr == P+k for k &lt; 0 (again, either applies for k == 0).  And dr = 2(vr)+delta-k.</p>

<p>And so the actual edit distance covered by our overlapping paths is:  d == (df+dr) == 2(vf+vr)+delta.  Note now pleasing this is, as vf+vr is the number of deletions of the combined paths, and so this corresponds to the original formula D == 2P+delta, where P is the number of deletions over the entire pathway.  We also see from the above that at a given Pth iteration, P does <em>not</em> equal the number of deletions in all paths with endpoints at the current iteration.  The true number of deletions for a given endpoint is a function of P, k and delta.</p>

<p>A note on implementation: when one is advancing forward paths, an overlapping reverse-path will be from previous iteration (P-1), as the reverse paths for (P) have not happened yet.  That will show up in the distance formula for (vr) by using (P-1) in place of P, as in this example code:</p>

<pre><code>y = max(Vf[k-1] + 1, Vf[k+1]);
if (y &gt;= Vr[k]) {
    // we found overlapping path, so compute corresponding edit distance
    vf = (k&gt;delta) ? (P + delta - k) : P;
    // use (P-1) for reverse paths:
    vr = (k&lt;0) ? (P-1 + k) : P-1;
    d = 2*(vf+vr)+delta;
}

// ....

y = min(Vr[k-1], Vr[k+1] - 1);
if (y &lt;= Vf[k]) {
    // we can use P for both since forward-paths have been advanced:
    vf = (k&gt;delta) ? (P + delta - k) : P;
    vr = (k&lt;0) ? (P + k) : P;
    d = 2*(vf+vr)+delta;
}
</code></pre>

<h3>Shortest Path</h3>

<p>With respect to halting conditions, the O(NP) algorithm differs in one imporant way from the O(ND) algorithm: The O(ND) algorithm maintains path endpoints corresponding to increasing <em>distance</em> (D) values.  Therefore, when two paths meet, they form a shortest-distance path by definition, and the algorithm can halt on the first such overlap it detects.</p>

<p>The same is <em>not true</em> for the O(NP) algorithm.  It stores endpoints at a particular P value.  However, at a given value of P, actual <em>distances</em> may vary considerably.  On a given iteration over P, actual path distances may vary from 2(P-1)+delta up to 4P+delta.</p>

<p>This problem is dealt with by maintaining a best-known distance, 'Dbest', which is initialized to its maximum possible value of N+M, the sum of both sequence lengths.  Whenever two overlapping paths are detected, their corresponding distance 'd' is computed as described earlier, and the running minimum is maintainted:  Dbest = min(Dbest,d).  As mentioned above, we know that the mimimum possible distance at a given iteration is Dmin = 2(P-1)+delta, and so when Dmin >= Dbest, we halt and return Dbest as our result.</p>

<h3>Loop Bounding</h3>

<p>Some important computational efficiency can be obtained by reorganizing the looping over the endpoints.   As mentioned above, conceptually the looping proceeds from the outside, inward.  Suppose we organize the looping over k values such that we explore k = {-P, P+delta, -P+1, P+delta-1, -P+2, P+delta-2 ... }  Note that the symmetry breaks a bit when we get to k==delta, as here we stop iterating backward, but continue iterating forward until we hit delta from below.  In the code, this looping pattern looks something like:</p>

<pre><code>// advance forward paths: reverse path looping is similar
for (ku = -P, kd = P+delta;  ku &lt;= delta;  ku += 1) {
    // advance diagonals from -P, upwards:
    y = max(1+Vf[ku-1], Vf[ku+1]);

    // check for overlapping path

    Vf[ku] = snake(y-ku, y);

    // stop searching backward past here:
    if (kd &lt;= delta) continue;

    // advance diagonals from P+delta, downwards:
    y = max(1+Vf[kd-1], Vf[kd+1]);

    // check for overlapping path

    Vf[kd] = snake(y-kd, y);
    kd -= 1;
}
</code></pre>

<p>There is method to this madness.  Observe that for any particular P value, the smallest edit distances are at the outside, and get larger as one moves inward.  The minimum distance 2P+delta is always when k == -P, and k == P+delta.  As we proceed inward, the corresponding edit distance increases towards its maximum of 4P+delta.   This allows <em>two</em> optimizations.  The first is that if we hit an overlapping path, we can now exit the loop immediately, as we know that any other such overlapping paths to our inside will have a larger edit distance, and so do not need to be considered.</p>

<p>The second optimization is to recall that path distances are a function of P, k and delta.  We can use this information to solve for k and obtain a useful adaptive bound on how far we loop.  From previous sections, also recall we are keeping a best-known distance Dbest.  We know that we do not have to explore any paths whose distance is >= Dbest.  So, we can set up the following inequality: 2(vf+vr)+delta &lt; Dbest, where vf = P, and vr = (P-1)+k, where k &lt; 0, which is the region where distance is growing.  Therefore, we have 2(P+(P-1)+k)+delta &lt; Dbest.  Solving for k, we have:  k &lt; ((Dbest-delta)/2)-2P+1.  The looping wants to use '&lt;=', so we can rewrite as: k &lt;= ((Dbest-delta-1)/2)-2P+1.  For the reverse-path looping, we can set up a similar inequality:  2(P+P+delta-k)+delta &lt; Dbest, which yields:  k >= ((1+delta-Dbest)/2)+delta+2P.</p>

<p>Note that if these bound expressions evaluate to a value past the nominal bound, then the nominal bound remains in effect: e.g. the operative forward looping bound = min(delta, ((Dbest-delta)/2)-2P).   Also note that these constraints do not break the computation of the endpoints, because when the bounds move, they always retreat toward the outside by 2 on each iteration of P.  Since computation proceeds outside in, that means the necessary values are always correctly populated from the previous iteration.</p>

<p>In the code, the forward path looping looks like this:</p>

<pre><code>// compute our adaptive loop bound (using P-1 for reverse)
bound = min(delta, ((Dbest-delta-1)/2)-(2*P)+1);

// constrain our search by bound:
for (ku = -P, kd = P+delta;  ku &lt;= bound;  ku += 1) {
    y = max(1+Vf[ku-1], Vf[ku+1]);
    if (y &gt;= Vr[k]) {
        vf = (k&gt;delta) ? (P + delta - k) : P;
        vr = (k&lt;0) ? (P-1 + k) : P-1;

        // maintain minimum distance:
        Dbest = min(Dbest, 2*(vf+vr)+delta);

        // we can now halt this loop immediately:
        break;
    }

    Vf[ku] = snake(y-ku, y);

    if (kd &lt;= delta) continue;

    y = max(1+Vf[kd-1], Vf[kd+1]);
    if (y &gt;= Vr[k]) {
        vf = (k&gt;delta) ? (P + delta - k) : P;
        vr = (k&lt;0) ? (P-1 + k) : P-1;

        // maintain minimum distance:
        Dbest = min(Dbest, 2*(vf+vr)+delta);

        // we can now halt this loop immediately:
        break;
    }

    Vf[kd] = snake(y-kd, y);
    kd -= 1;
}
</code></pre>

<h3>Implementation</h3>

<p>In conclusion, I will display a code segment with all of the ideas presented above, coming together.  This segment was taken from my <a href="https://github.com/erikerlandson/algorithm/blob/order_np_alg/include/boost/algorithm/sequence/detail/edit_distance.hpp#L342">working prototype code</a>, with some syntactic clutter removed and variable names changed to conform a bit more closely to <a href="#ref2">[2]</a>.  The implementation of O(NP) below is performing about 25% faster than the corresponding O(ND) algorithm in my benchmarking tests, and also uses substantially less memory.</p>

<pre><code>// initialize this with the maximum possible distance:
Dbest = M+N;

P = 0;
while (true) {
    // the minimum possible distance for the current P value
    Dmin = 2*(P-1) + delta;

    // if the minimum possible distance is &gt;= our best-known distance, we can halt
    if (Dmin &gt;= Dbest) return Dbest;

    // adaptive bound for the forward looping
    bound = min(delta, ((Dbest-delta-1)/2)-(2*P)+1);

    // advance forward diagonals
    for (ku = -P, kd = P+delta;  ku &lt;= bound;  ku += 1) {
        y = max(1+Vf[ku-1], Vf[ku+1]);
        x = y-ku;

        // path overlap detected
        if (y &gt;= Vr[ku]) {
            vf = (ku&gt;delta) ? (P + delta - ku) : P;
            vr = (ku&lt;0) ? (P-1 + ku) : P-1;
            Dbest = min(Dbest, 2*(vf+vr)+delta);
            break;
        }

        // extend forward snake
        if (N &gt;= M) {
            while (x &lt; M  &amp;&amp;  y &lt; N  &amp;&amp;  equal(S1[x], S2[y])) { x += 1;  y += 1; }
        } else {
            while (x &lt; N  &amp;&amp;  y &lt; M  &amp;&amp;  equal(S1[y], S2[x])) { x += 1;  y += 1; }
        }

        Vf[ku] = y;

        if (kd &lt;= delta) continue;

        y = max(1+Vf[kd-1], Vf[kd+1]);
        x = y-kd;

        // path overlap detected
        if (y &gt;= Vr[kd]) {
            vf = (kd&gt;delta) ? (P + delta - kd) : P;
            vr = (kd&lt;0) ? (P-1 + kd) : P-1;
            Dbest = min(Dbest, 2*(vf+vr)+delta);
            break;
        }

        // extend forward snake
        if (N &gt;= M) {
            while (x &lt; M  &amp;&amp;  y &lt; N  &amp;&amp;  equal(S1[x], S2[y])) { x += 1;  y += 1; }
        } else {
            while (x &lt; N  &amp;&amp;  y &lt; M  &amp;&amp;  equal(S1[y], S2[x])) { x += 1;  y += 1; }
        }

        Vf[kd] = y;
        kd -= 1;
    }

    // adaptive bound for the reverse looping
    bound = max(0, ((1+delta-Dbest)/2)+delta+(2*P));

    // advance reverse-path diagonals:
    for (kd=P+delta, ku=-P;  kd &gt;= bound;  kd -= 1) {
        y = min(Vr[kd-1], Vr[kd+1]-1);
        x = y-kd;

        // path overlap detected
        if (y &lt;= Vf[kd]) {
            vf = (kd&gt;delta) ? (P + delta - kd) : P;
            vr = (kd&lt;0) ? (P + kd) : P;
            Dbest = min(Dbest, 2*(vf+vr)+delta);
            break;
        }

        // extend reverse snake
        if (N &gt;= M) {
            while (x &gt; 0  &amp;&amp;  y &gt; 0  &amp;&amp;  equal(S1[x-1], S2[y-1])) { x -= 1;  y -= 1; }
        } else {
            while (x &gt; 0  &amp;&amp;  y &gt; 0  &amp;&amp;  equal(S1[y-1], S2[x-1])) { x -= 1;  y -= 1; }
        }

        Vr[kd] = y;

        if (ku &gt;= 0) continue;

        y = min(Vr[ku-1], Vr[ku+1]-1);
        x = y-ku;

        // path overlap detected
        if (y &lt;= Vf[ku]) {
            vf = (ku&gt;delta) ? (P + delta - ku) : P;
            vr = (ku&lt;0) ? (P + ku) : P;
            Dbest = min(Dbest, 2*(vf+vr)+delta);
            break;
        }

        // extend reverse snake
        if (N &gt;= M) {
            while (x &gt; 0  &amp;&amp;  y &gt; 0  &amp;&amp;  equal(S1[x-1], S2[y-1])) { x -= 1;  y -= 1; }
        } else {
            while (x &gt; 0  &amp;&amp;  y &gt; 0  &amp;&amp;  equal(S1[y-1], S2[x-1])) { x -= 1;  y -= 1; }
        }

        Vr[ku] = y;
        ku += 1;
    }
}
</code></pre>

<h3>References</h3>

<p><a name="anchor1" id="ref1">[1] </a><a href="http://www.xmailserver.org/diff2.pdf">An O(ND) Difference Algorithm and its Variations</a>, Eugene W. Myers<br>
<a name="anchor2" id="ref2">[2] </a><a href="http://www.itu.dk/stud/speciale/bepjea/xwebtex/litt/an-onp-sequence-comparison-algorithm.pdf">An O(NP) Sequence Comparison Algorithm</a>, Sun Wu, Udi Manber, Gene Myers</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Impact of Negotiator Cycle Cadence on Slot Loading]]></title>
    <link href="http://erikerlandson.github.com/blog/2013/03/21/the-impact-of-negotiator-cycle-cadence-on-slot-loading/"/>
    <updated>2013-03-21T15:10:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2013/03/21/the-impact-of-negotiator-cycle-cadence-on-slot-loading</id>
    <content type="html"><![CDATA[<p>The <a href="http://research.cs.wisc.edu/htcondor/manual/v7.8/3_1Introduction.html#8555">HTCondor negotiator</a> assigns jobs (resource requests) to slots (compute resources) at regular intervals, configured by the <a href="http://research.cs.wisc.edu/htcondor/manual/v7.8/3_3Configuration.html#20544">NEGOTIATOR_INTERVAL</a> parameter.  This interval (the cycle <em>cadence</em>) has a fundamental impact on a pool <em>loading factor</em> -- the fraction of time that slots are being productively utilized.</p>

<p>Consider the following diagram, which illustrates the utilization of a slot over the lifetime of a job.  When a job completes, its slot will remain empty until it can be assigned a new job on the next negotiation cycle.</p>

<p><img src="/assets/images/slot_load_study/loading_factor_diagram.png" width="750"></p>

<p>As the diagram above shows, the loading factor for a slot can be expressed as D/Z, where D is the duration of the job, and Z is the total time until the next cycle occurring after the job completes.  We can also write Z = D+I, where I is the "idle time" from job completion to the start of the next negotiation cycle.   Loading factor is always &lt;= 1, where a value of 1 corresponds to ideal loading -- every slot is utilized 100% of the time.  In general, loading will be &lt; 1, as jobs rarely complete exactly on a cycle boundary.</p>

<p>It is worth briefly noting that the <a href="http://research.cs.wisc.edu/htcondor/manual/v7.8/3_3Configuration.html#18202">claim reuse</a> feature was developed to help address this problem.  However, claim re-use is not compatible with all other features -- for example enabling claim re-use can cause accounting group starvation -- and so what follows remains relevant to many HTCondor configurations.</p>

<p>Given a particular negotiation cycle cadence, how does a slot's loading factor behave, as a function of job duration?  The loading factor can be expressed as:</p>

<div markdown="0">
\\[
\\text{Loading Factor} = \\frac{D}{C \\left( q + \\lceil r \\rceil \\right)} \\\\
 \\\\
\\text{where:} \\\\
D = \\text{job duration} \\\\
C = \\text{cycle cadence} \\\\
q = \\lfloor D / C \\rfloor \\\\
r = \\left( D / C \\right) - q \\\\
\\]
</div>


<p>The following plot illustrates how the loading factor changes with job duration, assuming a cadence of 300 seconds (5 minutes):</p>

<p><img src="/assets/images/slot_load_study/load_factor_300s.png" width="750"></p>

<p>We immediately see that there is a saw-tooth pattern to the plot.  As the job duration increases towards the boundary of a cycle, there is less and less idle time until the next cycle, and so the loading approaches 1.0.  However, once the job's end crosses the thresold to <em>just past</em> the start of the cycle, it immediately drops to the worse possible case: the slot will be idle for nearly an entire cycle.</p>

<p>The other important pattern is that the bottom of the saw-tooth gradually increases.  As a job's duration occupies more whole negotiation cycles, the idle time at the end of the last cycle represents a decreasing fraction of the total time.</p>

<p>Observe that the most important 'unit' in this plot is the number of negotiation cycles.  Since the saw-toothing scales with the cycle interval, we can express the same plot in units of cycles instead of seconds:</p>

<p><img src="/assets/images/slot_load_study/load_factor_cu.png" width="750"></p>

<p>The results above suggest a couple possible approaches for tuning negotiator cycle cadence to optimize slot loading in an HTCondor pool.  The first is to configure the negotiator interval to be small relative to a typical job duration, as the lower-bound on loading factor increases with the number of cycles a job's duration occupies.  For example, if a typical job duration is 10 minutes, then a cycle cadence of 60 seconds ensures that in general 9 out of 10 cycles will be fully utilized, and so loading will be around 90%.  However, if one has mostly very short jobs, this can be difficult, as negotiation cycle cadences much less than 60 seconds may risk causing performance problems even on a moderately loaded pool.</p>

<p>A second approach is to try and tune the cadence so that as many jobs as possible complete <em>near the end</em> of a cycle, thus minimizing delay until the next cycle.  For example, if job durations are relatively consistent, say close to 90 seconds, then setting the negotiator interval to something like 50 seconds will induce those jobs to finish near the end of the 2nd negotiation cycle (at t+100 seconds), for a loading factor around 90%.  The caveat here is that job durations are frequently <em>not</em> that consistent, and as job duration spread increases, one's ability to play this game <a href="http://erikerlandson.github.com/blog/2013/03/15/examining-the-modulus-of-random-variables/">rapidly evaporates</a>.</p>

<p>In this post, I have focused on the behavior of individual jobs and individual slots.  An obvious next question is what happens to aggregate pool loading when job durations are treated as population sampling from random variables, which I plan to explore in future posts.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Smooth Gradients for Cubic Hermite Splines]]></title>
    <link href="http://erikerlandson.github.com/blog/2013/03/16/smooth-gradients-for-cubic-hermite-splines/"/>
    <updated>2013-03-16T07:39:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2013/03/16/smooth-gradients-for-cubic-hermite-splines</id>
    <content type="html"><![CDATA[<p>One of the advantages of cubic Hermite splines is that their interval interpolation formula is an explicit function of gradients \( m_0, m_1, ... m_{n-1} \) at knot-points:</p>

<div markdown="0">
\\[
y(t) = h_{00}(t) y_j + h_{10}(t) m_j + h_{01}(t) y_{j+1} + h_{11}(t) m_{j+1} \\\\
\\]
</div>


<p>where the Hermite bases are:</p>

<div markdown="0">
\\[
h_{00} = 2t^3 - 3t^2 + 1 \\\\
h_{10} = t^3 - 2t^2 + t \\\\
h_{01} = -2t^3 + 3t^2 \\\\
h_{11} = t^3 - t^2 \\\\
\\]
</div>


<p>(For now, I will be using the unit-interval form of the interpolation, where t runs from 0 to 1 on each interval.  I will also discuss the non-uniform interval equations below)</p>

<p>This formulation allows one to explicitly specify the interpolation gradient at each knot point, and to choose from various gradient assignment policies, for example <a href="http://en.wikipedia.org/wiki/Cubic_Hermite_spline#Interpolating_a_data_set">those listed here</a>, even supporting policies for <a href="http://en.wikipedia.org/wiki/Monotone_cubic_interpolation">enforcing monotonic interpolations</a>.</p>

<p>One important caveat with cubic Hermite splines is that although the gradient \( y'(t) \) is guaranteed to be continuous, it is <em>not</em> guaranteed to be smooth (that is, differentiable) <em>across</em> the knots (it is of course smooth <em>inside</em> each interval). Therefore, another useful category of gradient policy is to obtain gradients \( m_0, m_1, ... m_{n-1} \) such that \( y'(t) \) is also smooth across knots.</p>

<p>(I feel sure that what follows was long since derived elsewhere, but my attempts to dig the formulation up on the internet failed, and so I decided the derivation might make a useful blog post)</p>

<p>To ensure smooth gradient across knot points, we want the 2nd derivative \( y"(t) \) to be equal at the boundaries of adjacent intervals:</p>

<div markdown="0">
\\[
h_{00}^"(t) y_{j-1} + h_{10}^"(t) m_{j-1} + h_{01}^"(t) y_j + h_{11}^"(t) m_j \\\\
= \\\\
h_{00}^"(t) y_j + h_{10}^"(t) m_j + h_{01}^"(t) y_{j+1} + h_{11}^"(t) m_{j+1}
\\]
</div>


<p>or substituting the 2nd derivative of the basis definitions above:</p>

<div markdown="0">
\\[
\\left( 12 t - 6 \\right) y_{j-1} + \\left( 6 t - 4 \\right) m_{j-1}  + \\left( 6 - 12 t \\right) y_j + \\left( 6 t - 2 \\right) m_j \\\\
= \\\\
\\left( 12 t - 6 \\right) y_{j} + \\left( 6 t - 4 \\right) m_{j}  + \\left( 6 - 12 t \\right) y_{j+1} + \\left( 6 t - 2 \\right) m_{j+1}
\\]
</div>


<p>Observe that t = 1 on the left hand side of this equation, and t = 0 on the right side, and so we have:</p>

<div markdown="0">
\\[
6 y_{j-1} + 2 m_{j-1} - 6 y_j + 4 m_j
=
-6 y_j - 4 m_j + 6 y_{j+1} - 2 m_{j+1}
\\]
</div>


<p>which we can rearrange as:</p>

<div markdown="0">
\\[
2 m_{j-1} + 8 m_j + 2 m_{j+1}
=
6 \\left( y_{j+1} - y_{j-1} \\right)
\\]
</div>


<p>Given n knot points, the above equation holds for j = 1 to n-2 (using zero-based indexing, as nature intended).  Once we define equations for j = 0 and j = n-1, we will have a system of equations to solve.  There are two likely choices.  The first is to simply specify the endpoint gradients \( m_0 = G \) and \( m_{n-1} = H \) directly, which yields the following <a href="http://en.wikipedia.org/wiki/Tridiagonal_matrix_algorithm">tri-diagonal matrix equation:</a></p>

<div markdown="0">
\\[
\\left( \\begin{array} {ccccc}
1 &   &   &   &   \\\\
2 & 8 & 2 &   &   \\\\
  & 2 & 8 & 2 &   \\\\
  &   & \\vdots &   &   \\\\
  &   & 2 & 8 & 2 \\\\ 
  &   &   &   & 1 \\\\
\\end{array} \\right)

\\left( \\begin{array} {c}
m_0 \\\\
m_1 \\\\
 \\\\
\\vdots \\\\
 \\\\
m_{n-1}
\\end{array} \\right)
=
\\left( \\begin{array} {c}
G \\\\
6 \\left( y_2 - y_0 \\right) \\\\
6 \\left( y_3 - y_1 \\right) \\\\
\\vdots \\\\
6 \\left( y_{n-1} - y_{n-3} \\right) \\\\
H \\\\
\\end{array} \\right)
\\]
</div>


<p>The second common endpoint policy is to set the 2nd derivative equal to zero -- the "natural spline."   Setting the 2nd derivative to zero at the left-end knot (and t = 0) gives us:</p>

<div markdown="0">
\\[
4 m_0 + 2 m_1   =   6 \\left( y_1 - y_0 \\right)
\\]
</div>


<p>Similarly, at the right-end knot (t = 1), we have:</p>

<div markdown="0">
\\[
2 m_0 + 4 m_1   =   6 \\left( y_{n-1} - y_{n-2} \\right)
\\]
</div>


<p>And so for a natural spline endpoint policy the matrix equation looks like this:</p>

<div markdown="0">
\\[
\\left( \\begin{array} {ccccc}
4 & 2 &   &   &   \\\\
2 & 8 & 2 &   &   \\\\
  & 2 & 8 & 2 &   \\\\
  &   & \\vdots &   &   \\\\
  &   & 2 & 8 & 2 \\\\ 
  &   &   & 2 & 4 \\\\
\\end{array} \\right)

\\left( \\begin{array} {c}
m_0 \\\\
m_1 \\\\
 \\\\
\\vdots \\\\
 \\\\
m_{n-1}
\\end{array} \\right)
=
\\left( \\begin{array} {c}
6 \\left( y_1 - y_0 \\right) \\\\
6 \\left( y_2 - y_0 \\right) \\\\
6 \\left( y_3 - y_1 \\right) \\\\
\\vdots \\\\
6 \\left( y_{n-1} - y_{n-3} \\right) \\\\
6 \\left( y_{n-1} - y_{n-2} \\right) \\\\
\\end{array} \\right)
\\]
</div>


<p>The derivation above is for uniform (and unit) intervals, where t runs from 0 to 1 on each knot interval.  I'll now discuss the variation where knot intervals are non-uniform.   The non-uniform form of the interpolation equation is:</p>

<div markdown="0">
\\[
y(x) = h_{00}(t) y_j + h_{10}(t) d_j m_j + h_{01}(t) y_{j+1} + h_{11}(t) d_j m_{j+1} \\\\
\\text{ } \\\\
\\text{where:} \\\\
\\text{ }  \\\\
d_j = x_{j+1} - x_j \\text{  for  } j = 0, 1, ... n-2 \\\\
t = (x - x_j) / d_j
\\]
</div>


<p>Taking \( t = t(x) \) and applying the chain rule, we see that 2nd derivative equation now looks like:</p>

<div markdown="0">
\\[
y"(x) = \\frac { \\left( 12 t - 6 \\right) y_{j} + \\left( 6 t - 4 \\right) d_j m_{j}  + \\left( 6 - 12 t \\right) y_{j+1} + \\left( 6 t - 2 \\right) d_j m_{j+1} } { d_j^2 }
\\]
</div>


<p>Applying a derivation similar to the above, we find that our (interior) equations look like this:</p>

<div markdown="0">
\\[
\\frac {2} { d_{j-1} }  m_{j-1} + \\left( \\frac {4} { d_{j-1} } + \\frac {4} { d_j } \\right) m_j + \\frac {2} {d_j} m_{j+1}
=
\\frac { 6 \\left( y_{j+1} - y_{j} \\right) } { d_j^2 } + \\frac { 6 \\left( y_{j} - y_{j-1} \\right) } { d_{j-1}^2 }
\\]
</div>


<p>and natural spline endpoint equations are:</p>

<div markdown="0">
\\[
\\text{left:  } \\frac {4} {d_0} m_0 + \\frac {2} {d_0} m_1   =   \\frac {6 \\left( y_1 - y_0 \\right)} {d_0^2} \\\\
\\text{right: } \\frac {2} {d_{n-2}} m_0 + \\frac {4} {d_{n-2}} m_1   =   \\frac {6 \\left( y_{n-1} - y_{n-2} \\right)} {d_{n-2}^2}
\\]
</div>


<p>And so the matrix equation for specified endpoint gradients is:</p>

<div markdown="0">
\\[
\\scriptsize
\\left( \\begin{array} {ccccc}
\\normalsize 1 \\scriptsize &   &   &   &   \\\\
\\frac{2}{d_0} & \\frac{4}{d_0} {+} \\frac{4}{d_1} & \\frac{2}{d_1} &   &   \\\\
  & \\frac{2}{d_1} & \\frac{4}{d_1} {+} \\frac{4}{d_2} & \\frac{2}{d_2} &   \\\\
  &   & \\vdots &   &   \\\\
  &   & \\frac{2}{d_{n-3}} & \\frac{4}{d_{n-3}} {+} \\frac{4}{d_{n-2}} & \\frac{2}{d_{n-2}} \\\\ 
  &   &   &   & \\normalsize 1 \\scriptsize \\\\
\\end{array} \\right)

\\left( \\begin{array} {c}
m_0 \\\\
m_1 \\\\
 \\\\
\\vdots \\\\
 \\\\
m_{n-1}
\\end{array} \\right)
=
\\left( \\begin{array} {c}
G \\\\
6 \\left( \\frac{y_2 {-} y_1}{d_1^2} {+} \\frac{y_1 {-} y_0}{d_0^2} \\right) \\\\
6 \\left( \\frac{y_3 {-} y_2}{d_2^2} {+} \\frac{y_2 {-} y_1}{d_1^2} \\right)  \\\\
\\vdots \\\\
6 \\left( \\frac{y_{n-1} {-} y_{n-2}}{d_{n-2}^2} {+} \\frac{y_{n-2} {-} y_{n-3}}{d_{n-3}^2} \\right) \\\\
H \\\\
\\end{array} \\right)
\\normalsize
\\]
</div>


<p>And the equation for natural spline endpoints is:</p>

<div markdown="0">
\\[
\\scriptsize
\\left( \\begin{array} {ccccc}
\\frac{4}{d_0} & \\frac{2}{d_0}  &   &   &   \\\\
\\frac {2} {d_0} & \\frac {4} {d_0} {+} \\frac {4} {d_1} & \\frac{2}{d_1} &   &   \\\\
  & \\frac{2}{d_1} & \\frac{4}{d_1} {+} \\frac{4}{d_2} & \\frac{2}{d_2} &   \\\\
  &   & \\vdots &   &   \\\\
  &   & \\frac{2}{d_{n-3}} & \\frac{4}{d_{n-3}} {+} \\frac{4}{d_{n-2}} & \\frac{2}{d_{n-2}} \\\\ 
  &   &   & \\frac{2}{d_{n-2}} & \\frac{4}{d_{n-2}} \\\\
\\end{array} \\right)

\\left( \\begin{array} {c}
m_0 \\\\
m_1 \\\\
 \\\\
\\vdots \\\\
 \\\\
m_{n-1}
\\end{array} \\right)
=
\\left( \\begin{array} {c}
\\frac{6 \\left( y_1 {-} y_0 \\right)}{d_0^2} \\\\
6 \\left( \\frac{y_2 {-} y_1}{d_1^2}  {+}  \\frac{y_1 {-} y_0}{d_0^2} \\right) \\\\
6 \\left( \\frac{y_3 {-} y_2}{d_2^2}  {+}  \\frac{y_2 {-} y_1}{d_1^2} \\right)  \\\\
\\vdots \\\\
6 \\left( \\frac{y_{n-1} {-} y_{n-2}}{d_{n-2}^2}  {+}  \\frac{y_{n-2} {-} y_{n-3}}{d_{n-3}^2} \\right) \\\\
\\frac{6 \\left( y_{n-1} {-} y_{n-2} \\right)}{d_{n-2}^2} \\\\
\\end{array} \\right)
\\normalsize
\\]
</div>

]]></content>
  </entry>
  
</feed>
