<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: computing | tool monkey]]></title>
  <link href="http://erikerlandson.github.com/blog/categories/computing/atom.xml" rel="self"/>
  <link href="http://erikerlandson.github.com/"/>
  <updated>2018-05-29T06:31:05-07:00</updated>
  <id>http://erikerlandson.github.com/</id>
  <author>
    <name><![CDATA[Erik Erlandson]]></name>
    <email><![CDATA[erikerlandson@yahoo.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Computing Smooth Max and its Gradients Without Over- and Underflow]]></title>
    <link href="http://erikerlandson.github.com/blog/2018/05/28/computing-smooth-max-and-its-gradients-without-over-and-underflow/"/>
    <updated>2018-05-28T08:13:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2018/05/28/computing-smooth-max-and-its-gradients-without-over-and-underflow</id>
    <content type="html"><![CDATA[<p>In my <a href="http://erikerlandson.github.io/blog/2018/05/27/the-gradient-and-hessian-of-the-smooth-max-over-functions/">previous post</a> I derived the gradient and Hessian for the smooth max function.
The <a href="https://www.johndcook.com/blog/">Notorious JDC</a> wrote a helpful companion post that describes <a href="https://www.johndcook.com/blog/2010/01/20/how-to-compute-the-soft-maximum/">computational issues</a> of overflow and underflow with smooth max;
values of f<sub>k</sub> don't have to grow very large (or small) before floating point limitations start to force their exponentials to +inf or zero.
In JDC's post he discusses this topic in terms of a two-valued smooth max.
However it isn't hard to generalize the idea to a collection of f<sub>k</sub>.
Start by taking the maximum value over our collection of functions, which I'll define as (z):</p>

<p><img src="/assets/images/smoothmax/eq1b.png" alt="eq1" /></p>

<p>As JDC described in his post, this alternative expression for smooth max (m) is computationally stable.
Individual exponential terms may underflow to zero, but they are the ones which are dominated by the other terms, and so approximating them by zero is numerically accurate.
In the limit where one value dominates all others, it will be exactly the value given by (z).</p>

<p>It turns out that we can play a similar trick with computing the gradient:</p>

<p><img src="/assets/images/smoothmax/eq2b.png" alt="eq2" /></p>

<p>Without showing the derivation, we can apply exactly the same manipulation to the terms of the Hessian:</p>

<p><img src="/assets/images/smoothmax/eq3b.png" alt="eq3" /></p>

<p>And so we now have a computationally stable form of the equations for smooth max, its gradient and its Hessian. Enjoy!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Gradient and Hessian of the Smooth Max Over Functions]]></title>
    <link href="http://erikerlandson.github.com/blog/2018/05/27/the-gradient-and-hessian-of-the-smooth-max-over-functions/"/>
    <updated>2018-05-27T09:36:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2018/05/27/the-gradient-and-hessian-of-the-smooth-max-over-functions</id>
    <content type="html"><![CDATA[<p>Suppose you have a set of functions over a vector space, and you are interested in taking the smooth-maximum over those functions.
For example, maybe you are doing gradient descent, or convex optimization, etc, and you need a variant on "maximum" that has a defined gradient.
The smooth maximum function has both a defined gradient and Hessian, and in this post I derive them.</p>

<p>I am using the <a href="https://www.johndcook.com/blog/2010/01/13/soft-maximum/">logarithm-based</a> definition of smooth-max, shown here:</p>

<p><img src="/assets/images/smoothmax/eq1.png" alt="eq1" /></p>

<p>I will use the second variation above, ignoring function arguments, with the hope of increasing clarity.
Applying the chain rule gives the ith partial gradient of smooth-max:</p>

<p><img src="/assets/images/smoothmax/eq2.png" alt="eq2" /></p>

<p>Now that we have an ith partial gradient, we can take the jth partial gradient of <em>that</em> to obtain the (i,j)th element of a Hessian:</p>

<p><img src="/assets/images/smoothmax/eq3.png" alt="eq3" /></p>

<p>This last re-grouping of terms allows us to see that we can express the full gradient and Hessian in the following more compact way:</p>

<p><img src="/assets/images/smoothmax/eq4.png" alt="eq4" /></p>

<p>With a gradient and Hessian, we now have the tools we need to use smooth-max in algorithms such as gradient descent and convex optimization. Happy computing!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rethinking the Concept of Release Versioning]]></title>
    <link href="http://erikerlandson.github.com/blog/2017/08/23/generalizing-the-concept-of-release-versioning/"/>
    <updated>2017-08-23T17:22:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2017/08/23/generalizing-the-concept-of-release-versioning</id>
    <content type="html"><![CDATA[<p>Recently I've been thinking about a few related problems with our current concepts of software release versioning, release dependencies and release building.
These problems apply to software releases in all languages and build systems that I've experienced,
but in the interest of keeping this post as simple as possible I'm going to limit myself to talking about the Maven ecosystem of release management and build tooling.</p>

<p>Consider how we annotate and refer to release builds for a Scala project:
The <em>version</em> of Scala -- 2.10, 2.11, etc -- that was used to build the project is a <em>qualifier</em> for the release.
For example, if I am building a project using Scala 2.11, and package P is one of my project dependencies, then the maven build tooling (or sbt, etc) looks for a version of P that was <em>also</em> built using Scala 2.11;
the build will fail if no such incarnation of P can be located.
This build constraint propagates recursively throughout the entire dependency tree for a project.</p>

<p>Now consider how we treat the version for the package P dependency itself:
Our build tooling forces us to specify one exact release version x.y.z for P.
This is superficially similar to the constraint for building with Scala 2.11, but <em>unlike</em> the Scala constraint, the knowledge about using P x.y.z is not propagated down the tree.</p>

<p>If the dependency for P appears only once in the depenency tree, everything is fine.
However, as anybody who has ever worked with a large dependency tree for a project knows, package P might very well appear in multiple locations of the dep-tree, as a transitive dependency of different packages.
Worse, these deps may be specified as <em>different versions</em> of P, which may be mutually incompatible.</p>

<p>Transitive dep incompatibilities are a particularly thorny problem to solve, but there are other annoyances related to release versioning.
Often a user would like a "major" package dependency built against a particular version of that dep.
For example, packages that use Apache Spark may need to work with a particular build version of Spark (2.1, 2.2, etc).
If I am the package purveyor, I have no very convenient way to build my package against multiple versions of spark, and then annotate those builds in Maven Central.
At best I can bake the spark version into the name.
But what if I want to specify other package dep verions?
Do I create package names with increasingly-long lists of (package,version) pairs hacked into the name?</p>

<p>Finally, there is simply the annoyance of revving my own package purely for the purpose of building it against the latest versions of my dependencies.
None of my code has changed, but I am cutting a new release just to pick up current dependency releases.
And then hoping that my package users will want those particular releases, and that these won't break <em>their</em> builds with incompatible transitive deps!</p>

<p>I have been toying with a release and build methodology for avoiding these headaches. What follows is full of vigorous hand-waving,
but I believe something like it could be formalized in a useful way.</p>

<p>The key idea is that a release <em>build</em> is defined by a <em>build signature</em> which is the union of all <code>(dep, ver)</code> pairs.
This includes:</p>

<ol>
<li>The actual release version of the package code, e.g. <code>(mypackage, 1.2.3)</code></li>
<li>The <code>(dep, ver)</code> for all dependencies (taken over all transitive deps, recursively)</li>
<li>The <code>(tool, ver)</code> for all impactful build tooling, e.g. <code>(scala, 2.11)</code>, <code>(python, 3.5)</code>, etc</li>
</ol>


<p>For example, if I maintain a package <code>P</code>, whose latest code release is <code>1.2.3</code>,
built with dependencies <code>(A, 0.5)</code>, <code>(B, 2.5.1)</code> and <code>(C, 1.7.8)</code>, and dependency <code>B</code> built against <code>(Q, 6.7)</code> and <code>(R, 3.3)</code>,
and <code>C</code> built against <code>(Q, 6.7)</code>
and all compiled with <code>(scala, 2.11)</code>, then the build signature will be:</p>

<p><code>{ (P, 1.2.3), (A, 0.5), (B, 2.5.1), (C, 1.7.8), (Q, 6.7), (R, 3.3), (scala, 2.11) }</code></p>

<p>Identifying a release build in this way makes several interesting things possible.
First, it can identify a build with a transitive dependency problem.
For example, if <code>C</code> had been built against <code>(Q, 7.0)</code>,
then the resulting build signature would have <em>two</em> pairs for <code>Q</code>; <code>(Q, 6.7)</code> and <code>(Q, 7.0)</code>,
which is an immediate red flag for a potential problem.</p>

<p>More intriguingly, it could provide a foundation for <em>avoiding</em> builds with incompatible dependencies.
Suppose that I redefine my build logic so that I only specify dependency package names, and not specific versions.
Whenever I build a project, the build system automatically searches for the most-recent version of each dependency.
This already addresses some of the release headaches above.
As a project builder, I can get the latest versions of packages when I build.
As a package maintainer, I do not have to rev a release just to update my package deps;
projects using my package will get the latest by default.
Moreover, because the latest package release is always pulled, I never get multiple incompatible dependency releases
in a build.</p>

<p>Suppose that for some reason I <em>need</em> a particular release of some dependency.
From the example above, imagine that I must use <code>(Q, 6.7)</code>.
We can imagine augmenting the build specification to allow overriding the default behavior of pulling the most recent release.
We might either specify a specific version as we do currently, or possibly specify a range of releases, as systems like brew or ruby gemfiles allow.
In the case where some constraint is placed on releases, this constraint would be propagaged down the tree (or possibly up from the leaves),
in essentially the same way that the constraint of scala version is already.
In the event that the total set of constraints over the whole dependency tree is not satisfiable, then the build will fail.</p>

<p>With a build annotation system like the one I just described, one could imagine a new role for registries like Maven Central,
where different builds are automatically cached.
The registry could maybe even automatically run CI testing to identify the most-recent versions of package dependencies that satisfy
any given package build,
or perhaps valid dependency release ranges.</p>

<p>To conclude, I believe that re-thinking how we describe the dependencies used to build and annotate package releases,
by generalizing release version to include the release version of all transitive deps (including build tooling as deps),
may enable more flexible ways to both build software releases and specify them for pulling.</p>

<p>Happy Computing!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Converging Monoid Addition for T-Digest]]></title>
    <link href="http://erikerlandson.github.com/blog/2016/12/19/converging-monoid-addition-for-t-digest/"/>
    <updated>2016-12-19T13:29:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2016/12/19/converging-monoid-addition-for-t-digest</id>
    <content type="html"><![CDATA[<blockquote><p>In the days when Sussman was a novice,
Minsky once came to him as he sat hacking at the PDP-6.
"What are you doing?", asked Minsky.
"I am training a randomly wired neural net to play Tic-tac-toe", Sussman replied.
"Why is the net wired randomly?", asked Minsky.
"I do not want it to have any preconceptions of how to play", Sussman said.
Minsky then shut his eyes.
"Why do you close your eyes?" Sussman asked his teacher.
"So that the room will be empty."
At that moment, Sussman was enlightened.</p></blockquote>

<p>Recently I've been doing some work with the <a href="https://github.com/isarn/isarn-sketches">t-digest sketching</a> algorithm, from the
<a href="https://github.com/tdunning/t-digest/blob/master/docs/t-digest-paper/histo.pdf">paper by Ted Dunning and Omar Ertl</a>.
One of the appealing properties of t-digest sketches is that you can "add" them together in the monoid sense to produce a combined sketch from two separate sketches.
This property is crucial for sketching data across data partitions in scale-out parallel computing platforms such as Apache Spark or Map-Reduce.</p>

<p>In the original Dunning/Ertl paper, they describe an algorithm for monoidal combination of t-digests based on randomized cluster recombination.  The clusters of the two input sketches are collected together, then randomly shuffled, and inserted into a new t-digest in that randomized order.  In Scala code, this algorithm might look like the following:</p>

<p>```scala
def combine(ltd: TDigest, rtd: TDigest): TDigest = {
  // randomly shuffle input clusters and re-insert to a new t-digest
  shuffle(ltd.clusters.toVector ++ rtd.clusters.toVector)</p>

<pre><code>.foldLeft(TDigest.empty)((d, e) =&gt; d + e)
</code></pre>

<p>}
```</p>

<p>I implemented this algorithm and used it until I noticed that a sum over multiple sketches seemed to behave noticeably differently than either the individual inputs, or the nominal underlying distribution.</p>

<p>To get a closer look at what was going on, I generated some random samples from a Normal distribution ~N(0,1).
I then generated t-digest sketches of each sample, took a cumulative monoid sum, and kept track of how closely each successive sum adhered to the original ~N(0,1) distribution.
As a measure of the difference between a t-digest sketch and the original distribution, I computed the Kolmogorov-Smirnov <a href="https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test#Kolmogorov.E2.80.93Smirnov_statistic">D-statistic</a>, which yields a distance between two cumulative distribution functions.
(Code for my data collections can be viewed <a href="https://github.com/erikerlandson/isarn-sketches-algebird-api/blob/blog/t_digest_sum/src/main/scala/org/isarnproject/sketchesAlgebirdAPI/AlgebirdFactory.scala#L65">here</a>)
I ran multiple data collections and subsequent cumulative sums and used those multiple measurements to generate the following box-plot.
The result was surprising and a bit disturbing:</p>

<p><img src="/assets/images/tdsum/plot1.png" alt="plot1" /></p>

<p>As the plot shows, the t-digest sketch distributions are gradually <em>diverging</em> from the underlying "true" distribution ~N(0,1).
This is a potentially significant problem for the stability of monoidal t-digest sums, and by extension any parallel sketching based on combining the partial sketches on data partitions in map-reduce-like environments.</p>

<p>Seeing this divergence motivated me to think about ways to avoid it.
One property of t-digest insertion logic is that the results of inserting new data can differ depending on what clusters are already present.
I wondered if the results might be more stable if the largest clusters were inserted first.
The t-digest algorithm allows clusters closest to the distribution median to grow the largest.
Combining input clusters from largest to smallest would be like building the combined distribution from the middle outwards, toward the distribution tails.
In the case where one t-digest had larger weights, it would also somewhat approximate inserting the smaller sketch into the larger one.
In Scala code, this alternative monoid addition looks like so:</p>

<p>```scala
def combine(ltd: TDigest, rtd: TDigest): TDigest = {
  // insert clusters from largest to smallest
  (ltd.clusters.toVector ++ rtd.clusters.toVector).sortWith((a, b) => a.<em>2 > b.</em>2)</p>

<pre><code>.foldLeft(TDigest.empty(delta))((d, e) =&gt; d + e)
</code></pre>

<p>}
```</p>

<p>As a second experiment, for each data sampling I compared the original monoid addition with the alternative method using largest-to-smallest cluster insertion.
When I plotted the resulting progression of D-statistics side-by-side, the results were surprising:</p>

<p><img src="/assets/images/tdsum/plot2a.png" alt="plot2a" /></p>

<p>As the plot demonstrates, not only was large-to-small insertion more stable, its D-statistics appeared to be getting <em>smaller</em> instead of larger.
To see if this trend was sustained over longer cumulative sums, I plotted the D-stats for cumulative sums over 100 samples:</p>

<p><img src="/assets/images/tdsum/plot2.png" alt="plot2" /></p>

<p>The results were even more dramatic;
These longer sums show that the standard randomized-insertion method continues to diverge,
but in the case of large-to-small insertion the cumulative t-digest sums continue to converge
towards the underlying distribution!</p>

<p>To test whether this effect might be dependent on particular shapes of distribution, I ran similar experiments using a Uniform distribution (no "tails") and an Exponential distribution (one tail).
I included the corresponding plots in the appendix.
The convergence of this alternative monoid addition doesn't seem to be sensitive to shape of distribution.</p>

<p>I have upgraded my <a href="https://github.com/isarn/isarn-sketches#t-digest">implementation of t-digest sketching</a> to use this new definition of monoid addition for t-digests.
As you can see, it is easy to change one implementation for another.
One or two lines of code may be sufficient.
I hope this idea may be useful for any other implementations in the community.
Happy sketching!</p>

<h3>Appendix: Plots with Alternate Distributions</h3>

<p><img src="/assets/images/tdsum/plot3.png" alt="plot3" /></p>

<p><img src="/assets/images/tdsum/plot4.png" alt="plot4" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Encoding Map-Reduce As A Monoid With Left Folding]]></title>
    <link href="http://erikerlandson.github.com/blog/2016/09/05/expressing-map-reduce-as-a-left-folding-monoid/"/>
    <updated>2016-09-05T10:31:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2016/09/05/expressing-map-reduce-as-a-left-folding-monoid</id>
    <content type="html"><![CDATA[<p>In a <a href="http://erikerlandson.github.io/blog/2015/11/24/the-prepare-operation-considered-harmful-in-algebird/">previous post</a> I discussed some scenarios where traditional map-reduce (directly applying a map function, followed by some monoidal reduction) could be inefficient.
To review, the source of inefficiency is in situations where the <code>map</code> operation is creating some non-trivial monoid that represents a single element of the input type.
For example, if the monoidal type is <code>Set[Int]</code>, then the mapping function ('prepare' in algebird) maps every input integer <code>k</code> into <code>Set(k)</code>, which is somewhat expensive.</p>

<p>In that discussion, I was focusing on map-reduce as embodied by the algebird <code>Aggregator</code> type, where <code>map</code> appears as the <code>prepare</code> function.
However, it is easy to see that <em>any</em> map-reduce implementation may be vulnerable to the same inefficiency.</p>

<p>I wondered if there were a way to represent map-reduce using some alternative formulation that avoids this vulnerability.
There is such a formulation, which I will talk about in this post.</p>

<p>I'll begin by reviewing a standard map-reduce implementation.
The following scala code sketches out the definition of a monoid over a type <code>B</code> and a map-reduce interface.
As this code suggests, the <code>map</code> function maps input data of some type <code>A</code> into some <em>monoidal</em> type <code>B</code>, which can be reduced (aka "aggregated") in a way that is amenable to parallelization:</p>

<p>``` scala
trait Monoid[B] {
  // aka 'combine' aka '++'
  def plus: (B, B) => B</p>

<p>  // aka 'empty' aka 'identity'
  def e: B
}</p>

<p>trait MapReduce[A, B] {
  // monoid embodies the reducible type
  def monoid: Monoid[B]</p>

<p>  // mapping function from input type A to reducible type B
  def map: A => B</p>

<p>  // the basic map-reduce operation
  def apply(data: Seq[A]): B = data.map(map).fold(monoid.e)(monoid.plus)</p>

<p>  // map-reduce parallelized over data partitions
  def apply(data: ParSeq[Seq[A]]): B =</p>

<pre><code>data.map { part =&gt;
  part.map(map).fold(monoid.e)(monoid.plus)
}
.fold(monoid.e)(monoid.plus)
</code></pre>

<p>}
```</p>

<p>In the parallel version of map-reduce above, you can see that map and reduce are executed on each data partition (which may occur in parallel) to produce a monoidal <code>B</code> value, followed by a final reduction of those intermediate results.
This is the classic form of map-reduce popularized by tools such as Hadoop and Apache Spark, where inidividual data partitions may reside across highly parallel commodity clusters.</p>

<p>Next I will present an alternative definition of map-reduce.
In this implementation, the <code>map</code> function is replaced by a <code>foldL</code> function, which executes a single "left-fold" of an input object with type <code>A</code> into the monoid object with type <code>B</code>:</p>

<p>``` scala
// a map reduce operation based on a monoid with left folding
trait MapReduceLF[A, B] extends MapReduce[A, B] {
  def monoid: Monoid[B]</p>

<p>  // left-fold an object with type A into the monoid B
  // obeys type law: foldL(b, a) = b ++ foldL(e, a)
  def foldL: (B, A) => B</p>

<p>  // foldL(e, a) embodies the role of map(a) in standard map-reduce
  def map = (a: A) => foldL(monoid.e, a)</p>

<p>  // map-reduce operation is now a single fold-left operation
  override def apply(data: Seq[A]): B = data.foldLeft(monoid.e)(foldL)</p>

<p>  // map-reduce parallelized over data partitions
  override def apply(data: ParSeq[Seq[A]]): B =</p>

<pre><code>data.map { part =&gt;
  part.foldLeft(monoid.e)(foldL)
}
.fold(monoid.e)(monoid.plus)
</code></pre>

<p>}
```</p>

<p>As the comments above indicate, the left-folding function <code>foldL</code> is assumed to obey the law <code>foldL(b, a) = b ++ foldL(e, a)</code>.
This law captures the idea that folding <code>a</code> into <code>b</code> should be the analog of reducing <code>b</code> with a monoid corresponding to the single element <code>a</code>.
Referring to my earlier example, if type <code>A</code> is <code>Int</code> and <code>B</code> is <code>Set[Int]</code>, then <code>foldL(b, a) =&gt; b + a</code>.
Note that <code>b + a</code> is directly inserting single element <code>a</code> into <code>b</code>, which is significantly more efficient than <code>b ++ Set(a)</code>, which is how a typical map-reduce implementation would be required to operate.</p>

<p>This law also gives us the corresponding definition of <code>map(a)</code>, which is <code>foldL(e, a)</code>, or in my example: <code>Set.empty[Int] ++ a</code> or just: <code>Set(a)</code></p>

<p>In this formulation, the basic map-reduce operation is now a single <code>foldLeft</code> operation, instead of a mapping followed by a monoidal reduction.
The parallel version is analoglous.
Each partition uses the new <code>foldLeft</code> operation, and the final reduction of intermediate monoidal results remains the same as before.</p>

<p>The <code>foldLeft</code> function is potentially a much more general operation, and it raises the question of whether this new encoding is indeed parallelizable as before.
I will conclude with a proof that this encoding is also parallelizable;
Note that the law <code>foldL(b, a) = b ++ foldL(e, a)</code> is a significant component of this proof, as it represents the constraint that <code>foldL</code> behaves like an analog of reducing <code>b</code> with a monoidal representation of element <code>a</code>.</p>

<p>In the following proof I used a scala-like pseudo code, described in the introduction:</p>

<p>```
// given an object mr of type MapReduceFL[A, B]
// and using notation:
// f &lt;==> mr.foldL
// for b1,b2 of type B: b1 ++ b2 &lt;==> mr.plus(b1, b2)
// e &lt;==> mr.e
// [...] &lt;==> Seq(...)
// d1, d2 are of type Seq[A]</p>

<p>// Proof that map-reduce with left-folding is parallelizable
// i.e. mr(d1 ++ d2) == mr(d1) ++ mr(d2)
mr(d1 ++ d2)
== (d1 ++ d2).foldLeft(e)(f)  // definition of map-reduce operation
== d1.foldLeft(e)(f) ++ d2.foldLeft(e)(f)  // Lemma A
== mr(d1) ++ mr(d2)  // definition of map-reduce (QED)</p>

<p>// Proof of Lemma A
// i.e. (d1 ++ d2).foldLeft(e)(f) == d1.foldLeft(e)(f) ++ d2.foldLeft(e)(f)</p>

<p>// proof is by induction on the length of data sequence d2</p>

<p>// case d2 where length is zero, i.e. d2 == []
(d1 ++ []).foldLeft(e)(f)
== d1.foldLeft(e)(f)  // definition of empty sequence []
== d1.foldLeft(e)(f) ++ e  // definition of identity e
== d1.foldLeft(e)(f) ++ [].foldLeft(e)(f)  // definition of foldLeft</p>

<p>// case d2 where length is 1, i.e. d2 == [a] for some a of type A
(d1 ++ [a]).foldLeft(e)(f)
== f(d1.foldLeft(e)(f), a)  // definition of foldLeft and f
== d1.foldLeft(e)(f) ++ f(e, a)  // the type-law f(b, a) == b ++ f(e, a)
== d1.foldLeft(e)(f) ++ [a].foldLeft(e)(f)  // definition of foldLeft</p>

<p>// inductive step, assuming proof for d2' of length &lt;= n
// consider d2 of length n+1, i.e. d2 == d2' ++ [a], where d2' has length n
(d1 ++ d2).foldLeft(e)(f)
== (d1 ++ d2' ++ [a]).foldLeft(e)(f)  // definition of d2, d2', [a]
== f((d1 ++ d2').foldLeft(e)(f), a)  // definition of foldLeft and f
== (d1 ++ d2').foldLeft(e)(f) ++ f(e, a)  // type-law f(b, a) == b ++ f(e, a)
== d1.foldLeft(e)(f) ++ d2'.foldLeft(e)(f) ++ f(e, a)  // induction
== d1.foldLeft(e)(f) ++ d2'.foldLeft(e)(f) ++ [a].foldLeft(e)(f)  // def'n of foldLeft
== d1.foldLeft(e)(f) ++ (d2' ++ [a]).foldLeft(e)(f)  // induction
== d1.foldLeft(e)(f) ++ d2.foldLeft(e)(f)  // definition of d2 (QED)
```</p>
]]></content>
  </entry>
  
</feed>
