<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: dimensionality | tool monkey]]></title>
  <link href="http://erikerlandson.github.com/blog/categories/dimensionality/atom.xml" rel="self"/>
  <link href="http://erikerlandson.github.com/"/>
  <updated>2017-03-06T14:43:30-07:00</updated>
  <id>http://erikerlandson.github.com/</id>
  <author>
    <name><![CDATA[Erik Erlandson]]></name>
    <email><![CDATA[erikerlandson@yahoo.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Approximating a PDF of Distances With a Gamma Distribution]]></title>
    <link href="http://erikerlandson.github.com/blog/2016/07/09/approximating-a-pdf-of-distances-with-a-gamma-distribution/"/>
    <updated>2016-07-09T11:25:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2016/07/09/approximating-a-pdf-of-distances-with-a-gamma-distribution</id>
    <content type="html"><![CDATA[<p>In a <a href="http://erikerlandson.github.io/blog/2016/06/08/exploring-the-effects-of-dimensionality-on-a-pdf-of-distances/">previous post</a> I discussed some unintuitive aspects of the distribution of distances as spatial dimension changes.  To help explain this to myself I derived a formula for this distribution, assuming a unit multivariate Gaussian.  For distance (aka radius) r, and spatial dimension d, the PDF of distances is:</p>

<p><img src="/assets/images/dist_dist/gwwv5a5.png" alt="Figure 1" /></p>

<p>Recall that the form of this PDF is the <a href="https://en.wikipedia.org/wiki/Generalized_gamma_distribution">generalized gamma distribution</a>, with scale parameter <nobr>a=sqrt(2),</nobr> shape parameter p=2, and free shape parameter (d) representing the dimensionality.</p>

<p>I was interested in fitting parameters to such a distribution, using some distance data from a clustering algorithm.  <a href="https://www.scipy.org/">SciPy</a> comes with a predefined method for fitting generalized gamma parameters, however I wished to implement something similar using <a href="http://commons.apache.org/proper/commons-math/">Apache Commons Math</a>, which does not have native support for fitting a generalized gamma PDF.  I even went so far as to start working out <a href="http://erikerlandson.github.io/blog/2016/06/15/computing-derivatives-of-the-gamma-function/">some of the math</a> needed to augment the Commons Math <a href="http://commons.apache.org/proper/commons-math/apidocs/org/apache/commons/math3/analysis/differentiation/package-summary.html">Automatic Differentiation libraries</a> with Gamma function differentiation needed to numerically fit my parameters.</p>

<p>Meanwhile, I have been fitting a <em>non generalized</em> <a href="https://en.wikipedia.org/wiki/Gamma_distribution">gamma distribution</a> to the distance data, as a sort of rough cut, using a fast <a href="https://en.wikipedia.org/wiki/Gamma_distribution#Maximum_likelihood_estimation">non-iterative approximation</a> to the parameter optimization.  Consistent with my habit of asking the obvious question last, I tried plotting this gamma approximation against distance data, to see how well it compared against the PDF that I derived.</p>

<p>Surprisingly (at least to me), my approximation using the gamma distribution is a very effective fit for spatial dimensionalities <nobr> >= 2 </nobr>:</p>

<p><img src="/assets/images/gamma_approx/approx_plot.png" alt="Figure 2" /></p>

<p>As the plot shows, only for the 1-dimension case is the gamma approximation substiantially deviating.  In fact, the fit appears to get better as dimensionality increases.  To address the 1D case, I can easily test the fit of a half-gaussian as a possible model.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Exploring the Effects of Dimensionality on a PDF of Distances]]></title>
    <link href="http://erikerlandson.github.com/blog/2016/06/08/exploring-the-effects-of-dimensionality-on-a-pdf-of-distances/"/>
    <updated>2016-06-08T20:56:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2016/06/08/exploring-the-effects-of-dimensionality-on-a-pdf-of-distances</id>
    <content type="html"><![CDATA[<p>Every so often I'm reminded that the effects of changing dimensionality on objects and processes can be surprisingly counterintuitive.  Recently I ran across a great example of this, while I working on a model for the distribution of distances in spaces of varying dimension.</p>

<p>Suppose that I draw some values from a classic one-dimensional Gaussian, with zero mean and unit variance, but that I am actually interested in their corresponding distances from center.  Knowing that my Gaussian is centered on the origin, I can rephrase that as: the distribution of magnitudes of values drawn from that Gaussian.  I can simulate this process by actually samping Gaussian values and taking their absolute value.  When I do, I get the following result:</p>

<p><img src="/assets/images/dist_dist/figure1.png" alt="Figure 1" /></p>

<p>It's easy to see -- and intuitive -- that the resulting distribution is a <a href="https://en.wikipedia.org/wiki/Half-normal_distribution">half-Gaussian</a>, as I confirmed by overlaying the histogrammed samples above with a half-Gaussian PDF (displayed in green).</p>

<p>I wanted to generalize this basic idea into some arbitrary dimensionality, (d), where I draw d-vectors from an <a href="https://en.wikipedia.org/wiki/Multivariate_normal_distribution">d-dimensional Gaussian</a> (again, centered on the origin with unit variances). When I take the magnitudes of these sampled d-vectors, what will the probability distribution of <em>their</em> magnitudes look like?</p>

<p>My intuitive assumption was that these magnitudes would <em>also</em> follow a half-Gaussian distribution.  After all, every multivariate Gaussian is densest at its mean, just like the univariate case I examined above.  In fact I was so confident in this assumption that I built my initial modeling around it.  Great confusion ensued, when I saw how poorly my models were working on my higher-dimensional data!</p>

<p>Eventually it occurred to me to do the obvious thing and generate some visualizations from higher dimensional data.  For example, here is the correponding plot generated from a bivariate Gaussian (d=2):</p>

<p><a name="figure2"></a>
<img src="/assets/images/dist_dist/figure2.png" alt="Figure 2" /></p>

<p>Surprise -- the distribution at d=2 is <em>not even close to half-Gaussian!</em>.  My intuitions couldn't have been more misleading!</p>

<p>Where did I go wrong?</p>

<p>I'll start by observing what happens when I take a multi-dimensional PDF of vectors in (d) dimensions and project it down to a one-dimensional PDF of the corresponding vector magnitudes. To keep things simple, I will be assuming a multi-dimensional PDF <nobr>f<sub>r</sub>(<strong>x</strong><sub>d</sub>)</nobr> that is (1) centered on the origin, and (2) is radially symmetric; the pdf value is the same for all points at a given distance from the origin.  For example, any multivariate Gaussian with <strong>0</strong><sub>d</sub> mean and <strong>I</strong><sub>d</sub> for a covariance matrix satisfies these two assumptions.  With this in mind, you can see that the process of projecting from vectors in <strong>R</strong><sub>d</sub> to their distance from <strong>0</strong><sub>d</sub> (their magnitude) is equivalent to summing all densities <nobr>f<sub>r</sub>(<strong>x</strong><sub>d</sub>)</nobr> along the surface of "d-sphere" radius (r) to obtain a pdf f(r) in distance space.  With assumption (2) we can simplify that integration to just <nobr>f(r)=A<sub>d</sub>(r)f'(r)</nobr>, where f'(r) defines the value of <nobr>f<sub>r</sub>(<strong>x</strong>)</nobr> for all <strong>x</strong> with magnitude of (r), and A<sub>d</sub>(r) is the surface area of a d-sphere with radius (r):</p>

<p><img src="/assets/images/dist_dist/ztrlusa.png" alt="Figure 3" /></p>

<p>The key observation is that this term is a <em>polynomial</em> function of radius (r), with degree (d-1).  When d=1, it is simply a constant multiplier and so we get the half-Gaussian distribution we expect, but when <nobr>d >= 2</nobr>, the term is zero at r=0, and grows with radius.  Hence we see the in the <a href="#figure2">d=2 plot above</a> that the density begins at zero, then grows with radius until the decreasing gaussian density gradually drives it back toward zero again.</p>

<p>The above ideas can be expressed compactly as follows:</p>

<p><img src="/assets/images/dist_dist/jukgy85.png" alt="Figure 4" /></p>

<p>In my experiments, I am using multivariate Gaussians of mean <strong>0</strong><sub>d</sub> and unit covariance matrix <strong>I</strong><sub>d</sub>, and so the form for f(r;d) becomes:</p>

<p><img src="/assets/images/dist_dist/gwwv5a5.png" alt="Figure 4" /></p>

<p>This form is in fact the <a href="https://en.wikipedia.org/wiki/Generalized_gamma_distribution">generalized gamma distribution</a>, with scale parameter <nobr>a=2<sup>1/2</sup>,</nobr> shape parameter p=2, and free shape parameter (d) representing the dimensionality in this context.</p>

<p>I can verify that this PDF is correct by plotting it against randomly sampled data at differing dimensions:</p>

<p><img src="/assets/images/dist_dist/figure3.png" alt="Figure 5" /></p>

<p>This plot demonstrates both that the PDF expression is correct for varying dimensionalities and also illustrates how the shape of the PDF evolves as dimensionality changes.  For me, it was a great example of challenging my intuitions and learning something completely unexpected about the interplay of distances and dimension.</p>
]]></content>
  </entry>
  
</feed>
