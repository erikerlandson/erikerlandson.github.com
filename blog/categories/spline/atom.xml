<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: spline | tool monkey]]></title>
  <link href="http://erikerlandson.github.com/blog/categories/spline/atom.xml" rel="self"/>
  <link href="http://erikerlandson.github.com/"/>
  <updated>2019-01-02T14:27:32-07:00</updated>
  <id>http://erikerlandson.github.com/</id>
  <author>
    <name><![CDATA[Erik Erlandson]]></name>
    <email><![CDATA[erikerlandson@yahoo.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[The Smooth-Max Minimum Incident of December 2018]]></title>
    <link href="http://erikerlandson.github.com/blog/2019/01/02/the-smooth-max-minimum-incident-of-december-2018/"/>
    <updated>2019-01-02T13:25:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2019/01/02/the-smooth-max-minimum-incident-of-december-2018</id>
    <content type="html"><![CDATA[<p>In what is becoming an ongoing series where I climb the convex optimization learning curve by making dumb mistakes,
I tripped over yet another <a href="https://github.com/erikerlandson/gibbous/issues/1">unexpected falure</a>
in my feasible point solver while testing a couple new inequality constraints for my
<a href="https://github.com/erikerlandson/snowball">monotonic splining project</a>.</p>

<p>The symptom was that when I added <a href="https://github.com/erikerlandson/snowball/pull/1">minimum and maximum constraints</a>,
the feasible point solver began reporting failure.
These failures made no sense to me, because they were in fact contraining my problem very little, if at all.
For example, I if I added constraints for <code>s(x) &gt; 0</code> and <code>s(x) &lt; 1</code>, the solver began failing,
even though my function (designed to behave as a CDF) was already meeting these constraints to within machine epsilon tolerance.</p>

<p>When I inspected its behavior, I discovered that my solver found a point <code>x</code> where the
<a href="http://erikerlandson.github.io/blog/2018/06/03/solving-feasible-points-with-smooth-max/">smooth-max was minimized</a>,
and reported this answer as also being the minimum possible value for the true maximum.
As it happened, this value for <code>x</code> was positive (non-satisfying) for the true max, even though better locations <em>did</em> exist!</p>

<p>This time, my error turned out to be that I had assumed the smooth-max function is "minimum preserving."
That is, I had assumed that the minimum of smooth-max is the same as the corresponding minimum for the true maximum.
I cooked up a quick jupyter notebook to see if I could prove I was wrong about this, and sure enough came up with a simple
visual counter-example:</p>

<p><img src="/assets/images/smooth-max-plot.png" alt="Figure-1" /></p>

<p>In this plot, the black dotted line identifies the minimum of the true maximum:
the left intersection of the blue parabola and red line.
The green dotted line shows the mimimum of soft-max, and it's easy to see that they are completely different!</p>

<p>I haven't yet coded up a fix for this, but my basic plan is to allow the smooth-max alpha to increase whenever it
fails to find a feasible point.
Why? Increasing alpha causes the
<a href="http://erikerlandson.github.io/blog/2018/05/28/computing-smooth-max-and-its-gradients-without-over-and-underflow/">smooth-max</a>
to more closely approximate true max.
If the soft-max approximation becomes sufficiently close to the true maximum, and no solution is found,
then I can report an empty feasible region with more confidence.</p>

<p>Why did I make this blunder?
I suspect it is because I originally only visualized symmetric examples in my mind,
where the mimimum of smooth-max and true maximum is the same.
Visual intuitions are only as good as your imagination!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Equality Constraints for Cubic B-Splines]]></title>
    <link href="http://erikerlandson.github.com/blog/2018/09/08/equality-constraints-for-cubic-b-splines/"/>
    <updated>2018-09-08T14:32:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2018/09/08/equality-constraints-for-cubic-b-splines</id>
    <content type="html"><![CDATA[<p>In my <a href="http://erikerlandson.github.io/blog/2018/09/02/putting-cubic-b-splines-into-standard-polynomial-form/">previous post</a>
I derived the standard-form polynomial coefficients for cubic B-splines.
As part of the <a href="https://github.com/erikerlandson/snowball">same project</a>,
I also need to add a feature that allows the library user to declare equality constraints of the form <nobr>(x,y)</nobr>,
where <nobr>S(x) = y</nobr>. Under the hood, I am invoking a <a href="https://github.com/erikerlandson/gibbous">convex optimization</a> library, and so I need to convert these
user inputs to a linear equation form that is consumable by the optimizer.</p>

<p>I expected this to be tricky, but it turns out I did most of the work <a href="http://erikerlandson.github.io/blog/2018/09/02/putting-cubic-b-splines-into-standard-polynomial-form/">already</a>.
I can take one of my previously-derived expressions for S(x) and put it into a form that gives me coefficients for the four contributing knot points <nobr>K<sub>j-3</sub> ... K<sub>j</sub></nobr>:</p>

<p><img src="/assets/images/bspline/ybblhxfw.png" alt="eq" /></p>

<p>Recall that by the convention from my previous post, <nobr>K<sub>j</sub></nobr> is the largest knot point that is <nobr>&lt;= x</nobr>.</p>

<p>My linear constraint equation is with respect to the vector I am solving for, in particular vector (τ), and so the
equation above yields the following:</p>

<p><img src="/assets/images/bspline/y7jhvnmk.png" alt="eq" /></p>

<p>In this form, it is easy to add into a <a href="https://github.com/erikerlandson/gibbous">convex optimization</a> problem as a linear equality constraint.</p>

<p>Gradient constraints are another common equality constraint in convex optimization, and so I can apply very similar logic to get coefficient values corresponding to the gradient of S:</p>

<p><img src="/assets/images/bspline/yd5fxmwk.png" alt="eq" /></p>

<p>And so my linear equality constraint with respect to (τ) in this case is:</p>

<p><img src="/assets/images/bspline/yalk3puu.png" alt="eq" /></p>

<p>And that gives me the tools I need to let my users supply additional equality constraints as simple <nobr>(x,y)</nobr> pairs, and translate them into a form that can be consumed by convex optimization routines. Happy Computing!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Putting Cubic B-Splines into Standard Polynomial Form]]></title>
    <link href="http://erikerlandson.github.com/blog/2018/09/02/putting-cubic-b-splines-into-standard-polynomial-form/"/>
    <updated>2018-09-02T11:07:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2018/09/02/putting-cubic-b-splines-into-standard-polynomial-form</id>
    <content type="html"><![CDATA[<p>Lately I have been working on an <a href="https://github.com/erikerlandson/snowball">implementation</a> of monotone smoothing splines, based on <a href="#ref1">[1]</a>. As the title suggests, this technique is based on a univariate cubic <a href="https://en.wikipedia.org/wiki/B-splines">B-spline</a>. The form of the spline function used in the paper is as follows:</p>

<p><img src="/assets/images/bspline/yd2guhxt.png" alt="eq1" /></p>

<p>The knot points <nobr>K<sub>j</sub></nobr> are all equally spaced by 1/α, and so α normalizes knot intervals to 1. The function <nobr>B<sub>3</sub>(t)</nobr> and the four <nobr>N<sub>i</sub>(t)</nobr> are defined in this transformed space, t, of unit-separated knots.</p>

<p>I'm interested in providing an interpolated splines using the Apache Commons Math API, in particular the <a href="https://commons.apache.org/proper/commons-math/javadocs/api-3.6/org/apache/commons/math3/analysis/polynomials/PolynomialSplineFunction.html">PolynomialSplineFunction</a> class. In principle the above is clearly such a polynomial, but there are a few hitches.</p>

<ol>
<li><code>PolynomialSplineFunction</code> wants its knot intervals in closed standard polynomial form <nobr>ax<sup>3</sup> + bx<sup>2</sup> + cx + d</nobr></li>
<li>It wants each such polynomial expressed in the translated space <nobr>(x-K<sub>j</sub>)</nobr>, where <nobr>K<sub>j</sub></nobr> is the greatest knot point that is &lt;= x.</li>
<li>The actual domain of S(x) is <nobr>K<sub>0</sub> ... K<sub>m-1</sub></nobr>. The first 3 "negative" knots are there to make the summation for S(x) cleaner. <code>PolynomialSplineFunction</code> needs its functions to be defined purely on the actual domain.</li>
</ol>


<p>Consider the arguments to <nobr>B<sub>3</sub></nobr>, for two adjacent knots <nobr>K<sub>j-1</sub></nobr> and <nobr>K<sub>j</sub></nobr>, where <nobr>K<sub>j</sub></nobr> is greatest knot point that is &lt;= x. Recalling that knot points are all equally spaced by 1/α, we have the following relationship in the transformed space t:</p>

<p><img src="/assets/images/bspline/ydcb2ao3.png" alt="eq" /></p>

<p>We can apply this same manipulation to show that the arguments to <nobr>B<sub>3</sub></nobr>, as centered around knot <nobr>K<sub>j</sub></nobr>, are simply <nobr>{... t+2, t+1, t, t-1, t-2 ...}</nobr>.</p>

<p>By the definition of <nobr>B<sub>3</sub></nobr> above, you can see that <nobr>B<sub>3</sub>(t)</nobr> is non-zero only for t in <nobr>[0,4)</nobr>, and so the four corresponding knot points <nobr>K<sub>j-3</sub> ... K<sub>j</sub></nobr> contribute to its value:</p>

<p><img src="/assets/images/bspline/y9tpgfqj.png" alt="eq2" /></p>

<p>This suggests a way to manipulate the equations into a standard form. In the transformed space t, the four nonzero terms are:</p>

<p><img src="/assets/images/bspline/ya6gsrjy.png" alt="eq4" /></p>

<p>and by plugging in the appropriate <nobr>N<sub>i</sub></nobr> for each term, we arrive at:</p>

<p><img src="/assets/images/bspline/yc6grwxe.png" alt="eq5" /></p>

<p>Now, <code>PolynomialSplineFunction</code> is going to automatically identify the appropriate <nobr>K<sub>j</sub></nobr> and subtract it, and so I can define <em>that</em> transform as <nobr>u = x -  K<sub>j</sub></nobr>, which gives:</p>

<p><img src="/assets/images/bspline/y9p3vgqt.png" alt="eq6" /></p>

<p>I substitute the argument (αu) into the definitions of the four <nobr>N<sub>i</sub></nobr> to obtain:</p>

<p><img src="/assets/images/bspline/y8apdoqy.png" alt="eq7" /></p>

<p>Lastly, collecting like terms gives me the standard-form coefficients that I need for <code>PolynomialSplineFunction</code>:</p>

<p><img src="/assets/images/bspline/ya74mlsf.png" alt="eq8" /></p>

<p>Now I am equipped to return a <code>PolynomialSplineFunction</code> to my users, which implements the cubic B-spline that I fit to their data. Happy computing!</p>

<h4>References</h4>

<p><a name="anchor1" id="ref1">[1] </a>H. Fujioka and H. Kano: <a href="https://github.com/erikerlandson/snowball/blob/master/monotone-cubic-B-splines-2013.pdf">Monotone smoothing spline curves using normalized uniform cubic B-splines</a>, Trans. Institute of Systems, Control and Information Engineers, Vol. 26, No. 11, pp. 389–397, 2013</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Smooth Gradients for Cubic Hermite Splines]]></title>
    <link href="http://erikerlandson.github.com/blog/2013/03/16/smooth-gradients-for-cubic-hermite-splines/"/>
    <updated>2013-03-16T07:39:00-07:00</updated>
    <id>http://erikerlandson.github.com/blog/2013/03/16/smooth-gradients-for-cubic-hermite-splines</id>
    <content type="html"><![CDATA[<p>One of the advantages of cubic Hermite splines is that their interval interpolation formula is an explicit function of gradients \( m_0, m_1, ... m_{n-1} \) at knot-points:</p>

<div markdown="0">
\\[
y(t) = h_{00}(t) y_j + h_{10}(t) m_j + h_{01}(t) y_{j+1} + h_{11}(t) m_{j+1} \\\\
\\]
</div>


<p>where the Hermite bases are:</p>

<div markdown="0">
\\[
h_{00} = 2t^3 - 3t^2 + 1 \\\\
h_{10} = t^3 - 2t^2 + t \\\\
h_{01} = -2t^3 + 3t^2 \\\\
h_{11} = t^3 - t^2 \\\\
\\]
</div>


<p>(For now, I will be using the unit-interval form of the interpolation, where t runs from 0 to 1 on each interval.  I will also discuss the non-uniform interval equations below)</p>

<p>This formulation allows one to explicitly specify the interpolation gradient at each knot point, and to choose from various gradient assignment policies, for example <a href="http://en.wikipedia.org/wiki/Cubic_Hermite_spline#Interpolating_a_data_set">those listed here</a>, even supporting policies for <a href="http://en.wikipedia.org/wiki/Monotone_cubic_interpolation">enforcing monotonic interpolations</a>.</p>

<p>One important caveat with cubic Hermite splines is that although the gradient \( y'(t) \) is guaranteed to be continuous, it is <em>not</em> guaranteed to be smooth (that is, differentiable) <em>across</em> the knots (it is of course smooth <em>inside</em> each interval). Therefore, another useful category of gradient policy is to obtain gradients \( m_0, m_1, ... m_{n-1} \) such that \( y'(t) \) is also smooth across knots.</p>

<p>(I feel sure that what follows was long since derived elsewhere, but my attempts to dig the formulation up on the internet failed, and so I decided the derivation might make a useful blog post)</p>

<p>To ensure smooth gradient across knot points, we want the 2nd derivative \( y"(t) \) to be equal at the boundaries of adjacent intervals:</p>

<div markdown="0">
\\[
h_{00}^"(t) y_{j-1} + h_{10}^"(t) m_{j-1} + h_{01}^"(t) y_j + h_{11}^"(t) m_j \\\\
= \\\\
h_{00}^"(t) y_j + h_{10}^"(t) m_j + h_{01}^"(t) y_{j+1} + h_{11}^"(t) m_{j+1}
\\]
</div>


<p>or substituting the 2nd derivative of the basis definitions above:</p>

<div markdown="0">
\\[
\\left( 12 t - 6 \\right) y_{j-1} + \\left( 6 t - 4 \\right) m_{j-1}  + \\left( 6 - 12 t \\right) y_j + \\left( 6 t - 2 \\right) m_j \\\\
= \\\\
\\left( 12 t - 6 \\right) y_{j} + \\left( 6 t - 4 \\right) m_{j}  + \\left( 6 - 12 t \\right) y_{j+1} + \\left( 6 t - 2 \\right) m_{j+1}
\\]
</div>


<p>Observe that t = 1 on the left hand side of this equation, and t = 0 on the right side, and so we have:</p>

<div markdown="0">
\\[
6 y_{j-1} + 2 m_{j-1} - 6 y_j + 4 m_j
=
-6 y_j - 4 m_j + 6 y_{j+1} - 2 m_{j+1}
\\]
</div>


<p>which we can rearrange as:</p>

<div markdown="0">
\\[
2 m_{j-1} + 8 m_j + 2 m_{j+1}
=
6 \\left( y_{j+1} - y_{j-1} \\right)
\\]
</div>


<p>Given n knot points, the above equation holds for j = 1 to n-2 (using zero-based indexing, as nature intended).  Once we define equations for j = 0 and j = n-1, we will have a system of equations to solve.  There are two likely choices.  The first is to simply specify the endpoint gradients \( m_0 = G \) and \( m_{n-1} = H \) directly, which yields the following <a href="http://en.wikipedia.org/wiki/Tridiagonal_matrix_algorithm">tri-diagonal matrix equation:</a></p>

<div markdown="0">
\\[
\\left( \\begin{array} {ccccc}
1 &   &   &   &   \\\\
2 & 8 & 2 &   &   \\\\
  & 2 & 8 & 2 &   \\\\
  &   & \\vdots &   &   \\\\
  &   & 2 & 8 & 2 \\\\ 
  &   &   &   & 1 \\\\
\\end{array} \\right)

\\left( \\begin{array} {c}
m_0 \\\\
m_1 \\\\
 \\\\
\\vdots \\\\
 \\\\
m_{n-1}
\\end{array} \\right)
=
\\left( \\begin{array} {c}
G \\\\
6 \\left( y_2 - y_0 \\right) \\\\
6 \\left( y_3 - y_1 \\right) \\\\
\\vdots \\\\
6 \\left( y_{n-1} - y_{n-3} \\right) \\\\
H \\\\
\\end{array} \\right)
\\]
</div>


<p>The second common endpoint policy is to set the 2nd derivative equal to zero -- the "natural spline."   Setting the 2nd derivative to zero at the left-end knot (and t = 0) gives us:</p>

<div markdown="0">
\\[
4 m_0 + 2 m_1   =   6 \\left( y_1 - y_0 \\right)
\\]
</div>


<p>Similarly, at the right-end knot (t = 1), we have:</p>

<div markdown="0">
\\[
2 m_0 + 4 m_1   =   6 \\left( y_{n-1} - y_{n-2} \\right)
\\]
</div>


<p>And so for a natural spline endpoint policy the matrix equation looks like this:</p>

<div markdown="0">
\\[
\\left( \\begin{array} {ccccc}
4 & 2 &   &   &   \\\\
2 & 8 & 2 &   &   \\\\
  & 2 & 8 & 2 &   \\\\
  &   & \\vdots &   &   \\\\
  &   & 2 & 8 & 2 \\\\ 
  &   &   & 2 & 4 \\\\
\\end{array} \\right)

\\left( \\begin{array} {c}
m_0 \\\\
m_1 \\\\
 \\\\
\\vdots \\\\
 \\\\
m_{n-1}
\\end{array} \\right)
=
\\left( \\begin{array} {c}
6 \\left( y_1 - y_0 \\right) \\\\
6 \\left( y_2 - y_0 \\right) \\\\
6 \\left( y_3 - y_1 \\right) \\\\
\\vdots \\\\
6 \\left( y_{n-1} - y_{n-3} \\right) \\\\
6 \\left( y_{n-1} - y_{n-2} \\right) \\\\
\\end{array} \\right)
\\]
</div>


<p>The derivation above is for uniform (and unit) intervals, where t runs from 0 to 1 on each knot interval.  I'll now discuss the variation where knot intervals are non-uniform.   The non-uniform form of the interpolation equation is:</p>

<div markdown="0">
\\[
y(x) = h_{00}(t) y_j + h_{10}(t) d_j m_j + h_{01}(t) y_{j+1} + h_{11}(t) d_j m_{j+1} \\\\
\\text{ } \\\\
\\text{where:} \\\\
\\text{ }  \\\\
d_j = x_{j+1} - x_j \\text{  for  } j = 0, 1, ... n-2 \\\\
t = (x - x_j) / d_j
\\]
</div>


<p>Taking \( t = t(x) \) and applying the chain rule, we see that 2nd derivative equation now looks like:</p>

<div markdown="0">
\\[
y"(x) = \\frac { \\left( 12 t - 6 \\right) y_{j} + \\left( 6 t - 4 \\right) d_j m_{j}  + \\left( 6 - 12 t \\right) y_{j+1} + \\left( 6 t - 2 \\right) d_j m_{j+1} } { d_j^2 }
\\]
</div>


<p>Applying a derivation similar to the above, we find that our (interior) equations look like this:</p>

<div markdown="0">
\\[
\\frac {2} { d_{j-1} }  m_{j-1} + \\left( \\frac {4} { d_{j-1} } + \\frac {4} { d_j } \\right) m_j + \\frac {2} {d_j} m_{j+1}
=
\\frac { 6 \\left( y_{j+1} - y_{j} \\right) } { d_j^2 } + \\frac { 6 \\left( y_{j} - y_{j-1} \\right) } { d_{j-1}^2 }
\\]
</div>


<p>and natural spline endpoint equations are:</p>

<div markdown="0">
\\[
\\text{left:  } \\frac {4} {d_0} m_0 + \\frac {2} {d_0} m_1   =   \\frac {6 \\left( y_1 - y_0 \\right)} {d_0^2} \\\\
\\text{right: } \\frac {2} {d_{n-2}} m_0 + \\frac {4} {d_{n-2}} m_1   =   \\frac {6 \\left( y_{n-1} - y_{n-2} \\right)} {d_{n-2}^2}
\\]
</div>


<p>And so the matrix equation for specified endpoint gradients is:</p>

<div markdown="0">
\\[
\\scriptsize
\\left( \\begin{array} {ccccc}
\\normalsize 1 \\scriptsize &   &   &   &   \\\\
\\frac{2}{d_0} & \\frac{4}{d_0} {+} \\frac{4}{d_1} & \\frac{2}{d_1} &   &   \\\\
  & \\frac{2}{d_1} & \\frac{4}{d_1} {+} \\frac{4}{d_2} & \\frac{2}{d_2} &   \\\\
  &   & \\vdots &   &   \\\\
  &   & \\frac{2}{d_{n-3}} & \\frac{4}{d_{n-3}} {+} \\frac{4}{d_{n-2}} & \\frac{2}{d_{n-2}} \\\\ 
  &   &   &   & \\normalsize 1 \\scriptsize \\\\
\\end{array} \\right)

\\left( \\begin{array} {c}
m_0 \\\\
m_1 \\\\
 \\\\
\\vdots \\\\
 \\\\
m_{n-1}
\\end{array} \\right)
=
\\left( \\begin{array} {c}
G \\\\
6 \\left( \\frac{y_2 {-} y_1}{d_1^2} {+} \\frac{y_1 {-} y_0}{d_0^2} \\right) \\\\
6 \\left( \\frac{y_3 {-} y_2}{d_2^2} {+} \\frac{y_2 {-} y_1}{d_1^2} \\right)  \\\\
\\vdots \\\\
6 \\left( \\frac{y_{n-1} {-} y_{n-2}}{d_{n-2}^2} {+} \\frac{y_{n-2} {-} y_{n-3}}{d_{n-3}^2} \\right) \\\\
H \\\\
\\end{array} \\right)
\\normalsize
\\]
</div>


<p>And the equation for natural spline endpoints is:</p>

<div markdown="0">
\\[
\\scriptsize
\\left( \\begin{array} {ccccc}
\\frac{4}{d_0} & \\frac{2}{d_0}  &   &   &   \\\\
\\frac {2} {d_0} & \\frac {4} {d_0} {+} \\frac {4} {d_1} & \\frac{2}{d_1} &   &   \\\\
  & \\frac{2}{d_1} & \\frac{4}{d_1} {+} \\frac{4}{d_2} & \\frac{2}{d_2} &   \\\\
  &   & \\vdots &   &   \\\\
  &   & \\frac{2}{d_{n-3}} & \\frac{4}{d_{n-3}} {+} \\frac{4}{d_{n-2}} & \\frac{2}{d_{n-2}} \\\\ 
  &   &   & \\frac{2}{d_{n-2}} & \\frac{4}{d_{n-2}} \\\\
\\end{array} \\right)

\\left( \\begin{array} {c}
m_0 \\\\
m_1 \\\\
 \\\\
\\vdots \\\\
 \\\\
m_{n-1}
\\end{array} \\right)
=
\\left( \\begin{array} {c}
\\frac{6 \\left( y_1 {-} y_0 \\right)}{d_0^2} \\\\
6 \\left( \\frac{y_2 {-} y_1}{d_1^2}  {+}  \\frac{y_1 {-} y_0}{d_0^2} \\right) \\\\
6 \\left( \\frac{y_3 {-} y_2}{d_2^2}  {+}  \\frac{y_2 {-} y_1}{d_1^2} \\right)  \\\\
\\vdots \\\\
6 \\left( \\frac{y_{n-1} {-} y_{n-2}}{d_{n-2}^2}  {+}  \\frac{y_{n-2} {-} y_{n-3}}{d_{n-3}^2} \\right) \\\\
\\frac{6 \\left( y_{n-1} {-} y_{n-2} \\right)}{d_{n-2}^2} \\\\
\\end{array} \\right)
\\normalsize
\\]
</div>

]]></content>
  </entry>
  
</feed>
