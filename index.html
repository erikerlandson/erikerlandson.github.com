
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>tool monkey</title>
  <meta name="author" content="Erik Erlandson">

  
  <meta name="description" content="In this post I am going to describe some work I&#8217;ve done recently on a system of Scala traits that support tree-based collection algorithms &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://erikerlandson.github.com/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="tool monkey" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

  <!-- enables inclusion of MathJax LaTeX: http://greglus.com/blog/2011/11/29/integrate-MathJax-LaTeX-and-MathML-Markup-in-Octopress/ -->
  <script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">tool monkey</a></h1>
  
    <h2>a many-angled blog</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:erikerlandson.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/09/26/a-library-of-binary-tree-algorithms-as-mixable-scala-traits/">A Library of Binary Tree Algorithms as Mixable Scala Traits</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-09-26T12:43:00-07:00" pubdate data-updated="true">Sep 26<span>th</span>, 2015</time>
        
        
         | <a href="/blog/2015/09/26/a-library-of-binary-tree-algorithms-as-mixable-scala-traits/#feedback">Feedback</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>In this post I am going to describe some work I&#8217;ve done recently on a system of Scala traits that support tree-based collection algorithms prefix-sum, nearest key query and value increment in a mixable format, all backed by Red-Black balanced tree logic, which is also a fully inheritable trait.</p>

<p>This post eventually became a bit more sprawling and &#8220;tl/dr&#8221; than I was expecting, so by way of apology, here is a table of contents with links:</p>

<ol>
<li><a href="#motivation">Motivating Use Case</a></li>
<li><a href="#overview">Library Overview</a></li>
<li><a href="#redblack">A Red-Black Tree Base Class</a></li>
<li><a href="#nodemap">Node Inheritance Example: NodeMap[K,V]</a></li>
<li><a href="#orderedmaplike">Collection Trait Example: OrderedMapLike[K,V,IN,M]</a></li>
<li><a href="#orderedmap">Collection Example: OrderedMap[K,V]</a></li>
<li><a href="#mixing">Finale: Trait Mixing</a></li>
</ol>


<p><a name="motivation"></a></p>

<h5>A Motivating Use Case</h5>

<p>The skeptical programmer may be wondering what the point of Yet Another Map Collection really is, much less an entire class hierarchy.  The use case that inspired this work was my project of implementing the <a href="https://github.com/tdunning/t-digest/blob/master/docs/t-digest-paper/histo.pdf">t-digest algorithm</a>.  Discussion of t-digest is beyond the scope of this post, but suffice it to say that constructing a t-digest requires the maintenance of a collection of &#8220;cluster&#8221; objects, that needs to satisfy the following several properties:</p>

<ol>
<li>an entry contains one <strong>or more</strong> cluster objects at a given numeric location</li>
<li>entries are maintained in a numeric key order</li>
<li>entries will be frequently inserted and deleted, in arbitrary order</li>
<li>given a numeric key value, be able to find the entry nearest to that value</li>
<li>given a key, compute a <a href="https://en.wikipedia.org/wiki/Prefix_sum">prefix-sum</a> for that value</li>
<li>all of the above should be bounded by logarithmic time complexity</li>
</ol>


<p>Propreties 2,3 and 6 are commonly satisfied by a map structure backed by some variety of balanced tree representation, of which the best-known is the <a href="https://en.wikipedia.org/wiki/Red%E2%80%93black_tree">Red-Black tree</a>.</p>

<p>Properties 1, 4 and 5 are more interesting.  Property 1 &#8211; representing a collection of multiple objects at each entry &#8211; can be accomplished in a generalizable way by noting that a collection is representable as a monoid, and so supporting values that can be incremented with respect to a <a href="http://twitter.github.io/algebird/index.html#com.twitter.algebird.Monoid">user-supplied monoid relation</a> can satisfy property-1, but also can support many other kinds of update, including but not limited to classical numeric incrementing operations.</p>

<p>Properties 4 and 5 &#8211; nearest-entry queries and prefix-sum queries &#8211; are also both supportable in logarithmic time using a tree data structure, provided that tree is balanced.  Again, the details of the algorithms are out of the current scope, however they are not extremely complex, and their implementations are available in the code.</p>

<p>A reader with their software engineering hat on will notice that these properties are <em>orthogonal</em>.  A programmer might be interested in a data structure supporting any one of them, or in some mixed combination.   This kind of situation fairly shouts &#8220;Scala traits&#8221; (or, alternatively, interfaces in Java, etc).  With that idea in mind, I designed a system of Scala collection traits that support all of the above properties, in a pure trait form that is fully &#8220;mixable&#8221; by the programmer, so that one can use exactly the properties needed, but not pay for anything else.</p>

<p><a name="overview"></a></p>

<h5>Library Overview</h5>

<p>The source files containing the code discussed in the remainder of this post are available <a href="https://github.com/erikerlandson/silex/tree/blog/rbtraits/src/main/scala/com/redhat/et/silex/maps">here</a>, and the unit testing files are <a href="https://github.com/erikerlandson/silex/tree/blog/rbtraits/src/test/scala/com/redhat/et/silex/maps">here</a>.  At the time of this post the tree algorithm trait system is a <a href="https://github.com/willb/silex/pull/35">PR against the silex project</a>.</p>

<p>The library consists broadly of 3 kinds of traits:</p>

<ul>
<li>tree node traits &#8211; implement core tree support for some functionality</li>
<li>collection traits &#8211; provide additional collection API methods the user</li>
<li>collections &#8211; instantiate a usable incarnation of a collection</li>
</ul>


<p>For the programmer who wishes to either create a trait mixture, or add new mixable traits, the collections also function as reference implementations.</p>

<p>The three tables that follow summarize the currently available traits of each kind listed above.  They are (at the time of this posting) all under the package namespace <code>com.redhat.et.silex.maps</code> :</p>

<table border="5">
<caption>Tree Node Traits</caption>
<tr><td>trait</td><td>sub-package</td><td>description</td></tr>
<tr><td>Node[K]</td> <td>redblack.tree</td><td>Fundamental Red-Black tree functionality</td></tr>
<tr><td>NodeMap[K,V]</td><td>ordered.tree</td><td>Support a mapping from keys to values</td></tr>
<tr><td>NodeNear[K]</td><td>nearest.tree</td><td>Nearest-entry query (key-only)</td></tr>
<tr><td>NodeNearMap[K,V]</td><td>nearest.tree</td><td>Nearest-entry query for key/value maps</td></tr>
<tr><td>NodeInc[K,V]</td><td>increment.tree</td><td>Increment values w.r.t. a monoid</td></tr>
<tr><td>NodePS[K,V,P]</td><td>prefixsum.tree</td><td>Prefix sum queries by key (w.r.t. a monoid)</td></tr>
</table>




<br>


<table border="5">
<caption>Collection Traits</caption>
<tr><td>trait</td><td>sub-package</td><td>description</td></tr>
<tr><td>OrderedSetLike[K,IN,M]</td><td>ordered</td><td>ordered set of keys</td></tr>
<tr><td>OrderedMapLike[K,V,IN,M]</td><td>ordered</td><td>ordered key/value map</td></tr>
<tr><td>NearestSetLike[K,IN,M]</td><td>nearest</td><td>nearest entry query on keys</td></tr>
<tr><td>NearestMapLike[K,V,IN,M]</td><td>nearest</td><td>nearest entry query on key/value map</td></tr>
<tr><td>IncrementMapLike[K,V,IN,M]</td><td>increment</td><td>increment values w.r.t a monoid</td></tr>
<tr><td>PrefixSumMapLike[K,V,P,IN,M]</td><td>prefixsum</td><td>prefix sum queries w.r.t. a monoid</td></tr>
</table>




<br>


<table border="5">
<caption>Concrete Collections</caption>
<tr><td>trait</td><td>sub-package</td><td>description</td></tr>
<tr><td>OrderedSet[K]</td><td>ordered</td><td>ordered set</td></tr>
<tr><td>OrderedMap[K,V]</td><td>ordered</td><td>ordered key/value map</td></tr>
<tr><td>NearestSet[K]</td><td>nearest</td><td>ordered set with nearest-entry query</td></tr>
<tr><td>NearestMap[K,V]</td><td>nearest</td><td>ordred map with nearest-entry query</td></tr>
<tr><td>IncrementMap[K,V]</td><td>increment</td><td>ordered map with value increment w.r.t. a monoid</td></tr>
<tr><td>PrefixSumMap[K,V,P]</td><td>prefixsum</td><td>ordered map with prefix sum query w.r.t. a monoid</td></tr>
</table>




<br>


<p>The following diagram summarizes the organization and inheritance relationships of the classes.</p>

<p><img src="/assets/images/rbtraits/rbtraits.png" alt="diagram" /></p>

<p><a name="redblack"></a></p>

<h5>A Red/Black Tree Base Class</h5>

<p>The most fundamental trait in this hierarchy is the trait that embodies Red-Black balancing; a &#8220;red-black-ness&#8221; trait, as it were.  This trait supplies the axiomatic tree operations of insertion, deletion and key lookup, where the Red-Black balancing operations are encapsulated for insertion (due to <a href="http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid=44273">Chris Okasaki</a>) and deletion (due to <a href="http://www.cs.kent.ac.uk/people/staff/smk/redblack/rb.html">Stefan Kahrs</a>)  Note that Red-Black trees do not assume a separate value, as in a map, but require only keys (thus implementing an ordered set over the key type):</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">object</span> <span class="nc">tree</span> <span class="o">{</span>
</span><span class='line'>  <span class="cm">/** The color (red or black) of a node in a Red/Black tree */</span>
</span><span class='line'>  <span class="k">sealed</span> <span class="k">trait</span> <span class="nc">Color</span>
</span><span class='line'>  <span class="k">case</span> <span class="k">object</span> <span class="nc">R</span> <span class="k">extends</span> <span class="nc">Color</span>
</span><span class='line'>  <span class="k">case</span> <span class="k">object</span> <span class="nc">B</span> <span class="k">extends</span> <span class="nc">Color</span>
</span><span class='line'>
</span><span class='line'>  <span class="cm">/** Defines the data payload of a tree node */</span>
</span><span class='line'>  <span class="k">trait</span> <span class="nc">Data</span><span class="o">[</span><span class="kt">K</span><span class="o">]</span> <span class="o">{</span>
</span><span class='line'>    <span class="cm">/** The axiomatic unit of data for R/B trees is a key */</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">key</span><span class="k">:</span> <span class="kt">K</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="cm">/** Base class of a Red/Black tree node</span>
</span><span class='line'><span class="cm">    * @tparam K The key type</span>
</span><span class='line'><span class="cm">    */</span>
</span><span class='line'>  <span class="k">trait</span> <span class="nc">Node</span><span class="o">[</span><span class="kt">K</span><span class="o">]</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>    <span class="cm">/** The ordering that is applied to key values */</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">keyOrdering</span><span class="k">:</span> <span class="kt">Ordering</span><span class="o">[</span><span class="kt">K</span><span class="o">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="cm">/** Instantiate an internal node. */</span>
</span><span class='line'>    <span class="k">protected</span> <span class="k">def</span> <span class="n">iNode</span><span class="o">(</span><span class="n">color</span><span class="k">:</span> <span class="kt">Color</span><span class="o">,</span> <span class="n">d</span><span class="k">:</span> <span class="kt">Data</span><span class="o">[</span><span class="kt">K</span><span class="o">],</span> <span class="n">lsub</span><span class="k">:</span> <span class="kt">Node</span><span class="o">[</span><span class="kt">K</span><span class="o">],</span> <span class="n">rsub</span><span class="k">:</span> <span class="kt">Node</span><span class="o">[</span><span class="kt">K</span><span class="o">])</span><span class="k">:</span> <span class="kt">INode</span><span class="o">[</span><span class="kt">K</span><span class="o">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">// ... declarations for insertion, deletion and key lookup ...</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">// ... red-black balancing rules ...</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>   <span class="cm">/** Represents a leaf node in the Red Black tree system */</span>
</span><span class='line'>  <span class="k">trait</span> <span class="nc">LNode</span><span class="o">[</span><span class="kt">K</span><span class="o">]</span> <span class="nc">extends</span> <span class="nc">Node</span><span class="o">[</span><span class="kt">K</span><span class="o">]</span> <span class="o">{</span>
</span><span class='line'>    <span class="c1">// ... basis case insertion, deletion, lookup ...</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="cm">/** Represents an internal node (Red or Black) in the Red Black tree system */</span>
</span><span class='line'>  <span class="k">trait</span> <span class="nc">INode</span><span class="o">[</span><span class="kt">K</span><span class="o">]</span> <span class="nc">extends</span> <span class="nc">Node</span><span class="o">[</span><span class="kt">K</span><span class="o">]</span> <span class="o">{</span>
</span><span class='line'>    <span class="cm">/** The Red/Black color of this node */</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">color</span><span class="k">:</span> <span class="kt">Color</span>
</span><span class='line'>    <span class="cm">/** Including, but not limited to, the key */</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">data</span><span class="k">:</span> <span class="kt">Data</span><span class="o">[</span><span class="kt">K</span><span class="o">]</span>
</span><span class='line'>    <span class="cm">/** The left sub-tree */</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">lsub</span><span class="k">:</span> <span class="kt">Node</span><span class="o">[</span><span class="kt">K</span><span class="o">]</span>
</span><span class='line'>    <span class="cm">/** The right sub-tree */</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">rsub</span><span class="k">:</span> <span class="kt">Node</span><span class="o">[</span><span class="kt">K</span><span class="o">]</span>
</span><span class='line'>
</span><span class='line'>    <span class="c1">// ... implementations for insertion, deletion, lookup ...</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>I will assume most readers are familiar with basic binary tree operations, and the Red-Black rules are described elsewhere (I adapted them from the Scala red-black implementation).  For the purposes of this discussion, the most interesting feature is that this is a <em>pure Scala trait</em>.  All <code>val</code> declarations are abstract.  This trait, by itself, cannot function without a subclass to eventually perform dependency injection.   However, this abstraction allows the trait to be inherited freely &#8211; any programmer can inherit from this trait and get a basic Red-Black balanced tree for (nearly) free, as long as a few basic principles are adhered to for proper dependency injection.</p>

<p>Another detail to call out is the abstraction of the usual <code>key</code> with a <code>Data</code> element.  This element represents any node payload that is moved around as a unit during tree structure manipulations, such as balancing pivots.  In the case of a map-like subclass, <code>Data</code> is extended to include a <code>value</code> field as well as a <code>key</code> field.</p>

<p>The other noteworthy detail is the abstract definition <code>def iNode(color: Color, d: Data[K], lsub: Node[K], rsub: Node[K]): INode[K]</code> - this is the function called to create any new tree node.  In fact, this function, when eventually instantiated, is what performs dependency injection of other tree node fields.</p>

<p><a name="nodemap"></a></p>

<h5>Node Inheritance Example: NodeMap[K,V]</h5>

<p>A relatively simple example of node inheritance is hopefully instructive.  Here is the definition for tree nodes supporting a key/value map:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">object</span> <span class="nc">tree</span> <span class="o">{</span>
</span><span class='line'>  <span class="cm">/** Trees that back a map-like object have a value as well as a key */</span>
</span><span class='line'>  <span class="k">trait</span> <span class="nc">DataMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]</span> <span class="nc">extends</span> <span class="nc">Data</span><span class="o">[</span><span class="kt">K</span><span class="o">]</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">value</span><span class="k">:</span> <span class="kt">V</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="cm">/** Base class of ordered K/V tree node</span>
</span><span class='line'><span class="cm">    * @tparam K The key type</span>
</span><span class='line'><span class="cm">    * @tparam V The value type</span>
</span><span class='line'><span class="cm">    */</span>
</span><span class='line'>  <span class="k">trait</span> <span class="nc">NodeMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]</span> <span class="nc">extends</span> <span class="nc">Node</span><span class="o">[</span><span class="kt">K</span><span class="o">]</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">trait</span> <span class="nc">LNodeMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]</span> <span class="nc">extends</span> <span class="nc">NodeMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]</span> <span class="k">with</span> <span class="nc">LNode</span><span class="o">[</span><span class="kt">K</span><span class="o">]</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">trait</span> <span class="nc">INodeMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]</span> <span class="nc">extends</span> <span class="nc">NodeMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]</span> <span class="k">with</span> <span class="nc">INode</span><span class="o">[</span><span class="kt">K</span><span class="o">]</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">data</span><span class="k">:</span> <span class="kt">DataMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that in this case very little is added to the red/black functionality already provided by <code>Node[K]</code>.  A <code>DataMap[K,V]</code> trait is defined to add a <code>value</code> field in addition to the <code>key</code>, and the internal node <code>INodeMap[K,V]</code> refines the type of its <code>data</code> field to be <code>DataMap[K,V]</code>.  The semantics is little more than &#8220;tree nodes now carry a value in addition to a key.&#8221;</p>

<p>A tree node trait inherits from its own parent class <em>and</em> the corresponding traits for any mixed-in functionality.  So for example <code>INodeMap[K,V]</code> inherits from <code>NodeMap[K,V]</code> but also <code>INode[K]</code>.</p>

<p><a name="orderedmaplike"></a></p>

<h5>Collection Trait Example: OrderedMapLike[K,V,IN,M]</h5>

<p>Continuing with the ordered map example, here is the definition of the collection trait for an ordered map:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">trait</span> <span class="nc">OrderedMapLike</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">IN</span> <span class="k">&lt;:</span> <span class="kt">INodeMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]</span>, <span class="kt">M</span> <span class="k">&lt;:</span> <span class="kt">OrderedMapLike</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">IN</span>, <span class="kt">M</span><span class="o">]]</span>
</span><span class='line'>    <span class="nc">extends</span> <span class="nc">NodeMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]</span> <span class="k">with</span> <span class="nc">OrderedLike</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">IN</span>, <span class="kt">M</span><span class="o">]</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>  <span class="cm">/** Obtain a new map with a (key, val) pair inserted */</span>
</span><span class='line'>  <span class="k">def</span> <span class="o">+(</span><span class="n">kv</span><span class="k">:</span> <span class="o">(</span><span class="kt">K</span><span class="o">,</span> <span class="kt">V</span><span class="o">))</span> <span class="k">=</span> <span class="k">this</span><span class="o">.</span><span class="n">insert</span><span class="o">(</span>
</span><span class='line'>    <span class="k">new</span> <span class="nc">DataMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]</span> <span class="o">{</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">key</span> <span class="k">=</span> <span class="n">kv</span><span class="o">.</span><span class="n">_1</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">value</span> <span class="k">=</span> <span class="n">kv</span><span class="o">.</span><span class="n">_2</span>
</span><span class='line'>    <span class="o">}).</span><span class="n">asInstanceOf</span><span class="o">[</span><span class="kt">M</span><span class="o">]</span>
</span><span class='line'>
</span><span class='line'>  <span class="cm">/** Get the value stored at a key, or None if key is not present */</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">get</span><span class="o">(</span><span class="n">k</span><span class="k">:</span> <span class="kt">K</span><span class="o">)</span> <span class="k">=</span> <span class="k">this</span><span class="o">.</span><span class="n">getNode</span><span class="o">(</span><span class="n">k</span><span class="o">).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">value</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="cm">/** Iterator over (key,val) pairs, in key order */</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">iterator</span> <span class="k">=</span> <span class="n">nodesIterator</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">n</span> <span class="k">=&gt;</span> <span class="o">((</span><span class="n">n</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">key</span><span class="o">,</span> <span class="n">n</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">value</span><span class="o">)))</span>
</span><span class='line'>
</span><span class='line'>  <span class="cm">/** Container of values, in key order */</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">values</span> <span class="k">=</span> <span class="n">valuesIterator</span><span class="o">.</span><span class="n">toIterable</span>
</span><span class='line'>
</span><span class='line'>  <span class="cm">/** Iterator over values, in key order */</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">valuesIterator</span> <span class="k">=</span> <span class="n">nodesIterator</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">value</span><span class="o">)</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>You can see that this trait supplies collection API methods that a Scala programmer will recognize as being standard for any map-like collection.  Note that this trait also inherits other standard methods from <code>OrderedLike[K,IN,M]</code> (common to both sets and maps) and <em>also</em> inherits from <code>NodeMap[K,V]</code>: In other words, a collection is effectively yet another kind of tree node, with additional collection API methods mixed in.   Note also the use of &#8220;self types&#8221; (the type parameter <code>M</code>), which allows the collection to return objects of its own kind.  This is crucial for allowing operations like data insertion to return an object that also supports node insertion, and to maintain consistency of type across operations.  The collectoin type is properly &#8220;closed&#8221; with respect to its own operations.</p>

<p><a name="orderedmap"></a></p>

<h5>Collection Example: OrderedMap[K,V]</h5>

<p>To conclude the ordered map example, consider the task of defining a concrete instantiation of an ordered map:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">sealed</span> <span class="k">trait</span> <span class="nc">OrderedMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]</span> <span class="nc">extends</span> <span class="nc">OrderedMapLike</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">INodeMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]</span>, <span class="kt">OrderedMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]]</span> <span class="o">{</span>
</span><span class='line'>  <span class="k">override</span> <span class="k">def</span> <span class="n">toString</span> <span class="k">=</span>
</span><span class='line'>    <span class="s">&quot;OrderedMap(&quot;</span> <span class="o">+</span>
</span><span class='line'>      <span class="n">nodesIterator</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">n</span> <span class="k">=&gt;</span> <span class="n">s</span><span class="s">&quot;${n.data.key} -&gt; ${n.data.value}&quot;</span><span class="o">).</span><span class="n">mkString</span><span class="o">(</span><span class="s">&quot;, &quot;</span><span class="o">)</span> <span class="o">+</span>
</span><span class='line'>    <span class="s">&quot;)&quot;</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>You can see that (aside from a convenience override of <code>toString</code>) the trait <code>OrderedMap[K,V]</code> is nothing more than a vehicle for instantiating a particular concrete <code>OrderedMapLike[K,V,IN,M]</code> subtype, with particular concrete types for internal node (<code>INodeMap[K,V]</code>) and its own self-type.</p>

<p>Things become a little more interesting inside the companion object <code>OrderedMap</code>:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">object</span> <span class="nc">OrderedMap</span> <span class="o">{</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">key</span><span class="o">[</span><span class="kt">K</span><span class="o">](</span><span class="k">implicit</span> <span class="n">ord</span><span class="k">:</span> <span class="kt">Ordering</span><span class="o">[</span><span class="kt">K</span><span class="o">])</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">AnyRef</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">def</span> <span class="n">value</span><span class="o">[</span><span class="kt">V</span><span class="o">]</span><span class="k">:</span> <span class="kt">OrderedMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]</span> <span class="k">=</span>
</span><span class='line'>      <span class="k">new</span> <span class="nc">InjectMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">](</span><span class="n">ord</span><span class="o">)</span> <span class="k">with</span> <span class="nc">LNodeMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]</span> <span class="k">with</span> <span class="nc">OrderedMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that the object returned by the factory method is upcast to <code>OrderedMap[K,V]</code>, but in fact has the more complicated type: <code>InjectMap[K,V] with LNodeMap[K,V] with OrderedMap[K,V]</code>.  There are a couple things going on here.  The trait <code>LNodeMap[K,V]</code> ensures that the new object is in particular a leaf node, which embodies a new empty tree in the Red-Black tree system.</p>

<p>The type <code>InjectMap[K,V]</code> has an even more interesting purpose.  Here is its definition:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">class</span> <span class="nc">InjectMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">](</span><span class="k">val</span> <span class="n">keyOrdering</span><span class="k">:</span> <span class="kt">Ordering</span><span class="o">[</span><span class="kt">K</span><span class="o">])</span> <span class="o">{</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">iNode</span><span class="o">(</span><span class="n">clr</span><span class="k">:</span> <span class="kt">Color</span><span class="o">,</span> <span class="n">dat</span><span class="k">:</span> <span class="kt">Data</span><span class="o">[</span><span class="kt">K</span><span class="o">],</span> <span class="n">ls</span><span class="k">:</span> <span class="kt">Node</span><span class="o">[</span><span class="kt">K</span><span class="o">],</span> <span class="n">rs</span><span class="k">:</span> <span class="kt">Node</span><span class="o">[</span><span class="kt">K</span><span class="o">])</span> <span class="k">=</span>
</span><span class='line'>    <span class="k">new</span> <span class="nc">InjectMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">](</span><span class="n">keyOrdering</span><span class="o">)</span> <span class="k">with</span> <span class="nc">INodeMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]</span> <span class="k">with</span> <span class="nc">OrderedMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]</span> <span class="o">{</span>
</span><span class='line'>      <span class="c1">// INode</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">color</span> <span class="k">=</span> <span class="n">clr</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">lsub</span> <span class="k">=</span> <span class="n">ls</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">rsub</span> <span class="k">=</span> <span class="n">rs</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="n">dat</span><span class="o">.</span><span class="n">asInstanceOf</span><span class="o">[</span><span class="kt">DataMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]]</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Firstly, note that it is a bona fide <em>class</em>, as opposed to a trait.  This class is where, finally, all things abstract are made real &#8211; &#8220;dependency injection&#8221; in the parlance of Scala idioms.  You can see that it defines the implementation of abstract method <code>iNode</code>, and that it does this by returning yet <em>another</em> <code>InjectMap[K,V]</code> object, mixed with both <code>INodeMap[K,V]</code> and <code>OrderedMap[K,V]</code>, thus maintaining closure with respect to all three slices of functionality: dependency injection, the proper type of internal node, and map collection methods.</p>

<p>The various abstract <code>val</code> fields <code>color</code>, <code>data</code>, <code>lsub</code> and <code>rsub</code> are all given concrete values inside of <code>iNode</code>.  Here is where the value of concrete &#8220;reference&#8221; implementations manifests.  Any fields in the relevant internal-node type must be instantiated here, and the logic of instantiation cannot be inherited while still preserving the ability to mix abstract traits.  Therefore, any programmer wishing to create a new concrete sub-class must replicate the logic for instantiating all inherited in an internal node.</p>

<p>Another example makes the implications more clear.  Here is the definition of injection for a <a href="https://github.com/erikerlandson/silex/blob/blog/rbtraits/src/test/scala/com/redhat/et/silex/maps/mixed.scala">collection that mixes in all three traits</a> for incrementable values, nearest-key queries, and prefix-sum queries:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'>  <span class="k">class</span> <span class="nc">Inject</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">](</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">keyOrdering</span><span class="k">:</span> <span class="kt">Numeric</span><span class="o">[</span><span class="kt">K</span><span class="o">],</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">valueMonoid</span><span class="k">:</span> <span class="kt">Monoid</span><span class="o">[</span><span class="kt">V</span><span class="o">],</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">prefixMonoid</span><span class="k">:</span> <span class="kt">IncrementingMonoid</span><span class="o">[</span><span class="kt">P</span>, <span class="kt">V</span><span class="o">])</span> <span class="o">{</span>
</span><span class='line'>      <span class="k">def</span> <span class="n">iNode</span><span class="o">(</span><span class="n">clr</span><span class="k">:</span> <span class="kt">Color</span><span class="o">,</span> <span class="n">dat</span><span class="k">:</span> <span class="kt">Data</span><span class="o">[</span><span class="kt">K</span><span class="o">],</span> <span class="n">ls</span><span class="k">:</span> <span class="kt">Node</span><span class="o">[</span><span class="kt">K</span><span class="o">],</span> <span class="n">rs</span><span class="k">:</span> <span class="kt">Node</span><span class="o">[</span><span class="kt">K</span><span class="o">])</span> <span class="k">=</span>
</span><span class='line'>      <span class="k">new</span> <span class="nc">Inject</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">](</span><span class="n">keyOrdering</span><span class="o">,</span> <span class="n">valueMonoid</span><span class="o">,</span> <span class="n">prefixMonoid</span><span class="o">)</span>
</span><span class='line'>          <span class="k">with</span> <span class="nc">INodeTD</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">]</span> <span class="k">with</span> <span class="nc">TDigestMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">]</span> <span class="o">{</span>
</span><span class='line'>        <span class="c1">// INode[K]</span>
</span><span class='line'>        <span class="k">val</span> <span class="n">color</span> <span class="k">=</span> <span class="n">clr</span>
</span><span class='line'>        <span class="k">val</span> <span class="n">lsub</span> <span class="k">=</span> <span class="n">ls</span><span class="o">.</span><span class="n">asInstanceOf</span><span class="o">[</span><span class="kt">NodeTD</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">]]</span>
</span><span class='line'>        <span class="k">val</span> <span class="n">rsub</span> <span class="k">=</span> <span class="n">rs</span><span class="o">.</span><span class="n">asInstanceOf</span><span class="o">[</span><span class="kt">NodeTD</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">]]</span>
</span><span class='line'>        <span class="k">val</span> <span class="n">data</span> <span class="k">=</span> <span class="n">dat</span><span class="o">.</span><span class="n">asInstanceOf</span><span class="o">[</span><span class="kt">DataMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]]</span>
</span><span class='line'>        <span class="c1">// INodePS[K, V, P]</span>
</span><span class='line'>        <span class="k">val</span> <span class="n">prefix</span> <span class="k">=</span> <span class="n">prefixMonoid</span><span class="o">.</span><span class="n">inc</span><span class="o">(</span><span class="n">prefixMonoid</span><span class="o">.</span><span class="n">plus</span><span class="o">(</span><span class="n">lsub</span><span class="o">.</span><span class="n">pfs</span><span class="o">,</span> <span class="n">rsub</span><span class="o">.</span><span class="n">pfs</span><span class="o">),</span> <span class="n">data</span><span class="o">.</span><span class="n">value</span><span class="o">)</span>
</span><span class='line'>        <span class="c1">// INodeNear[K, V]</span>
</span><span class='line'>        <span class="k">val</span> <span class="n">kmin</span> <span class="k">=</span> <span class="n">lsub</span> <span class="k">match</span> <span class="o">{</span>
</span><span class='line'>          <span class="k">case</span> <span class="n">n</span><span class="k">:</span> <span class="kt">INodeTD</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">]</span> <span class="k">=&gt;</span> <span class="n">n</span><span class="o">.</span><span class="n">kmin</span>
</span><span class='line'>          <span class="k">case</span> <span class="k">_</span> <span class="k">=&gt;</span> <span class="n">data</span><span class="o">.</span><span class="n">key</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>        <span class="k">val</span> <span class="n">kmax</span> <span class="k">=</span> <span class="n">rsub</span> <span class="k">match</span> <span class="o">{</span>
</span><span class='line'>          <span class="k">case</span> <span class="n">n</span><span class="k">:</span> <span class="kt">INodeTD</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">]</span> <span class="k">=&gt;</span> <span class="n">n</span><span class="o">.</span><span class="n">kmax</span>
</span><span class='line'>          <span class="k">case</span> <span class="k">_</span> <span class="k">=&gt;</span> <span class="n">data</span><span class="o">.</span><span class="n">key</span>
</span><span class='line'>        <span class="o">}</span>
</span><span class='line'>      <span class="o">}</span>
</span><span class='line'>  <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Here you can see that all logic for both &#8220;basic&#8221; internal nodes and also for maintaining prefix sums, and key min/max information for nearest-entry queries, must be supplied.  If there is a singularity in this design here is where it is.  The saving grace is that it is localized into a single well defined place, and any logic can be transcribed from a proper reference implementation of whatever traits are being mixed.</p>

<p><a name="mixing"></a></p>

<h5>Finale: Trait Mixing</h5>

<p>I will conclude by showing the code for mixing tree node traits and collection traits, which is elegant.  Here are type definitions for tree nodes and collection traits that inherit from incrementable values, nearest-key queries, and prefix-sum queries, and there is literally no code except the proper inheritances:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">object</span> <span class="nc">tree</span> <span class="o">{</span>
</span><span class='line'>  <span class="k">import</span> <span class="nn">com.redhat.et.silex.maps.increment.tree._</span>
</span><span class='line'>  <span class="k">import</span> <span class="nn">com.redhat.et.silex.maps.prefixsum.tree._</span>
</span><span class='line'>  <span class="k">import</span> <span class="nn">com.redhat.et.silex.maps.nearest.tree._</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">trait</span> <span class="nc">NodeTD</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">]</span> <span class="nc">extends</span> <span class="nc">NodePS</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">]</span> <span class="k">with</span> <span class="nc">NodeInc</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]</span> <span class="k">with</span> <span class="nc">NodeNearMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">trait</span> <span class="nc">LNodeTD</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">]</span> <span class="nc">extends</span> <span class="nc">NodeTD</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">]</span>
</span><span class='line'>      <span class="k">with</span> <span class="nc">LNodePS</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">]</span> <span class="k">with</span> <span class="nc">LNodeInc</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]</span> <span class="k">with</span> <span class="nc">LNodeNearMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">trait</span> <span class="nc">INodeTD</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">]</span> <span class="nc">extends</span> <span class="nc">NodeTD</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">]</span>
</span><span class='line'>      <span class="k">with</span> <span class="nc">INodePS</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">]</span> <span class="k">with</span> <span class="nc">INodeInc</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]</span> <span class="k">with</span> <span class="nc">INodeNearMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span><span class="o">]</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">lsub</span><span class="k">:</span> <span class="kt">NodeTD</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">]</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">rsub</span><span class="k">:</span> <span class="kt">NodeTD</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">]</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span><span class='line'>
</span><span class='line'><span class="c1">// ...</span>
</span><span class='line'>
</span><span class='line'><span class="k">sealed</span> <span class="k">trait</span> <span class="nc">TDigestMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">]</span>
</span><span class='line'>  <span class="nc">extends</span> <span class="nc">IncrementMapLike</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">INodeTD</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">]</span>, <span class="kt">TDigestMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">]]</span>
</span><span class='line'>  <span class="k">with</span> <span class="nc">PrefixSumMapLike</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span>, <span class="kt">INodeTD</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">]</span>, <span class="kt">TDigestMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">]]</span>
</span><span class='line'>  <span class="k">with</span> <span class="nc">NearestMapLike</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">INodeTD</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">]</span>, <span class="kt">TDigestMap</span><span class="o">[</span><span class="kt">K</span>, <span class="kt">V</span>, <span class="kt">P</span><span class="o">]]</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">override</span> <span class="k">def</span> <span class="n">toString</span> <span class="k">=</span> <span class="c1">// ...</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/08/18/lightweight-non-negative-numerics-for-better-scala-type-signatures/">Lightweight Non-Negative Numerics for Better Scala Type Signatures</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-08-18T17:42:00-07:00" pubdate data-updated="true">Aug 18<span>th</span>, 2015</time>
        
        
         | <a href="/blog/2015/08/18/lightweight-non-negative-numerics-for-better-scala-type-signatures/#feedback">Feedback</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>In this post I want to discuss several advantages of defining lightweight non-negative numeric types in Scala, whose primary benefit is that they allow improved type signatures for Scala functions and methods.  I&#8217;ll first describe the simple class definition, and then demonstrate how it can be used in function signatures and the benefits of doing so.</p>

<p>If the following ideas interest you at all, I highly recommend looking at the <a href="https://github.com/fthomas/refined">&#8216;refined&#8217; project</a> authored by <a href="http://timepit.eu/~frank/">Frank S. Thomas</a>, which generalizes on the ideas below and supports additional static checking functionalities via macros.</p>

<h5>A Non-Negative Integer Type</h5>

<p>As a working example, I&#8217;ll discuss a non-negative integer type <code>NonNegInt</code>.  My proposed definition is sufficiently lightweight to view as a single code block:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">object</span> <span class="nc">nonneg</span> <span class="o">{</span>
</span><span class='line'>  <span class="k">import</span> <span class="nn">scala.language.implicitConversions</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">class</span> <span class="nc">NonNegInt</span> <span class="k">private</span> <span class="o">(</span><span class="k">val</span> <span class="n">value</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="k">extends</span> <span class="nc">AnyVal</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">object</span> <span class="nc">NonNegInt</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">def</span> <span class="n">apply</span><span class="o">(</span><span class="n">v</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>      <span class="n">require</span><span class="o">(</span><span class="n">v</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="o">,</span> <span class="s">&quot;NonNegInt forbids negative integer values&quot;</span><span class="o">)</span>
</span><span class='line'>      <span class="k">new</span> <span class="nc">NonNegInt</span><span class="o">(</span><span class="n">v</span><span class="o">)</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">implicit</span> <span class="k">def</span> <span class="n">toNonNegInt</span><span class="o">(</span><span class="n">v</span><span class="k">:</span> <span class="kt">Int</span><span class="o">)</span> <span class="k">=</span> <span class="nc">NonNegInt</span><span class="o">(</span><span class="n">v</span><span class="o">)</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">implicit</span> <span class="k">def</span> <span class="n">toInt</span><span class="o">(</span><span class="n">nn</span><span class="k">:</span> <span class="kt">NonNegInt</span><span class="o">)</span> <span class="k">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">value</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>The notable properties and features of <code>NonNegInt</code> are:</p>

<ul>
<li><code>NonNegInt</code> is a value class around an <code>Int</code>, and so invokes no actual object construction or allocation</li>
<li>Its constructor is private, and so is safe from directly constructing around a negative integer</li>
<li>It supplies factory method <code>NonNegInt(v)</code> to construct a non negative integer value</li>
<li>It supplies implicit conversion from <code>Int</code> values to <code>NonNegInt</code></li>
<li>Both factory method and implicit conversion check for negative values.  There is no way to construct a <code>NonNegInt</code> that contains a negative integer value.</li>
<li>It also supplies implicit conversion from <code>NonNegInt</code> back to <code>Int</code>.  Moving back and forth between <code>Int</code> and <code>NonNegInt</code> is effectively transparent.</li>
</ul>


<p>The above properties work to make <code>NonNegInt</code> very lightweight with respect to size and runtime properties, and semantically safe in the sense that it is impossible to construct one with a negative value inside it.</p>

<h5>Application of <code>NonNegInt</code></h5>

<p>I primarily envision <code>NonNegInt</code> as an easy and informative way to declare function parameters that are only well defined for non-negative values, without the need to write any explicit checking code, and yet allowing the programmer to call the function with normal <code>Int</code> values, due to the implicit conversions:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">object</span> <span class="nc">example</span> <span class="o">{</span>
</span><span class='line'>  <span class="k">import</span> <span class="nn">nonneg._</span>
</span><span class='line'>
</span><span class='line'>  <span class="k">def</span> <span class="n">element</span><span class="o">[</span><span class="kt">T</span><span class="o">](</span><span class="n">seq</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">T</span><span class="o">],</span> <span class="n">j</span><span class="k">:</span> <span class="kt">NonNegInt</span><span class="o">)</span> <span class="k">=</span> <span class="n">seq</span><span class="o">(</span><span class="n">j</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">// call element function with a regular Int index</span>
</span><span class='line'>  <span class="k">val</span> <span class="n">e</span> <span class="k">=</span> <span class="n">element</span><span class="o">(</span><span class="nc">Vector</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span><span class="mi">2</span><span class="o">,</span><span class="mi">3</span><span class="o">),</span> <span class="mi">1</span><span class="o">)</span> <span class="c1">// e is set to 2</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>This short example demonstrates some appealing properties of <code>NonNegInt</code>.  Firstly, the constraint that index <code>j &gt;= 0</code> is enforced via the type definition, and so the programmer does not have to write the usual <code>require(j &gt;= 0, ...)</code> check (or worry about forgetting it).  Secondly, the implicit conversion from <code>Int</code> to <code>NonNegInt</code> means the programmer can just provide a regular integer value for parameter <code>j</code>, instead of having to explicitly say <code>NonNegInt(1)</code>.  Third, the implicit conversion from <code>NonNegInt</code> to <code>Int</code> means that <code>j</code> can easily be used anywhere a regular <code>Int</code> is used.  Last, and very definitely not least, the fact that function <code>element</code> requires a non-negative integer is obvious <strong>right in the function signature</strong>.  There is no need for a programmer to guess whether <code>j</code> can be negative, and no need for the author of <code>element</code> to document that <code>j</code> cannot be negative.  Its type makes that completely clear.</p>

<h5>Conclusions</h5>

<p>In this post I&#8217;ve laid out some advantages of defining lightweight non-negative numeric types, in particular using <code>NonNegInt</code> as a working example.  Clearly, if you want to apply this idea, you&#8217;d want to also define <code>NonNegLong</code>, <code>NonNegDouble</code>, <code>NonNegFloat</code> and for that matter <code>PosInt</code>, <code>PosLong</code>, etc.  Happy computing!</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/08/17/the-reservoir-sampling-gap-distribution/">The Reservoir Sampling Gap Distribution</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-08-17T07:35:00-07:00" pubdate data-updated="true">Aug 17<span>th</span>, 2015</time>
        
        
         | <a href="/blog/2015/08/17/the-reservoir-sampling-gap-distribution/#feedback">Feedback</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>In a <a href="http://erikerlandson.github.io/blog/2014/09/11/faster-random-samples-with-gap-sampling/">previous post</a>, I showed that random Bernoulli and Poisson sampling could be made much faster by modeling the <em>sampling gap distribution</em> - that is, directly drawing random samples from the distribution of how many elements would be skipped over between actual samples taken.</p>

<p>Another popular sampling algorithm is <a href="https://en.wikipedia.org/wiki/Reservoir_sampling">Reservoir Sampling</a>.  Its sampling logic is a bit more complicated than Bernoulli or Poisson sampling, in the sense that the probability of sampling any given (jth) element <em>changes</em>. For a sampling reservoir of size R, and all j>R, the probability of choosing element (j) is R/j.  You can see that the potential payoff for gap-sampling is big, particularly as data size becomes large; as (j) approaches infinity, the probability R/j goes to zero, and the corresponding gaps between samples grow without bound.</p>

<p>Modeling a sampling gap distribution is a powerful tool for optimizing a sampling algorithm, but it requires that (1) you actually <em>know</em> the sampling distribution, and (2) that you can effectively draw values from that distribution faster than just applying a random process to drawing each data element.</p>

<p>With that goal in mind, I derived the probability mass function (pmf) and cumulative distribution function (cdf) for the sampling gap distribution of reservoir sampling.  In this post I will show the derivations.</p>

<h3>The Sampling Gap Distribution</h3>

<p>In the interest of making it easy to get at the actual answers, here are the pmf and cdf for the Reservoir Sampling Gap Distribution.  For a sampling reservoir of size (R), starting at data element (j), the probability distribution of the sampling gap is:</p>

<p><img src="/assets/images/reservoir1/figure6.png" title="Figure 6" alt="Figure 6" /></p>

<h3>Conventions</h3>

<p>In the derivations that follow, I will keep to some conventions:</p>

<ul>
<li>R = the sampling reservoir size.  R > 0.</li>
<li>j = the index of a data element being considered for sampling.  j > R.</li>
<li>k = the size of a gap between samples.  k >= 0.</li>
</ul>


<p>P(k) is the probability that the gap between one sample and the next is of size k.  The support for P(k) is over all k>=0.  I will generally assume that j>R, as the first R samples are always loaded into the reservoir and the actual random sampling logic starts at j=R+1.  The constraint j>R will also be relevant to many binomial coefficient expressions, where it ensures the coefficient is well defined.</p>

<h3>Deriving the Probability Mass Function, P(k)</h3>

<p>Suppose we just chose (randomly) to sample data element (j-1).  Now we are interested in the probability distribution of the next sampling gap.  That is, the probability P(k) that we will <em>not</em> sample the next (k) elements {j,j+1,&#8230;j+k-1}, and sample element (j+k):</p>

<p><img src="/assets/images/reservoir1/figure1.png" title="Figure 1" alt="Figure 1" /></p>

<p>By arranging the product terms in descending order as above, you can see that they can be written as factorial quotients:</p>

<p><img src="/assets/images/reservoir1/figure2.png" title="Figure 2" alt="Figure 2" /></p>

<p>Now we apply <a href="#LemmaA">Lemma A</a>.  The 2nd case (a&lt;=b) of the Lemma applies, since (j-1-R)&lt;=j, so we have:</p>

<p><img src="/assets/images/reservoir1/figure3.png" title="Figure 3" alt="Figure 3" /></p>

<p>And so we have now derived a compact, closed-form expression for P(k).</p>

<h3>Deriving the Cumulative Distribution Function, F(k)</h3>

<p>Now that we have a derivation for the pmf P(k), we can tackle a derivation for the cdf.  First I will make note of this <a href="https://en.wikipedia.org/wiki/Binomial_coefficient#Series_involving_binomial_coefficients">useful identity</a> that I scraped off of Wikipedia (I substituted (x) => (a) and (k) => (b)):</p>

<p><img src="/assets/images/reservoir1/identity1.png" title="identity 1" alt="identity 1" /></p>

<p>The cumulative distribution function for the sampling gap, F(k), is of course just the sum over P(t), for (t) from 0 up to (k):</p>

<p><img src="/assets/images/reservoir1/figure4.png" title="Figure 4" alt="Figure 4" /></p>

<p>This is a closed-form solution, but we can apply a bit more simplification:</p>

<p><img src="/assets/images/reservoir1/figure5.png" title="Figure 5" alt="Figure 5" /></p>

<h3>Conclusions</h3>

<p>We have derived closed-form expressions for the pmf and cdf of the Reservoir Sampling gap distribution:</p>

<p><img src="/assets/images/reservoir1/figure6.png" title="Figure 6" alt="Figure 6" /></p>

<p>In order to apply these results to a practical gap-sampling implementation of Reservoir Sampling, we would next need a way to efficiently sample from P(k), to obtain gap sizes to skip over.  How to accomplish this is an open question, but knowing a formula for P(k) and F(k) is a start.</p>

<h3>Acknowledgements</h3>

<p>Many thanks to <a href="http://rnowling.github.io/">RJ Nowling</a> and <a href="http://chapeau.freevariable.com/">Will Benton</a> for proof reading and moral support!  Any remaining errors are my own fault.</p>

<p><a name="LemmaA"></a></p>

<h3>Lemma A, And Its Proof</h3>

<p><img src="/assets/images/reservoir1/lemmaA.png" title="Lemma A" alt="Lemma A" /></p>

<p><img src="/assets/images/reservoir1/lemmaAproof.png" title="Lemma A Proof" alt="Lemma A Proof" /></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/08/14/generalizing-kendalls-tau/">Generalizing Kendall&#8217;s Tau</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-08-14T14:35:00-07:00" pubdate data-updated="true">Aug 14<span>th</span>, 2015</time>
        
        
         | <a href="/blog/2015/08/14/generalizing-kendalls-tau/#feedback">Feedback</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Recently I have been applying <a href="https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient">Kendall&#8217;s Tau</a> as an evaluation metric to assess how well a regression model ranks input samples, with respect to a known correct ranking.</p>

<p>The process of implementing the Kendall&#8217;s Tau statistic, with my software engineer&#8217;s hat on, caused me to reflect a bit on how it could be generalized beyond the traditional application of ranking numeric pairs.  In this post I&#8217;ll discuss the generalization of Kendall&#8217;s Tau to non-numeric data, and also generalizing from totally ordered data to partial orderings.</p>

<h5>A Review of Kendall&#8217;s Tau</h5>

<p>I&#8217;ll start with a brief review of Kendall&#8217;s Tau.  For more depth, a good place to start is the Wikipedia article at the link above.</p>

<p>Consider a sequence of (n) observations where each observation is a pair (x,y), where we wish to measure how well a ranking by x-values agrees with a ranking by the y-values.  Informally, Kendall&#8217;s Tau (aka the Kendall Rank Correlation Coefficient) is the difference between number of observation-pairs (pairs of pairs, if you will) whose ordering <em>agrees</em> (&#8220;concordant&#8221; pairs) and the number of such pairs whose ordering <em>disagrees</em> (&#8220;discordant&#8221; pairs).  This difference is divided by the total number of observation pairs.</p>

<p>The commonly-used formulation of Kendall&#8217;s Tau is the &#8220;Tau-B&#8221; statistic, which accounts for observed pairs having tied values in either x or y as being neither concordant nor discordant:</p>

<h6>Figure 1: Kendall&#8217;s Tau-B</h6>

<p><img src="/assets/images/kendalls_tau/figure_1.png" title="Kendall's Tau" alt="Kendall's Tau" /></p>

<p>The formulation above has quadratic complexity, with respect to data size (n).  It is possible to rearrange this computation in a way that can be computed in (n)log(n) time[1]:</p>

<h6>Figure 2: An (n)log(n) formulation of Kendall&#8217;s Tau-B</h6>

<p><img src="/assets/images/kendalls_tau/figure_2.png" title="Kendall's Tau" alt="Kendall's Tau" /></p>

<p>The details of performing this computation can be found at [1] or on the <a href="https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient#Algorithms">Wikipedia entry</a>.  For my purposes, I&#8217;ll note that it requires two (n)log(n) sorts of the data, which becomes relevant below.</p>

<h5>Generalizing to Non-Numeric Values</h5>

<p>Generalizing Kendall&#8217;s Tau to non-numeric values is mostly just making the observation that the definition of &#8220;concordant&#8221; and &#8220;discordant&#8221; pairs is purely based on comparing x-values and y-values (and, in the (n)log(n) formulation, performing sorts on the data).  From the software engineer&#8217;s perspective this means that the computations are well defined on any data type with an ordering relation, which includes numeric types but also chars, strings, sequences of any element supporting an ordering, etc.  Significantly, most programming languages support the concept of defining ordering relations on arbitrary data types, which means that <em><em>Kendall&#8217;s Tau can, in principle, be computed on literally any kind of data structure</em></em>, provided you supply it with a well defined ordering.  Furthermore, an examination of the algorithms shows that values of x and y need not even be of the same type, nor do they require the same ordering.</p>

<h5>Generalizing to Partial Orderings</h5>

<p>When I brought this observation up, my colleague <a href="http://chapeau.freevariable.com/">Will Benton</a> asked the very interesting question of whether it&#8217;s also possible to compute Kendall&#8217;s Tau on objects that have only a <em>partial ordering</em>.  It turns out that you <em><em>can</em></em> define Kendall&#8217;s Tau on partially ordered data, by defining the case of two non-comparable x-values, or y-values, as another kind of tie.</p>

<p>The big caveat with this definition is that the (n)log(n) optimization does not apply.  Firstly, the optimized algorithm relies heavily on (n)log(n) sorting, and there is no unique full sorting of elements that are only partially ordered.  Secondly, the formula&#8217;s definition of the quantities n1, n2 and n3 is founded on the assumption that element equality is transitive; this is why you can count a number of tied values, t, and use t(t-1)/2 as the corresponding number of tied pairs.  But in a partial ordering, this assumption is violated. Consider the case where (a) &lt; (b), but (a) is non-comparable to (c) and (b) is also non-comparable to (c).  By our definition, (a) is tied with (c), and (c) is tied with (b), but transitivity is violated, as (a) &lt; (b).</p>

<p>So how <em>can</em> we compute Tau in this case?  Consider (n1) and (n2), in Figure-1.  These values represent the number of pairs that were tied wrt (x) and (y), respectively.  We can&#8217;t use the shortcut formulas for (n1) and (n2), but we can count them directly, pair by pair, simply by conducting the traditional quadratic iteration over pairs, and incrementing (n1) whenever two x-values are noncomparable, and incrementing (n2) whenever two y-values are non-comparable, just as we increment (nc) and (nd) to count concordant and discordant pairs.  With this modification, we can apply the formula in Figure-1 as-is.</p>

<h5>Conclusions</h5>

<p>I made these observations without any particular application in mind. However, my instincts as a software engineer tell me that making generalizations in this way often paves the way for new ideas, once the generalized concept is made available.  With luck, it will inspire either me or somebody else to apply Kendall&#8217;s Tau in interesting new ways.</p>

<h5>References</h5>

<p>[1] Knight, W. (1966). &#8220;A Computer Method for Calculating Kendall&#8217;s Tau with Ungrouped Data&#8221;. Journal of the American Statistical Association 61 (314): 436439. doi:10.2307/2282833. JSTOR 2282833.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/05/06/parallel-k-medoids-using-scala-parseq/">Parallel K-Medoids Using Scala ParSeq</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-05-06T16:33:00-07:00" pubdate data-updated="true">May 6<span>th</span>, 2015</time>
        
        
         | <a href="/blog/2015/05/06/parallel-k-medoids-using-scala-parseq/#feedback">Feedback</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Scala supplies a <a href="http://docs.scala-lang.org/overviews/parallel-collections/overview.html">parallel collections library</a> that was designed to make it easy for a programmer to add parallel computing over the elements in a collection.  In this post, I will describe a case study of applying Scala&#8217;s parallel collections to cleanly implement multithreading support for training a K-Medoids clustering model.</p>

<h3>Motivation</h3>

<p><a href="http://en.wikipedia.org/wiki/K-medoids">K-Medoids clustering</a> is a relative of K-Means clustering that does not require an algebra over input data elements.  That is, K-Medoids requires only a distance metric defined on elements in the data space, and can cluster objects which do not have a well-defined concept of addition or division that is necessary for computing the <a href="http://en.wikipedia.org/wiki/Centroid">centroids</a> required by K-Means.  For example, K-Medoids can cluster character strings, which have a notion of <a href="http://en.wikipedia.org/wiki/Edit_distance">distance</a>, but no notion of summation that could be used to compute a geometric centroid.</p>

<p>This additional generality comes at a cost.  The medoid of a collection of elements is the member of the collection that minimizes some function F of the distances from that element to all the other elements in the collection.  For example, F might be the sum of distances from one element to all the elements, or perhaps the maximum distance, etc.  <strong>It is not hard to see that the cost of computing a medoid of (n) elements is quadratic in (n)</strong>: Evaluating F is linear in (n) and F in turn must be evaluated with respect to each element.  Furthermore, unlike centroid-based computations used in K-Means, computing a medoid does not naturally lend itself to common scale-out computing formalisms such as Spark RDDs, due to the full-cross-product nature of the computation.</p>

<p>With this in mind, a more traditional multithreading approach is a good candidate to achieve some practical parallelism on modern multi-core hardware.  I&#8217;ll demonstrate that this is easy to implement in Scala with parallel sequences.</p>

<h3>Non-Parallel Code</h3>

<p>Consider a baseline non-parallel implementation of K-Medoids, as in the following example skeleton code.  (A working version of this code, under review at the time of this post, can be <a href="https://github.com/erikerlandson/silex/blob/parseq_blog/src/main/scala/com/redhat/et/silex/cluster/KMedoids.scala">viewed here</a>)</p>

<figure class='code'><figcaption><span>A skeleton K-Medoids implementation </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'><span class="k">class</span> <span class="nc">KMedoids</span><span class="o">[</span><span class="kt">T</span><span class="o">](</span><span class="n">k</span><span class="k">:</span> <span class="kt">Int</span><span class="o">,</span> <span class="n">metric</span><span class="k">:</span> <span class="o">(</span><span class="kt">T</span><span class="o">,</span> <span class="kt">T</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="nc">Double</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">// Train a K-Medoids cluster on some input data</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">train</span><span class="o">[</span><span class="kt">T</span><span class="o">](</span><span class="n">data</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">T</span><span class="o">])</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">var</span> <span class="n">current</span> <span class="k">=</span> <span class="c1">// randomly select k data elements as initial cluster</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">var</span> <span class="n">model_converged</span> <span class="k">=</span> <span class="kc">false</span>
</span><span class='line'>    <span class="k">while</span> <span class="o">(!</span><span class="n">model_converged</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>      <span class="c1">// assign each element to its closest medoid</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">clusters</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">medoidIdx</span><span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">current</span><span class="o">)).</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">_2</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>      <span class="c1">// recompute the medoid from the latest cluster elements</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">next</span> <span class="k">=</span> <span class="n">benchmark</span><span class="o">(</span><span class="s">&quot;medoids&quot;</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">clusters</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">medoid</span><span class="o">)</span>
</span><span class='line'>      <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>      <span class="n">model_converged</span> <span class="k">=</span> <span class="c1">// test for model convergence</span>
</span><span class='line'>
</span><span class='line'>      <span class="n">current</span> <span class="k">=</span> <span class="n">next</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">// Return the medoid of some collection of elements</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">medoid</span><span class="o">(</span><span class="n">data</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">T</span><span class="o">])</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">benchmark</span><span class="o">(</span><span class="n">s</span><span class="s">&quot;medoid: n= ${data.length}&quot;</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>      <span class="n">data</span><span class="o">.</span><span class="n">minBy</span><span class="o">(</span><span class="n">medoidCost</span><span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">data</span><span class="o">)</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">// The sum of an element&#39;s distance to all the elements in its cluster</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">medoidCost</span><span class="o">(</span><span class="n">e</span><span class="k">:</span> <span class="kt">T</span><span class="o">,</span> <span class="n">data</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">T</span><span class="o">])</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">iterator</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">metric</span><span class="o">(</span><span class="n">e</span><span class="o">,</span> <span class="k">_</span><span class="o">)).</span><span class="n">sum</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">// Index of the closest medoid to an element</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">medoidIdx</span><span class="o">(</span><span class="n">e</span><span class="k">:</span> <span class="kt">T</span><span class="o">,</span> <span class="n">mv</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">T</span><span class="o">])</span> <span class="k">=</span> <span class="n">mv</span><span class="o">.</span><span class="n">iterator</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">metric</span><span class="o">(</span><span class="n">e</span><span class="o">,</span> <span class="k">_</span><span class="o">)).</span><span class="n">zipWithIndex</span><span class="o">.</span><span class="n">min</span><span class="o">.</span><span class="n">_2</span>
</span><span class='line'>
</span><span class='line'>  <span class="c1">// Output a benchmark timing of some expression</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">benchmark</span><span class="o">[</span><span class="kt">T</span><span class="o">](</span><span class="n">label</span><span class="k">:</span> <span class="kt">String</span><span class="o">)(</span><span class="n">blk</span><span class="k">:</span> <span class="o">=&gt;</span> <span class="n">T</span><span class="o">)</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">t0</span> <span class="k">=</span> <span class="nc">System</span><span class="o">.</span><span class="n">nanoTime</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">t</span> <span class="k">=</span> <span class="n">blk</span>
</span><span class='line'>    <span class="k">val</span> <span class="n">sec</span> <span class="k">=</span> <span class="o">(</span><span class="nc">System</span><span class="o">.</span><span class="n">nanoTime</span> <span class="o">-</span> <span class="n">t0</span><span class="o">)</span> <span class="o">/</span> <span class="mi">1</span><span class="n">e9</span>
</span><span class='line'>    <span class="n">println</span><span class="o">(</span><span class="n">f</span><span class="s">&quot;Run time for $label = $sec%.1f&quot;</span><span class="o">);</span> <span class="nc">System</span><span class="o">.</span><span class="n">out</span><span class="o">.</span><span class="n">flush</span>
</span><span class='line'>    <span class="n">t</span>
</span><span class='line'>  <span class="o">}</span>
</span><span class='line'><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>If we run the code above (de-skeletonized), then we might see something like this output from our benchmarking, where I clustered a dataset of 40,000 randomly-generated (x,y,z) points by Gaussian sampling around 5 chosen centers.  (This data is numeric, but I provide only a distance metric on the points.  K-Medoids has no knowledge of the data except that it can run the given metric function on it):</p>

<figure class='code'><figcaption><span>One iteration of a clustering run (k = 5) </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Run time for medoid: n= 8299 = 7.7
</span><span class='line'>Run time for medoid: n= 3428 = 1.2
</span><span class='line'>Run time for medoid: n= 12581 = 17.0
</span><span class='line'>Run time for medoid: n= 5731 = 3.3
</span><span class='line'>Run time for medoid: n= 9961 = 10.2
</span><span class='line'>Run time for medoids = 39.8</span></code></pre></td></tr></table></div></figure>


<p>Observe that cluster sizes are generally not the same, and we can see the time per cluster varying quadratically with respect to cluster size.</p>

<h3>A First Take On Parallel K-Medoids</h3>

<p>Studying our non-parallel code above, we can see that the computation of each new medoid is independent, which makes it a likely place to inject some parallelism. A Scala sequence can be transformed into a corresponding parallel sequence using the <code>par</code> method, and so parallelizing our code is literally this simple:</p>

<figure class='code'><figcaption><span>Parallelizing a collection with .par </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'>      <span class="c1">// recompute the medoid from the latest cluster elements</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">next</span> <span class="k">=</span> <span class="n">benchmark</span><span class="o">(</span><span class="s">&quot;medoids&quot;</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="n">clusters</span><span class="o">.</span><span class="n">par</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">medoid</span><span class="o">).</span><span class="n">seq</span>
</span><span class='line'>      <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>In this block, I also apply <code>.seq</code> at the end, which is not always necessary but can avoid type mismatches between <code>Seq[T]</code> and <code>ParSeq[T]</code> under some circumstances.</p>

<p>In my case I also wish to exercise some control over the threading used by the parallelism, and so I explicitly assign a <code>ForkJoinPool</code> thread pool to the sequence:</p>

<figure class='code'><figcaption><span>Set the threading used by a Scala ParSeq </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'>      <span class="c1">// establish a thread pool for use by K-Medoids</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">threadPool</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ForkJoinPool</span><span class="o">(</span><span class="n">numThreads</span><span class="o">)</span>
</span><span class='line'>
</span><span class='line'>      <span class="c1">// ...</span>
</span><span class='line'>
</span><span class='line'>      <span class="c1">// recompute the medoid from the latest cluster elements</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">next</span> <span class="k">=</span> <span class="n">benchmark</span><span class="o">(</span><span class="s">&quot;medoids&quot;</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>        <span class="k">val</span> <span class="n">pseq</span> <span class="k">=</span> <span class="n">clusters</span><span class="o">.</span><span class="n">par</span>
</span><span class='line'>        <span class="n">pseq</span><span class="o">.</span><span class="n">tasksupport</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ForkJoinTaskSupport</span><span class="o">(</span><span class="n">threadPool</span><span class="o">)</span>
</span><span class='line'>        <span class="n">pseq</span><span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="n">medoid</span><span class="o">).</span><span class="n">seq</span>
</span><span class='line'>      <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Minor grievance: it would be nice if Scala supported some &#8216;in-line&#8217; methods, like <code>seq.par(n)...</code> and <code>seq.par(threadPool)...</code>, instead of requiring the programmer to break the flow of the code to invoke <code>tasksupport =</code>, which returns <code>Unit</code>.</p>

<p>Now that we&#8217;ve parallelized our K-Medoids training, we should see how well it responds to additional threads.  I ran the above parallelized version using <code>{1, 2, 4, 8, 16, 32}</code> threads, on a machine with 40 cores, so that my benchmarking would not be impacted by attempting to run more threads than there are cores to support them.  I also ran two versions of test data.  The first I generated with clusters of equal size (5 clusters of ~8000 elements), and the second with one cluster being twice as large (1 cluster of ~13300 and 4 clusters of ~6700).  Following is a plot of throughput (iterations / second) versus threads:</p>

<p><img class="left" src="/assets/images/parseq/by_cluster_1.png" title="Throughput As A Function Of Threads" ></p>

<p>In the best of all possible worlds, our throughput would increase linearly with the number of threads; double the threads, double our iterations per second.  Instead, our throughput starts to increase nicely as we add threads, but hits a hard ceiling at 8 threads.  It is not hard to see why: our parallelism is limited by the number of elements in our collection of clusters.  In our case that is k = 5, and so we reach our ceiling at 8 threads, the first thread number >= 5.  Furthermore, we see that when the size of clusters is unequal, the throughput suffers even more.  The time required to complete the clustering is dominated by the most expensive element.  In our case, the cluster that is twice the size of other clusters:</p>

<figure class='code'><figcaption><span>Run time is dominated by largest cluster </span></figcaption>
<div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Run time for medoid: n= 6695 = 5.1
</span><span class='line'>Run time for medoid: n= 6686 = 5.2
</span><span class='line'>Run time for medoid: n= 6776 = 5.3
</span><span class='line'>Run time for medoid: n= 6682 = 5.4
</span><span class='line'>Run time for medoid: n= 13161 = 19.9
</span><span class='line'>Run time for medoids = 19.9</span></code></pre></td></tr></table></div></figure>


<h3>Take 2: Improving The Use Of Threads</h3>

<p>Fortunately it is not hard to improve on this situation.  If parallelizing by cluster is too coarse, we can try pushing our parallelism down one level of granularity.  In our case, that means parallelizing the outer loop of our medoid function, and it is just as easy as before:</p>

<figure class='code'><figcaption><span>Parallelize the outer loop of medoid computation </span></figcaption>
 <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='scala'><span class='line'>  <span class="c1">// Return the medoid of some collection of elements</span>
</span><span class='line'>  <span class="k">def</span> <span class="n">medoid</span><span class="o">(</span><span class="n">data</span><span class="k">:</span> <span class="kt">Seq</span><span class="o">[</span><span class="kt">T</span><span class="o">])</span> <span class="k">=</span> <span class="o">{</span>
</span><span class='line'>    <span class="n">benchmark</span><span class="o">(</span><span class="n">s</span><span class="s">&quot;medoid: n= ${data.length}&quot;</span><span class="o">)</span> <span class="o">{</span>
</span><span class='line'>      <span class="k">val</span> <span class="n">pseq</span> <span class="k">=</span> <span class="n">data</span><span class="o">.</span><span class="n">par</span>
</span><span class='line'>      <span class="n">pseq</span><span class="o">.</span><span class="n">tasksupport</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">ForkJoinTaskSupport</span><span class="o">(</span><span class="n">threadPool</span><span class="o">)</span>
</span><span class='line'>      <span class="n">pseq</span><span class="o">.</span><span class="n">minBy</span><span class="o">(</span><span class="n">medoidCost</span><span class="o">(</span><span class="k">_</span><span class="o">,</span> <span class="n">data</span><span class="o">)</span>
</span><span class='line'>    <span class="o">}</span>
</span><span class='line'>  <span class="o">}</span>
</span></code></pre></td></tr></table></div></figure>


<p>Note that I retained the previous parallelism at the cluster level, otherwise the algorithm would execute parallel medoids, but one cluster at a time.  Also observe that we are applying the same thread pool we supplied to the ParSeq at the cluster level.  Scala&#8217;s parallel logic can utilize the same thread pool at multiple granularities without blocking.  This makes it very clean to control the total number of threads used by some computation, by simply re-using the same threadpool across all points of parallelism.</p>

<p>Now, when we re-run our experiment, we see that our throughput continues to increase as we add threads.  The following plot illustrates the throughput increasing in comparison to the previous ceiling, and also that throughput is less sensitive to the cluster size, as threads can be allocated flexibly across clusters as they are available:</p>

<p><img class="left" src="/assets/images/parseq/all_1.png" title="Thread utilization improves at finer granularity" ></p>

<p>I hope this short case study has demonstrated how easy it is to add multithreading to computations with Scala parallel sequences, and some considerations for making the best use of available threads.  Happy Parallel Programming!</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/03/31/hygienic-closures-for-scala-function-serialization/">Hygienic Closures for Scala Function Serialization</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-03-31T06:06:00-07:00" pubdate data-updated="true">Mar 31<span>st</span>, 2015</time>
        
        
         | <a href="/blog/2015/03/31/hygienic-closures-for-scala-function-serialization/#feedback">Feedback</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>In most use cases of Scala closures, what you see is what you get, but there are exceptions where looks can be deceiving and this can have a big impact on closure serialization.  Closure serialization is of more than academic interest.  Tools like Apache Spark cannot operate without serializing functions over the network.  In this post I&#8217;ll describe some scenarios where closures include more than what is evident in the code, and then a technique for preventing unwanted inclusions.</p>

<p>To establish a bit of context, consider this simple example that obtains a function and serializes it to disk, and which <em>does</em> behave as expected:</p>

<pre><code>object Demo extends App {
  def write[A](obj: A, fname: String) {
    import java.io._
    new ObjectOutputStream(new FileOutputStream(fname)).writeObject(obj)
  }

  object foo {
    val v = 42
    // The returned function includes 'v' in its closure
    def f() = (x: Int) =&gt; v * x
  }

  // The function 'f' will serialize as expected
  val f = foo.f
  write(f, "/tmp/demo.f")
}
</code></pre>

<p>When this app is compiled and run, it will serialize <code>f</code> to &#8220;/tmp/demo.f1&#8221;, which of course includes the value of <code>v</code> as part of the closure for <code>f</code>.</p>

<pre><code>$ scalac -d /tmp closures.scala
$ scala -cp /tmp Demo
$ ls /tmp/demo*
/tmp/demo.f
</code></pre>

<p>Now, imagine you wanted to make a straightforward change, where <code>object foo</code> becomes <code>class foo</code>:</p>

<pre><code>object Demo extends App {
  def write[A](obj: A, fname: String) {
    import java.io._
    new ObjectOutputStream(new FileOutputStream(fname)).writeObject(obj)
  }

  // foo is a class instead of an object
  class foo() {
    val v = 42
    // The returned function includes 'v' in its closure, but also a secret surprise
    def f() = (x: Int) =&gt; v * x
  }

  // This will throw an exception!
  val f = new foo().f
  write(f, "/tmp/demo.f")
}
</code></pre>

<p>It would be reasonable to expect that this minor variation behaves exactly as the previous one, but instead it throws an exception!</p>

<pre><code>$ scalac -d /tmp closures.scala
$ scala -cp /tmp Demo
java.io.NotSerializableException: Demo$foo
</code></pre>

<p>If we look at the exception message, we see that it&#8217;s complaining about not knowing how to serialize objects of class <code>foo</code>.  But we weren&#8217;t including any values of <code>foo</code> in the closure for <code>f</code>, only a particular member &#8216;v&#8217;!  What gives?  Scala is not very helpful with diagnosing this problem, but when a class member value shows up in a closure that is defined <em>inside</em> the class body, the <em>entire instance</em>, including any and all other member values, is included in the closure.  Presumably this is because a class may have any number of instances, and the compiler is including the entire instance in the closure to properly resolve the correct member value.</p>

<p>One straightforward way to fix this is to simply make class <code>foo</code> serializable:</p>

<pre><code>class foo() extends Serializable {
  // ...
}
</code></pre>

<p>If you make this change to the above code, the example with <code>class foo</code> now works correctly, but it is working by serializing the entire <code>foo</code> instance, not just the value of <code>v</code>.</p>

<p>In many cases, this is not a problem and will work fine.  Serializing a few additional members may be inexpensive.  In other cases, however, it can be an impractical or impossible option.  For example, <code>foo</code> might include other very large members, which will be expensive or outright impossible to serialize:</p>

<pre><code>class foo() extends Serializable {
  val v = 42    // easy to serialize
  val w = 4.5   // easy to serialize
  val data = (1 to 1000000000).toList  // serialization landmine hiding in your closure

  // The returned function includes all of 'foo' instance in its closure
  def f() = (x: Int) =&gt; v * x
}
</code></pre>

<p>A variation on the above problem is class members that are small or moderate in size, but serialized many times.  In this case, the serialization cost can become intractable via repetition of unwanted inclusions.</p>

<p>Another potential problem is class members that are not serializable, and perhaps not under your control:</p>

<pre><code>class foo() extends Serializable {
  import some.class.NotSerializable

  val v = 42                      // easy to serialize
  val x = new NotSerializable     // I'll hide in your closure and fail to serialize

  // The returned function includes all of 'foo' instance in its closure
  def f() = (x: Int) =&gt; v * x
}
</code></pre>

<p>There is a relatively painless way to decouple values from their parent instance, so that only desired values are included in a closure.  Passing desired values as parameters to a shim function whose job is to assemble the closure will prevent the parent instance from being pulled into the closure.  In the following example, a shim function named <code>closureFunction</code> is defined for this purpose:</p>

<pre><code>object Demo extends App {
  def write[A](obj: A, fname: String) {
    import java.io._
    new ObjectOutputStream(new FileOutputStream(fname)).writeObject(obj)
  }

  // apply a generator to create a function with safe decoupled closures
  def closureFunction[E,D,R](enclosed: E)(gen: E =&gt; (D =&gt; R)) = gen(enclosed)

  class NotSerializable {}

  class foo() {
    val v1 = 42
    val v2 = 73
    val n = new NotSerializable

    // use shim function to enclose *only* the values of 'v1' and 'v2'
    def f() = closureFunction((v1, v2)) { enclosed =&gt;
      val (v1, v2) = enclosed
      (x: Int) =&gt; (v1 + v2) * x   // Desired function, with 'v1' and 'v2' enclosed
    }
  }

  // This will work!
  val f = new foo().f
  write(f, "/tmp/demo.f")
}
</code></pre>

<p>Being aware of the scenarios where parent instances are pulled into closures, and how to keep your closures clean, can save some frustration and wasted time.  Happy programming!</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2015/01/24/monadic-break-and-continue-for-scala-sequence-comprehensions/">Monadic &#8216;break&#8217; and &#8216;continue&#8217; for Scala Sequence Comprehensions</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2015-01-24T11:54:00-07:00" pubdate data-updated="true">Jan 24<span>th</span>, 2015</time>
        
        
         | <a href="/blog/2015/01/24/monadic-break-and-continue-for-scala-sequence-comprehensions/#feedback">Feedback</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Author&#8217;s note: I&#8217;ve since received some excellent feedback from the Scala community, which I included in some <a href="#notes">end notes</a>.</p>

<p>Author&#8217;s note the 2nd: I later realized I could apply an implicit conversion and mediator class to preserve the traditional ordering: the code has been updated with that approach.</p>

<p>Author&#8217;s note the 3rd: This concept has been submitted to the Scala project as JIRA <a href="https://issues.scala-lang.org/browse/SI-9120">SI-9120</a> (PR <a href="https://github.com/scala/scala/pull/4275">#4275</a>)</p>

<p>Scala <a href="http://docs.scala-lang.org/tutorials/tour/sequence-comprehensions.html">sequence comprehensions</a> are an excellent functional programming idiom for looping in Scala.  However, sequence comprehensions encompass much more than just looping &#8211; they represent a powerful syntax for manipulating <em>all</em> monadic structures<a href="#ref1">[1]</a>.</p>

<p>The <code>break</code> and <code>continue</code> looping constructs are a popular framework for cleanly representing multiple loop halting and continuation conditions at differing stages in the execution flow.  Although there is no native support for <code>break</code> or <code>continue</code> in Scala control constructs, it is possible to implement them in a clean and idiomatic way for sequence comprehensions.</p>

<p>In this post I will describe a lightweight and easy-to-use implementation of <code>break</code> and <code>continue</code> for use in Scala sequence comprehensions (aka <code>for</code> statements).  The entire implementation is as follows:</p>

<pre><code>object BreakableGenerators {
  import scala.language.implicitConversions

  type Generator[+A] = Iterator[A]
  type BreakableGenerator[+A] = BreakableIterator[A]

  // Generates a new breakable generator from any traversable object.
  def breakable[A](t1: TraversableOnce[A]): Generator[BreakableGenerator[A]] =
    List(new BreakableIterator(t1.toIterator)).iterator

  // Mediates boolean expression with 'break' and 'continue' invocations
  case class BreakableGuardCondition(cond: Boolean) {
    // Break the looping over one or more breakable generators, if 'cond' 
    // evaluates to true.
    def break(b: BreakableGenerator[_], bRest: BreakableGenerator[_]*): Boolean = {
      if (cond) {
        b.break
        for (x &lt;- bRest) { x.break }
      }
      !cond
    }

    // Continue to next iteration of enclosing generator if 'cond' 
    // evaluates to true.
    def continue: Boolean = !cond
  }

  // implicit conversion of boolean values to breakable guard condition mediary
  implicit def toBreakableGuardCondition(cond: Boolean) =
    BreakableGuardCondition(cond)

  // An iterator that can be halted via its 'break' method.  Not invoked directly
  class BreakableIterator[+A](itr: Iterator[A]) extends Iterator[A] {
    private var broken = false
    private[BreakableGenerators] def break { broken = true }

    def hasNext = !broken &amp;&amp; itr.hasNext
    def next = itr.next
  }
}
</code></pre>

<p>The approach is based on a simple subclass of <code>Iterator</code> &#8211; <code>BreakableIterator</code> &#8211; that can be halted by &#8216;breaking&#8217; it.  The function <code>breakable(&lt;traversable-object&gt;)</code> returns an Iterator over a single <code>BreakableIterator</code> object.  Iterators are monad-like structures in that they implement <code>map</code> and <code>flatMap</code>, and so its output can be used with <code>&lt;-</code> at the start of a <code>for</code> construct in the usual way.  Note that this means the result of the <code>for</code> statement will also be an Iterator.</p>

<p>Whenever the boolean expression for an <code>if</code> guard is followed by either <code>break</code> or <code>continue</code>, it is implicitly converted to a &#8220;breakable guard condition&#8221; that supports those methods.  The function <code>break</code> accepts one or more instances of <code>BreakableIterator</code>.  If it evaluates to <code>true</code>, the loops embodied by the given iterators are immediately halted via the associated <code>if</code> guard, and the iterators are halted via their <code>break</code> method.  The <code>continue</code> function is mostly syntactic sugar for a standard <code>if</code> guard, simply with the condition inverted.</p>

<p>Here is a simple example of <code>break</code> and <code>continue</code> in use:</p>

<pre><code>object Main {
  import BreakableGenerators._

  def main(args: Array[String]) {

    val r = for (
      // generate a breakable sequence from some sequential input
      loop &lt;- breakable(1 to 1000);
      // iterate over the breakable sequence
      j &lt;- loop;
      // print out at each iteration
      _ = { println(s"iteration j= $j") };
      // continue to next iteration when 'j' is even
      if { j % 2 == 0 } continue;
      // break out of the loop when 'j' exceeds 5
      if { j &gt; 5 } break(loop)
    ) yield {
      j
    }
    println(s"result= ${r.toList}")
  }
}
</code></pre>

<p>We can see from the resulting output that <code>break</code> and <code>continue</code> function in the usual way.  The <code>continue</code> clause ignores all subsequent code when <code>j</code> is even.  The <code>break</code> clause halts the loop when it sees its first value > 5, which is 7.  Only odd values &lt;= 5 are output from the <code>yield</code> statement:</p>

<pre><code>$ scalac -d /home/eje/class monadic_break.scala
$ scala -classpath /home/eje/class Main
iteration j= 1
iteration j= 2
iteration j= 3
iteration j= 4
iteration j= 5
iteration j= 6
iteration j= 7
result= List(1, 3, 5)
</code></pre>

<p>Breakable iterators can be nested in the way one would expect.  The following example shows an inner breakable loop nested inside an outer one:</p>

<pre><code>object Main {
  import BreakableGenerators._

  def main(args: Array[String]) {
    val r = for (
      outer &lt;- breakable(1 to 7);
      j &lt;- outer;
      _ = { println(s"outer  j= $j") };
      if { j % 2 == 0 } continue;
      inner &lt;- breakable(List("a", "b", "c", "d", "e"));
      k &lt;- inner;
      _ = { println(s"    inner  j= $j  k= $k") };
      if { k == "d" } break(inner);
      if { j == 5  &amp;&amp;  k == "c" } break(inner, outer)
    ) yield {
      (j, k)
    }
    println(s"result= ${r.toList}")
  }
}
</code></pre>

<p>The output demonstrates that the inner loop breaks whenever <code>k=="d"</code>, and so <code>"e"</code> is never present in the <code>yield</code> result.  When <code>j==5</code> and <code>k=="c"</code>, both the inner and outer loops are broken, and so we see that there is no <code>(5,"c")</code> pair in the result, nor does the outer loop ever iterate over 6 or 7:</p>

<pre><code>$ scalac -d /home/eje/class monadic_break.scala
$ scala -classpath /home/eje/class Main
outer  j= 1
    inner  j= 1  k= a
    inner  j= 1  k= b
    inner  j= 1  k= c
    inner  j= 1  k= d
outer  j= 2
outer  j= 3
    inner  j= 3  k= a
    inner  j= 3  k= b
    inner  j= 3  k= c
    inner  j= 3  k= d
outer  j= 4
outer  j= 5
    inner  j= 5  k= a
    inner  j= 5  k= b
    inner  j= 5  k= c
result= List((1,a), (1,b), (1,c), (3,a), (3,b), (3,c), (5,a), (5,b))
</code></pre>

<p>Using <code>break</code> and <code>continue</code> with <code>BreakableIterator</code> for sequence comprehensions is that easy.  Enjoy!</p>

<p><a name="notesname" id="notes"></a></p>

<h5>Notes</h5>

<p>The helpful community on freenode #scala made some excellent observations:</p>

<p>1: Iterators in Scala are not strictly monadic &#8211; it would be more accurate to say they&#8217;re &#8220;things with a flatMap and map method, also they can use filter or withFilter sometimes.&#8221;  However, I personally still prefer to think of them as &#8220;monadic in spirit if not law.&#8221;</p>

<p>2: The <code>break</code> function, as described in this post, is not truly functional in the sense of referential transparency, as the invocation <code>if break(loop) { condition }</code> involves a side-effect on the variable <code>loop</code>.  I would say that it does maintain &#8220;scoped functionality.&#8221;  That is, the break in non-referential transparency is scoped by the variables in question.  The <code>for</code> statement containing them is referentially transparent with respect to its inputs (provided no other code is breaking referential transparency, of course).</p>

<h5>References</h5>

<p><a name="ref1name" id="ref1">[1] </a><em><a href="http://www.manning.com/bjarnason/">Functional Programming in Scala</a></em>, Paul Chiusano and Runar Bjarnason, (section 6.6)</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/09/11/faster-random-samples-with-gap-sampling/">Faster Random Samples With Gap Sampling</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-09-11T07:57:00-07:00" pubdate data-updated="true">Sep 11<span>th</span>, 2014</time>
        
        
         | <a href="/blog/2014/09/11/faster-random-samples-with-gap-sampling/#feedback">Feedback</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Generating a random sample of a collection is, logically, a O(np) operation, where (n) is the sample size and (p) is the sampling probability.  For example, extracting a random sample, without replacement, from an array might look like this in pseudocode:</p>

<pre><code>sample(data: array, p: real) {
    n = length(data)
    m = floor(p * n)
    for j = 0 to m-1 {
        k = random(j, n-1)
        swap(data[j], data[k])
    }
    emit the first m elements of 'data' to output
}
</code></pre>

<p>We can see that this sampling algorithm is indeed O(np).  However, it makes some nontrivial assumptions about its input data:</p>

<ul>
<li>It is random access</li>
<li>It is writable</li>
<li>Its size is known</li>
<li>It can be destructively modified</li>
</ul>


<p>These assumptions can be violated in several ways.  The input data might not support random access, for example it might be a list, or stream, or an iterator over the same.  We might not know its size a priori.  It might be read-only.  It might be up-cast to some superclass where knowledge about these assumed properties is no longer available.</p>

<p>In cases such as this, there is another common sampling algorithm:</p>

<pre><code>sample(data: sequence, p: real) {
    while not end(data) {
        v = next(data)
        if random(0.0, 1.0) &lt; p then emit v to output
    }
}
</code></pre>

<p>The above algorithm enjoys all the advantage in flexibility.  It requires only linear access, does not require writable input, and makes no assumptions about input size.  However it comes at a price: this algorithm is no longer O(np), it is O(n).  Each element must be traversed directly, and worse yet the random number generagor (RNG) must be invoked on each element.  O(n) invocation of the RNG is a substantial cost &#8211; random number generation is typically very expensive compared to the cost of iterating to the next element in a sequence.</p>

<p>But&#8230; does linear sampling truly require us to invoke our RNG on every element?   Consider the pattern of data access, divorced from code.   It looks like a sequence of choices: for each element we either (skip) or (sample):</p>

<pre><code>(skip) (skip) (sample) (skip) (sample) (skip) (sample) (sample) (skip) (skip) (sample) ...
</code></pre>

<p>The number of consecutive (skip) events between each (sample) &#8211; the <em>sampling gap</em> &#8211; can itself be modeled as a random variable.  Each (skip)/(sample) choice is an independent Bernoulli trial, where the probability of (skip) is (1-p).   The PMF of the sampling gap for gap of {0, 1, 2, &#8230;} is therefore a geometric distribution: P(k) = p(1-p)<sup>k</sup></p>

<p>This suggests an alternative algorithm for sampling, where we only need to randomly choose sample gaps instead of randomly choosing whether we sample each individual element:</p>

<pre><code>// choose a random sampling gap 'k' from P(k) = p(1-p)^k
// caution: this explodes for p = 0 or p = 1
random_gap(p: real) {
    u = max(random(0.0, 1.0), epsilon)
    return floor(log(u) / log(1-p))
}

sample(data: sequence, p: real) {
    advance(data, random_gap(p))
    while not end(data) {
        emit next(data) to output
        advance(data, random_gap(p))
    }
}
</code></pre>

<p>The above algorithm calls the RNG only once per actual collected sample, and so the cost of RNG calls is O(np).  Note that the algorithm is still O(n), but the cost of the RNG tends to dominate the cost of sequence traversal, and so the resulting efficiency improvement is substantial.  I measured the following performance improvements with gap sampling, compared to traditional linear sequence sampling, on a <a href="https://gist.github.com/erikerlandson/05db1f15c8d623448ff6">Scala prototype testing rig</a>:</p>

<p><head><style>
table, th, td {
border: 1px solid black;
border-collapse: collapse;
}
th, td {
padding: 10px;
}
th {
text-align: center;
}
</style></head></p>

<table>
<tr> <th>Type</th> <th>p</th> <th>linear</th> <th>gap</th> </tr>
<tr> <td>Array</td> <td>0.001</td> <td>2833</td> <td>29</td> </tr>
<tr> <td>Array</td> <td>0.01</td> <td>2825</td> <td>76</td> </tr>
<tr> <td>Array</td> <td>0.1</td> <td>2985</td> <td>787</td> </tr>
<tr> <td>Array</td> <td>0.5</td> <td>3526</td> <td>3478</td> </tr>
<tr> <td>Array</td> <td>0.9</td> <td>3023</td> <td>6081</td> </tr>
<tr> <td>List</td> <td>0.001</td> <td>2213</td> <td>230</td> </tr>
<tr> <td>List</td> <td>0.01</td> <td>2220</td> <td>265</td> </tr>
<tr> <td>List</td> <td>0.1</td> <td>2337</td> <td>796</td> </tr>
<tr> <td>List</td> <td>0.5</td> <td>2794</td> <td>3151</td> </tr>
<tr> <td>List</td> <td>0.9</td> <td>2513</td> <td>4849</td> </tr>
</table>




<br>


<p>In the results above, we see that the gap sampling times are essentially linear in (p), as expected.  In the case of the linear-access List type, there is a higher baseline time (230 vs 29) due to the constant cost of actual data traversal.  Efficiency improvements are substantial at small sampling probabilities.</p>

<p>We can also see that the cost of gap sampling begins to meet and then exceed the cost of traditinal linear sampling, in the vicinnity (p) = 0.5.  This is due to the fact that the gap sampling logic is about twice the cost (in my test environment) of simply calling the RNG once.  For example, the gap sampling invokes a call to the numeric logarithm code that isn&#8217;t required in traditional sampling.  And so at (p) = 0.5 the time spent doing the gap sampling approximates the time spent invoking the RNG once per sample, and at higher values of (p) the cost is greater.</p>

<p>This suggests that one should in fact fall back to traditional linear sampling when the sampling probability (p) >= some threshold.  That threshold appears to be about 0.5 or 0.6 in my testing rig, but is likely to depend on underlying numeric libraries, the particular RNG being used, etc, and so I would expect it to benefit from customized tuning on a per-environment basis.  With this in mind, a sample algorithm as deployed would look like this:</p>

<pre><code>// threshold is a tuning parameter
threshold = 0.5

sample(data: sequence, p: real) {
    if (p &lt; threshold) {
        gap_sample(data, p)
    } else {
        traditional_linear_sample(data, p)
    }
}
</code></pre>

<p>The gap-sampling algorithm described above is for sampling <em>without</em> replacement.   However, the same approach can be modified to generate sampling <em>with</em> replacement.</p>

<p>When sampling with replacement, it is useful to consider the <em>replication factor</em> of each element (where a replication factor of zero means the element wasn&#8217;t sampled).  Pretend for the moment that the actual data size (n) is known.  The sample size (m) = (n)(p).  The probability that each element gets sampled, per trial, is 1/n, with (m) independent trials, and so the replication factor (r) for each element obeys a binomial distribution: Binomial(m, 1/n).  If we substitute (n)(p) for (m), we have Binomial(np, 1/n).  As the (n) grows, the Binomial is <a href="http://en.wikipedia.org/wiki/Binomial_distribution#Poisson_approximation">well approximated by a Poisson distribution</a> Poisson(L), where (L) = (np)(1/n) = (p).  And so for our purposes we may sample from Poisson(p), where P(r) = (p<sup>r</sup> / r!)e<sup>(-p),</sup> for our sampling replication factors.  Note that we have now discarded any dependence on sample size (n), as we desire.</p>

<p>In our gap-sampling context, the sampling gaps are now elements whose replication factor is zero, which occurs with probability P(0) = e<sup>(-p).</sup>  And so our sampling gaps are now drawn from geometric distribution P(k) = (1-q)(q)<sup>k,</sup> where q = e<sup>(-p).</sup>   When we <em>do</em> sample an element, its replication factor is drawn from Poisson(p), however <em>conditioned such that the value is >= 1.</em>  It is straightforward to adapt a <a href="http://en.wikipedia.org/wiki/Poisson_distribution#Generating_Poisson-distributed_random_variables">standard Poisson generator</a>, as shown below.</p>

<p>Given the above, gap sampling with replacement in pseudocode looks like:</p>

<pre><code>// sample 'k' from Poisson(p), conditioned to k &gt;= 1
poisson_ge1(p: real) {
    q = e^(-p)
    // simulate a poisson trial such that k &gt;= 1
    t = q + (1-q)*random(0.0, 1.0)
    k = 1

    // continue standard poisson generation trials
    t = t * random(0.0, 1.0)
    while (t &gt; q) {
        k = k + 1
        t = t * random(0.0, 1.0)
    }
    return k
}

// choose a random sampling gap 'k' from P(k) = p(1-p)^k
// caution: this explodes for p = 0 or p = 1
random_gap(p: real) {
    u = max(random(0.0, 1.0), epsilon)
    return floor(log(u) / -p)
}

sample(data: sequence, p: real) {
    advance(data, random_gap(p))
    while not end(data) {
        rf = poisson_ge1(p)
        v = next(data)
        emit (rf) copies of (v) to output
        advance(data, random_gap(p))
    }
}
</code></pre>

<p>The efficiency improvements I have measured for gap sampling with replacement are shown here:</p>

<table>
<tr> <th>Type</th> <th>p</th> <th>linear</th> <th>gap</th> </tr>
<tr> <td>Array</td> <td>0.001</td> <td>2604</td> <td>45</td> </tr>
<tr> <td>Array</td> <td>0.01</td> <td>3442</td> <td>117</td> </tr>
<tr> <td>Array</td> <td>0.1</td> <td>3653</td> <td>1044</td> </tr>
<tr> <td>Array</td> <td>0.5</td> <td>5643</td> <td>5073</td> </tr>
<tr> <td>Array</td> <td>0.9</td> <td>7668</td> <td>8388</td> </tr>
<tr> <td>List</td> <td>0.001</td> <td>2431</td> <td>233</td> </tr>
<tr> <td>List</td> <td>0.01</td> <td>2450</td> <td>299</td> </tr>
<tr> <td>List</td> <td>0.1</td> <td>2984</td> <td>1330</td> </tr>
<tr> <td>List</td> <td>0.5</td> <td>5331</td> <td>4752</td> </tr>
<tr> <td>List</td> <td>0.9</td> <td>6744</td> <td>7811</td> </tr>
</table>




<br>


<p>As with the results for sampling without replacement, we see that gap sampling cost is linear with (p), which yields large cost savings at small sampling, but begins to exceed traditional linear sampling at higher sampling probabilities.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/09/03/matryoshka-class-construction-from-the-scala-iterator-drop-method/">The Scala Iterator &#8216;drop&#8217; Method Generates a Matryoshka Class Nesting</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-09-03T17:23:00-07:00" pubdate data-updated="true">Sep 3<span>rd</span>, 2014</time>
        
        
         | <a href="/blog/2014/09/03/matryoshka-class-construction-from-the-scala-iterator-drop-method/#feedback">Feedback</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>The Scala Iterator <code>drop</code> method has a complexity bug that shows up when one calls <code>drop</code> repeatedly, for example when traversing over an iterator in a loop.</p>

<p>The nature of the problem is that <code>drop</code>, under the hood, invokes <code>slice</code>, which returns a new anonymous subclass of <code>AbstractIterator</code> containing an instance of the input class, which can be seen in this <a href="https://github.com/erikerlandson/scala/blob/scala_drop_blog/src/library/scala/collection/Iterator.scala#L323">code excerpt from Iterator.scala</a>:</p>

<pre><code>def drop(n: Int): Iterator[A] = slice(n, Int.MaxValue)

// ... comments excised ...

def slice(from: Int, until: Int): Iterator[A] = {
  val lo = from max 0
  var toDrop = lo
  while (toDrop &gt; 0 &amp;&amp; self.hasNext) {
    self.next()
    toDrop -= 1
  }

  // I am a ticking quadratic time bomb:
  new AbstractIterator[A] {
    private var remaining = until - lo
    def hasNext = remaining &gt; 0 &amp;&amp; self.hasNext
    def next(): A =
      if (remaining &gt; 0) {
        remaining -= 1
        self.next()
      }
      else empty.next()
  }
}
</code></pre>

<p>In the case where one is only calling <code>drop</code> once, this is not very consequential, but when the same method is used in a loop, the nesting is repeated, generating a nesting of anonymous classes that is ever-deeper &#8211; rather like Matryoshka dolls:</p>

<p><img src="/assets/images/matryoshka.jpg" width="400"></p>

<p>This can be a substantial problem, as it generates quadratic complexity in what is logically a linear operation.  A simple example of looping code that can cause this nesting:</p>

<pre><code>def process_nth_elements[T](itr: Iterator[T], n: Int = 1) {
  var iter = itr
  while (iter.hasNext) {
    val nxt = iter.next
    // ... process next element ...

    // skip to next element
    iter = iter.drop(n-1)
    // this becomes more and more expensive as iterator classes
    // become nested deeper
  }
}
</code></pre>

<p>A simple example program, which can be <a href="https://gist.github.com/erikerlandson/a310ccd3c58a85f031dc">found here</a>, demonstrates this nesting directly:</p>

<pre><code>import java.io.{StringWriter, PrintWriter}
import scala.reflect.ClassTag

def tracehead(e: Exception, substr: String = "slice"): String = {
  val sw = new StringWriter()
  e.printStackTrace(new PrintWriter(sw))
  sw.toString.split('\n').takeWhile((s:String)=&gt; !s.contains(substr)).drop(1).mkString("\n")  
}

class TestIterator[T: ClassTag](val iter: Iterator[T]) extends Iterator[T] {
  override def hasNext = iter.hasNext
  override def next = {
    println(tracehead(new Exception))
    iter.next
  }
}

def drop_test[T](itr: Iterator[T]) {
  var n = 0
  var iter = itr
  while (iter.hasNext) {
    n += 1
    println(s"\ndrop # $n")
    iter = iter.drop(1)
  }
}
</code></pre>

<p>When the <code>drop_test</code> function is run on an instance of <code>TestIterator</code>, the stack trace output shows the Matryoshka nesting directly:</p>

<pre><code>scala&gt; drop_test(new TestIterator(List(1,2,3,4,5).iterator))

drop # 1
    at $line18.$read$$iw$$iw$$iw$$iw$TestIterator.next(&lt;console&gt;:19)

drop # 2
    at $line18.$read$$iw$$iw$$iw$$iw$TestIterator.next(&lt;console&gt;:19)
    at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)

drop # 3
    at $line18.$read$$iw$$iw$$iw$$iw$TestIterator.next(&lt;console&gt;:19)
    at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)
    at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)

drop # 4
    at $line18.$read$$iw$$iw$$iw$$iw$TestIterator.next(&lt;console&gt;:19)
    at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)
    at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)
    at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)

drop # 5
    at $line18.$read$$iw$$iw$$iw$$iw$TestIterator.next(&lt;console&gt;:19)
    at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)
    at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)
    at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)
    at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)
</code></pre>

<p>One would expect this quadratic behavior to show up in benchmarking, and it does.  Consider this simple timing test:</p>

<pre><code>def drop_time[T](itr: Iterator[T]) {
  val t0 = System.currentTimeMillis()
  var iter = itr
  while (iter.hasNext) {
    iter = iter.drop(1)
  }
  println(s"Time: ${System.currentTimeMillis() - t0}")
}
</code></pre>

<p>One would expect this function to be linear in the length of the iterator, but we see the following behavior:</p>

<pre><code>scala&gt; drop_time((1 to 5000 * 1).toList.iterator)
Time: 106

scala&gt; drop_time((1 to 5000 * 2).toList.iterator)
Time: 475

scala&gt; drop_time((1 to 5000 * 3).toList.iterator)
Time: 1108

scala&gt; drop_time((1 to 5000 * 4).toList.iterator)
Time: 2037

scala&gt; drop_time((1 to 5000 * 5).toList.iterator)
Time: 3234

scala&gt; drop_time((1 to 5000 * 6).toList.iterator)
Time: 4717

scala&gt; drop_time((1 to 5000 * 7).toList.iterator)
Time: 6447

scala&gt; drop_time((1 to 5000 * 8).toList.iterator)
java.lang.StackOverflowError
    at scala.collection.Iterator$$anon$10.next(Iterator.scala:312)
</code></pre>

<p>The corresponding plot shows the quadratic cost:</p>

<p><img src="/assets/images/matryoshka_quadratic_plot.png" alt="&quot;image&quot;" /></p>

<p>Given the official semantics of <code>drop</code>, which state that the method invalidates the iterator it was called on, this nesting problem should be avoidable by implementing the method more like this:</p>

<pre><code>def drop(n: Int): Iterator[A] = {
  var j = 0
  while (j &lt; n) {
    this.next
    j += 1
  }
  this
}
</code></pre>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2014/08/12/implementing-parallel-prefix-scan-as-a-spark-rdd-transform/">Implementing Parallel Prefix Scan as a Spark RDD Transform</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-08-12T11:37:00-07:00" pubdate data-updated="true">Aug 12<span>th</span>, 2014</time>
        
        
         | <a href="/blog/2014/08/12/implementing-parallel-prefix-scan-as-a-spark-rdd-transform/#feedback">Feedback</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>In my <a href="/blog/2014/08/09/implementing-an-rdd-scanleft-transform-with-cascade-rdds/">previous post</a>, I described how to implement the Scala <code>scanLeft</code> function as an RDD transform.  By definition <code>scanLeft</code> invokes a sequential-only prefix scan algorithm; it does not assume that either its input function <code>f</code> or its initial-value <code>z</code> can be applied in a parallel fashion.   Its companion function <code>scan</code>, however, computes a <em>parallel</em> prefix scan.  In this post I will describe an implementation of parallel prefix <code>scan</code> as an RDD transform.</p>

<p>As was the case with <code>scanLeft</code>, a basic strategy is to begin by applying <code>scan</code> to each RDD partition.  Provided that appropriate &#8220;offsets&#8221; <code>{z1, z2, ...}</code> can be computed for each partition, these can be applied to the partial, per-partition results to yield the output.   In fact, the desired <code>{z1, z2, ...}</code> are the parallel prefix scan of the last element in each per-partition scan.  The following diagram illustrates:</p>

<p><img src="/assets/images/rdd_scan/rdd_scan_4.png" alt="image" /></p>

<p>The diagram above glosses over the details of computing <code>scan</code> to obtain <code>{z1, z2, ...}</code>.   I will first describe the implementation I currently use, and then also discuss a possible alternative.  The current implementation takes the approach of encoding the <a href="http://en.wikipedia.org/wiki/Prefix_sum#Parallel_algorithm">logic of a parallel prefix scan</a> directly into an RDD computation DAG.   Each iteration, or &#8220;ply,&#8221; of the parallel algorithm is represented by an RDD.  Each element resides in its own partition, and so the computation dependency for each element is directly representable in the RDD dependency substructure.  This construction is illustrated in the following schematic (for a vector of 8 z-values):</p>

<p><img src="/assets/images/rdd_scan/rdd_scan_5.png" alt="image" /></p>

<p>The parallel prefix scan algorithm executes O(log(n)) plies, which materializes as O(log(n)) RDDs shown in the diagram above.  In this context, (n) is the number of input RDD <em>partitions</em>, not to be confused with the number of data rows in the RDD.   There are O((n)log(n)) partitions, each having a single row containing the z-value for a corresponding output partition.   Some z-values are determined earlier than others.  For example z1 is immediately available in ply(0), and ply(3) can refer directly back to that ply(0) partition in the interest of efficiency, as called out by the red DAG arcs.</p>

<p>This scheme allows each final output partition to obtain its z-value directly from a single dedicated partition, which ensures that minimal data needs to be transferred across worker processes.  Final output partitions can be computed local to their corresponding input partitions.  Data transfer may be limited to the intermediate z-values, which are small single-row affairs by construction.</p>

<p>The code implementing the logic above can be <a href="https://github.com/erikerlandson/spark/blob/rdd_scan_blog/core/src/main/scala/org/apache/spark/rdd/ScanRDDFunctions.scala#L161">viewed here.</a></p>

<p>I will conclude by noting that there is an alternative to this highly distributed computation of <code>{z1, z2, ...}</code>, which is to collect the last-values in the per-partition intermediate scan ouputs into a single array, and run <code>scan</code> directly on that array.   This has the advantage of avoiding the construction of log(n) intermediate RDDs.   It does, however, require a monolithic &#8216;fan-in&#8217; of data into a single RDD to receive the collection of values.  That is followed by a fan-out of the array, where each output partition picks its single z-value from the array.  It is for this reason I suspect this alternative incurs substantially more transfer overhead across worker processes.  However, one might also partition the resulting z-values in some optimal way, so that each final output partition needs to request only the partition that contains its z-value.  Future experimentation might show that this can out-perform the current fully-distributed implementation.</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>About The Author</h1>
  <p>Erik is a senior software engineer on the <a href="http://www.redhat.com">Red Hat</a> Emerging Technologies Group.</p>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2015/09/26/a-library-of-binary-tree-algorithms-as-mixable-scala-traits/">A Library of Binary Tree Algorithms as Mixable Scala Traits</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/08/18/lightweight-non-negative-numerics-for-better-scala-type-signatures/">Lightweight Non-Negative Numerics for Better Scala Type Signatures</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/08/17/the-reservoir-sampling-gap-distribution/">The Reservoir Sampling Gap Distribution</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/08/14/generalizing-kendalls-tau/">Generalizing Kendall&#8217;s Tau</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/05/06/parallel-k-medoids-using-scala-parseq/">Parallel K-Medoids Using Scala ParSeq</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/erikerlandson">@erikerlandson</a> on GitHub
  
  <script type="text/javascript">
    $.domReady(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'erikerlandson',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>


<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  <script type="text/javascript">
    $.domReady(function(){
      getTwitterFeed("manyangled", 4, true);
    });
  </script>
  <script src="/javascripts/twitter.js" type="text/javascript"> </script>
  
    <a href="http://twitter.com/manyangled" class="twitter-follow-button" data-show-count="false">Follow @manyangled</a>
  
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 - Erik Erlandson -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
